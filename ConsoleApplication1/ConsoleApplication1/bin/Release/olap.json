{"count":493,"tag":"olap","questions":[{"tags":["sql","oracle","olap","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":45,"score":1,"question_id":12081229,"title":"Oracle OLAP Expression/Analytical Functions and NA Values","body":"<p>This question is specific to NA values and Oracle OLAP Expression Syntax.</p>\n\n<p><a href=\"http://docs.oracle.com/cd/E11882_01/olap.112/e23381.pdf\" rel=\"nofollow\">http://docs.oracle.com/cd/E11882_01/olap.112/e23381.pdf</a></p>\n\n<p>I am trying to perform some simple avg and sum calculations and there are specific cases where I will have NA values.  It does not appear to exist as part of the Expression Syntax, but is there anyway to perform one of these calcs and skip these values?</p>\n"},{"tags":["ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":9,"score":0,"question_id":13243718,"title":"SSAS dimensions hierarchies: A duplicate attribute key has been found when processing","body":"<p>I am completely new to SSAS an I am trying to deploy a simple cube with only one dimention comprised of multiples attributes. What I did already was to create a DSV from my data source and then I created a dimension from my fact table. It seams that no matter what happens, I get the following error message:</p>\n\n<p><code>Errors in the OLAP storage engine: A duplicate attribute key has been found when processing: Table: 'dbo_Fact_Statistics', Column: 'Team', value: 'ANA'. The attribute is 'Team'.</code></p>\n\n<p>This is my hierarchy: Id (SK) -> Player id -> Team -> Player Name -> Salary</p>\n\n<p>I don't understand, obviously the problem is not that the value is null, like I've seen in other threads, telling me to set <code>NullProcessing</code> under <code>KeyColumns</code> to something else than automatic, but this is not the problem in this context.</p>\n\n<p>Any help would be greatly appreciated.</p>\n"},{"tags":["python","database","olap","star-schema"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":45,"score":1,"question_id":13233809,"title":"Python Cubes OLAP Framework - how to work with joins?","body":"<p>I'm trying to use python's olap framework <a href=\"http://packages.python.org/cubes/\" rel=\"nofollow\">cubes</a> on a very simple database, but I am having some trouble joining tables.</p>\n\n<p>My schema looks like this:</p>\n\n<pre><code>Users table\nID | name\n\nProducts table\nID | name | price\n\nPurchases table\nID | user_id | product_id | date\n</code></pre>\n\n<p>And the cubes model:</p>\n\n<pre><code>{\n    'dimensions': [\n        {'name': 'user_id'},\n        {'name': 'product_id'},\n        {'name': 'date'},\n    ],\n    'cubes': [\n        {\n            'name': 'purchases',\n            'dimensions': ['user_id', 'product_id', 'date'],\n            'measures': ['price']\n            'mappings': {\n                'purchases.user_id': 'users.id',\n                'purchases.product_id': 'products.id',\n                'purchases.price': 'products.price'\n            },\n            'joins': [\n                {\n                    'master': 'purchases.user_id',\n                    'detail': 'users.id'\n                },\n                {\n                    'master': 'purchases.product_id',\n                    'detail': 'products.id'\n                }\n            ]\n        }\n    ]\n}\n</code></pre>\n\n<p>Now I would like to display all the purchases, showing the product's name, user's name and purchase date. I can't seem to find a way to do this. The documentation is a bit scarce.</p>\n\n<p>Thank you</p>\n"},{"tags":["java","olap","numa","activepivot"],"answer_count":2,"favorite_count":0,"up_vote_count":4,"down_vote_count":0,"view_count":46,"score":4,"question_id":13160456,"title":"How does NUMA architecture affect the performance of ActivePivot?","body":"<p>We are migrating an ActivePivot application to a new server (4 sockets Intel Xeon, 512GB of memory). After deploying we launched our application benchmark (that's a mix of large OLAP queries concurrent to real-time transactions). The measured performance is almost twice slower than on our previous server, that has similar processors but twice less cores and twice less memory.</p>\n\n<p>We have investigated the differences between the two servers, and it appears the big one has a <strong>NUMA architecture</strong> (non uniform memory acccess). Each CPU socket is physically close to 1/4 of the memory, but further away from the rest of it... The JVM that runs our application allocates a large global heap, there is a random fraction of that heap on each NUMA node. Our analysis is that the memory access pattern is pretty random and CPU cores frequently waste time accessing remote memory.</p>\n\n<p>We are looking after more feedback about leveraging ActivePivot on NUMA severs. Can we configure ActivePivot cubes, or thread pools, change our queries, configure the operating system?</p>\n"},{"tags":["ssis","ssas","olap","partitioning","rolap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":24,"score":0,"question_id":13034203,"title":"Updating a SSAS partition slice in SSIS","body":"<p>I have an SSAS cube that has two partitions, one in MOLAP and the other in ROLAP.  On my ROLAP partition, I have the slice set with the last 5 members of my Time dimension.  Each night when the cube is processed, I need to update the slice for my ROLAP partition to include the 5 most recent members in my time dimension.</p>\n\n<p>For example, if my cube has a partition slice of:</p>\n\n<pre><code> {[Time].[100], [Time].[101], [Time].[102], [Time].[103], [Time].[104]}\n</code></pre>\n\n<p>After processing, I want to update the slice to become</p>\n\n<pre><code> {[Time].[101], [Time].[102], [Time].[103], [Time].[104], [Time].[105]}\n</code></pre>\n\n<p>Is this possible to achieve this programmatically so that it is possible to include it as a step in my SSIS package?</p>\n"},{"tags":["ssas","olap","mdx"],"answer_count":11,"favorite_count":6,"up_vote_count":12,"down_vote_count":0,"view_count":7566,"score":12,"question_id":24963,"title":"How to learn MDX","body":"<p>I am currently learning OLAP &amp; MDX after many years of relational database development.  </p>\n\n<p>Any tips on getting started in MDX? What are the best books and resources to learn MDX?</p>\n"},{"tags":["ssas","olap","pivot-table","cube","office-web-components"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":53,"score":0,"question_id":12677636,"title":"PivotTable Field List Error - Current session is no longer valid due to structural changes in the database","body":"<p>I have an Analysis Services database. The cube Storage Mode is MOLAP and Proactive Caching is set to Off. All dimensions, measures and partitions have MOLAP set as Storage Mode and Proactive Caching set to Off as well.</p>\n\n<p>When I'm connecting to the cube through Excel or SQL Server Management Studio, everything works great.</p>\n\n<p>But users connect to the cube through web pages. We use Office Web Components. They were working fine until recently, users encounter the below error randomly when filtering dimension, expanding, collapsing, etc...:\nCurrent session is no longer valid due to structural changes in the database</p>\n\n<p>First the PivotTable returns blank. When they try to refresh data, they get the below error message.</p>\n\n<p><img src=\"http://i.stack.imgur.com/xkgdJ.png\" alt=\"Error\"></p>\n\n<p>Help.</p>\n\n<p>Thanks,</p>\n\n<p>Mona</p>\n"},{"tags":["olap","mondrian"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":9,"score":0,"question_id":13195652,"title":"Querying non-SQL multidimensional store","body":"<p>I have a data store with multidimensional arrays, which I would like to expose to Mondrian. Is it correct that as for now Monrian can only work with SQL databases? </p>\n\n<p>My arrays are rather small so I can comfortably load them into memory - perhaps I can somehow populate the Mondrian cache with them within my dialect implementation? This way Mondrian would never have to issue any SQL queries as all data would be loaded into the cache. </p>\n\n<p>Is this doable and can existing API be used for it or would I have to change some core Mondrian classes to implement it?</p>\n"},{"tags":["ssas","parent-child","mdx","olap","dimensions"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":37,"score":0,"question_id":13092247,"title":"Parent Child Relationships Between Measure Groups in SSAS","body":"<p>I am having a tough time figuring out how I am supposed to implement parent-child relationships between my measure groups in SSAS.  Essentially I am just trying recreate a standard SQL join so that I can lookup measures in my Parent group while using keys in my Child group.</p>\n\n<p>For example, let's say I have the following dimensions:</p>\n\n<ul>\n<li>Parent </li>\n<li>Child (FK: ParentID)</li>\n<li>Time</li>\n</ul>\n\n<p>And I have the following measure groups</p>\n\n<ul>\n<li>ParentFact (Keys: ParentID, TimeID - Measures Related to the parent over time)</li>\n<li>ChildFact (Keys: ChildID, TimeID - Measures related to the child over time)</li>\n</ul>\n\n<p>I have not created any specific dimensions for any of my fact tables.</p>\n\n<p>In the end I just want to run a query like this to list out measures in my Child table joined to measures in my Parent table:</p>\n\n<pre><code>SELECT\n    {\n        [ChildMeasure]\n        , [ParentMeasure]        \n    } ON COLUMNS\n    , [Child].Children ON ROWS\nFROM\n    [MyCube]\nWHERE\n    [Time].[100]\n</code></pre>\n\n<p>When this query runs, the Child rows are correctly listed, alongside the appropriate measure values for Time ID 100.  Unfortunately, <strong>ParentMeasure</strong> is all the same, and appears to be an aggregate for this value over all Parents at Time ID 100.  I would expect this column to show the value from each child's associated parent at Time ID 100.</p>\n\n<p>What am I doing wrong here?  Do I need to create FactDimensions for each FactTable, and somehow relate those?  Should I crate an association between Parent and Child in my Datasource view?  Would that make it a Snowflake schema, which I think I am supposed to avoid?</p>\n\n<p>As a side note, my ChildFact table actually contains ParentID as one of the measures, because it is on the relational table in the datasource (probably due to some previous denormalization effort by the DB developer).  Should I remove any measures that are actually FKs in my fact table, or is that somehow required for what I am trying to do?</p>\n"},{"tags":["sql","sql-server","ssas","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":44,"score":0,"question_id":13169055,"title":"Is it more efficient to build a cube off of tables or views?","body":"<p>I began to ponder this question after I noticed a system that I had been asked to work on had a cube based entirely off of views. I noticed that those views all joined in other tables/views and the views also had logic coded into them (if, case statements aswell as convert statements, concatation etc.). This all seemed horrible to me, but it made me wonder if one should ever base their datasource for a cube off of views?</p>\n\n<p>To me tables make more sense. It prevents expensive joins in the datasource, and also isn't prone to errors that could occur due to conversions performed by a view. However, I still see many people using views as datasources for cubes. Is there a best practice here? Am I perhaps missing some advantages that views give when used as a datasource?</p>\n"},{"tags":["data-warehouse","olap","business-intelligence"],"answer_count":1,"favorite_count":1,"up_vote_count":6,"down_vote_count":0,"view_count":257,"score":6,"question_id":8024861,"title":"What advantages does in-memory OLAP have over traditional systems with significant memory?","body":"<p>Do in-memory OLAP engines have advantages over the traditional OLAP engines backed by enough RAM to contain the entire cube(s)?</p>\n\n<p>For example, if I use a MOLAP engine (SSAS) and GB / TB of RAM where the entire cube (or even star-schema) is RAM resident, what is the difference compared to something like TM1 / SAP HANA?</p>\n"},{"tags":["mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":14,"score":0,"question_id":13162550,"title":"MDX Sum values of lower level","body":"<p>I am new to OLAP, I just designed my first cube and now I am trying to make some simple analyses. I have a simple time dimension that looks like this:</p>\n\n<pre><code>- Year\n  - Month\n    - DayOfWeek\n</code></pre>\n\n<p>Now I would like to sum all measures for e. g. Monday. I don't want to know the measure for Monday for every month of every year seperated (I am able to do this) but for all Mondays ever. Just one value.</p>\n\n<p>Is it possible and if, how?</p>\n\n<p>Thanks!</p>\n"},{"tags":["olap","business-intelligence","pentaho","mondrian"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":47,"score":0,"question_id":13117399,"title":"Is there any native client for Mondrian?","body":"<p>Now I'm start to study Pentaho and still working on Mondrian\nright now I confusing that does it have a native client for Mondrian? </p>\n\n<p>How do I start? Is there any document, tool or source that I should to understand </p>\n\n<p>Thanks for every answer.</p>\n"},{"tags":["mdx","olap","pentaho","mondrian","olap4j"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":1,"view_count":21,"score":-1,"question_id":13117235,"title":"Is it possible to process and query mondrian cubes without deploying to pentaho bi-server?","body":"<p>If yes, please give a reference. I did a little googling with no result.\nI want to use olap4j to query the cubes and use the result in a web application. But, I don't need any of the features of bi-server.\nAccording to tutorials, the olap schemas have to be published on an instance of bi-server. So isn't it really possible to have cubes built, processed and queried independently?</p>\n"},{"tags":["hadoop","olap","mapreduce","hbase","hive"],"answer_count":5,"favorite_count":9,"up_vote_count":18,"down_vote_count":0,"view_count":4085,"score":18,"question_id":1424132,"title":"Can OLAP be done in BigTable?","body":"<p>In the past I used to build WebAnalytics using OLAP cubes running on MySQL.\nNow an OLAP cube the way I used it is simply a large table (ok, it was stored a bit smarter than that) where each row is basically a measurement or and aggregated set of measurements. Each measurement has a bunch of dimensions (i.e. which pagename, useragent, ip, etc.) and a bunch of values (i.e. how many pageviews, how many visitors, etc.).</p>\n\n<p>The queries that you run on a table like this are usually of the form (meta-SQL):</p>\n\n<pre><code>SELECT SUM(hits), SUM(bytes),\nFROM MyCube\nWHERE date='20090914' and pagename='Homepage' and browser!='googlebot'\nGROUP BY hour\n</code></pre>\n\n<p>So you get the totals for each hour of the selected day with the mentioned filters.\nOne snag was that these cubes usually meant a full table scan (various reasons) and this meant a practical limitation on the size (in MiB) you could make these things.</p>\n\n<p>I'm currently learning the ins and outs of Hadoop and the likes.</p>\n\n<p>Running the above query as a mapreduce on a BigTable looks easy enough: \nSimply make 'hour' the key, filter in the map and reduce by summing the values.</p>\n\n<p>Can you run a query like I showed above (or at least with the same output) on a BigTable kind of system in 'real time' (i.e. via a user interface and the user get's their answer ASAP) instead of batch mode?</p>\n\n<p>If not; what is the appropriate technology to do something like this in the realm of BigTable/Hadoop/HBase/Hive and the likes?</p>\n"},{"tags":["ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":33,"score":0,"question_id":13056020,"title":"Regular vs Fact dimension usage in a very large scale database","body":"<p>Suppose a table of Customers containing about 40 millions of records; each day a few customers could be added to the table and some existing customers become updated.</p>\n\n<p>Every day a file containing last financial status of all customers (named as balance file) should be handled. A cube for the balance information should be created and a partition should be created for balance information of each day.</p>\n\n<p>Each record in balance file, belongs to a specific account. Each customer could have several accounts. All records in a single balance file belong to a single day and each day have a single balance file.</p>\n\n<p>Since the balance information is received as a file, an ETL step is mandatory. </p>\n\n<p>The question: Which makes a better performance:</p>\n\n<ul>\n<li>Having separate tables for customer and balance, defining a relation between them in a data source view and defining regular dimension usage between balance cube and customer dimension</li>\n<li>Joining customer and balance information into a single table in ETL step and defining a Fact dimension usage.</li>\n</ul>\n\n<p>It's really really hard to test in real situation. Please share any experience. Thanks in advance</p>\n"},{"tags":["aggregate-functions","mdx","olap","pentaho","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":152,"score":0,"question_id":10252695,"title":"Mondrian: Help picking the right aggregator for Measures?","body":"<p>There are some measurements I calculate that don't roll up in the same way as something like sales, or revenue.  In sales if you wanted to calculate sales for the quarter you could sum all entries in the sales for each month falling in that quarter.  And generally you'd just state in the schema the aggregator for the Sales Measure as sum and it would do that.</p>\n\n<p>Consider we have a table of employment entries.  If an employee was employed for that month there is an entry in the table for that employee.  And we want to know the head count for either Month, Quarter, or year.  In this case Measures like Head Count don't make sense to sum up in the same way.  The head count for the quarter is the same as the head count for the last day of the month occurring in that quarter.  Adding up the head count for Q1 isn't the sum of Jan, Feb, and Mar.  It's simply what was the head count on Mar 31?  However, I don't see any choice from the given aggregators that would allow you to specify that.</p>\n\n<p>Everything works great for Head Count when you are using the lowest division of time like month, but when you start to look at head count for the quarter or year summing up doesn't make much sense.</p>\n\n<p>So how is something like head count handled given that there are probably lots of other dimensions that could be included on the facts used to calculate head count?  You need to roll up head count on some dimensions, but you can't sum across all dated entries?  I'm looking to encapsulate this logic into the schema in some way so that users don't have to add extra filters every time they want to define a report using head count.</p>\n"},{"tags":["ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":2629,"score":0,"question_id":1302348,"title":"Memory error: Allocation failure: not enough storage is available to process this command","body":"<p>I was trying to run the cube script to install the cube-database in the analysis server. I changed the data source to point to the server I wanted, but I got the error as in the title with the error codes</p>\n\n<p>Error Code = 0x8007000E, External Code = 0x00000000:</p>\n\n<p>I tried the properties of the analysis server too and set the \"MemoryLimitErrorEnbales\" to false. That did not help. </p>\n\n<p>Any insight would be a great help.</p>\n\n<p>Thanx</p>\n"},{"tags":["reporting","olap","oracle-olap"],"answer_count":5,"favorite_count":2,"up_vote_count":1,"down_vote_count":0,"view_count":1672,"score":1,"question_id":5831566,"title":"best free olap reporting tool","body":"<p>I need a free olap reporting tool which I can show drill down, slice , dice ( olap operations). Do you know any free olap reporting tool that I can show olap  operations?</p>\n\n<p>Regards</p>\n"},{"tags":["sql-server","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":53,"score":0,"question_id":12983046,"title":"Performing Calculations on a Subset of OLAP data in MDX","body":"<p>I'm trying to figure out a way I can filter out data in my cube so that I can perform time-series calculations such as a moving average using only that subset.</p>\n\n<p>For example, let's say that I have a fact table with the following columns:</p>\n\n<ul>\n<li>DayId (Key)</li>\n<li>HourId (Key)</li>\n<li>Value</li>\n</ul>\n\n<p>I also have a Time dimension with a composite key of <strong>DayId</strong> and <strong>HourId</strong>.  This dimension has a key for every hour over the span of 100 days, so the keys go from (1,1) to (100,24).</p>\n\n<p>In the fact table there is a value for every point in time so it looks like</p>\n\n<pre><code>DayId HourId Value\n1     1       50\n1     2       60\n1     3       75.2\n...   ...     ...\n100   23      87\n100   24      89\n</code></pre>\n\n<p>Now, suppose I want to calculate a daily moving average from the beginning of time through some arbitrary point in the middle of the day.  Basically, I would want to calculate the average using the last point of every day except the last one, which would use a different point in time in the middle of the day.  If I was to do a moving average from day 1 to day 10, ending at noon of the 10th day (HourId 12), the data I would use for my calculation would look like:</p>\n\n<pre><code>DayId HourId Value\n1     24     80\n2     24     90\n3     24     39\n4     24     60\n...   ...    ...\n9     24     10 \n10    12     30\n</code></pre>\n\n<p>In SQL, I could retrieve a set like this pretty easily:</p>\n\n<pre><code>SELECT \n    *\nFROM\n    [FactTable]\nWHERE\n    ((DayId BETWEEN 1 AND 9) AND (HourId = 24))\n    OR ((DayId = 10) AND (HourId = 12))\n</code></pre>\n\n<p>I'm pretty new to OLAP and MDX, so I've really been struggling with the right way to do this.  So far, the best I've been able to do is to perform a sub-select in my <code>FROM</code> clause, and essentially construct a tuple set of only the rows I want:</p>\n\n<pre><code>WITH\n    MEMBER [SMA 10 Value] AS\n    AVG (\n        ([Time].[DayId].Lag(9):[Time].[DayId], [Time].[HourId])\n        , [Value]\n    )\nSELECT\n    {\n      [Value]\n      , [SMA 10 Value]\n    } ON COLUMNS\n    , ([Time].[DayId], [Time].[HourId]) ON ROWS\nFROM\n(\n    SELECT\n        [Measures] ON COLUMNS\n        , {\n            ([Time].[DayId].[1]:[Time].[DayId].[9], [Time].[HourId].[24])\n            , ([Time].[DayId].[10], [Time].[HourId].[12])\n    } ON ROWS\n    FROM\n        [Cube]\n)\n</code></pre>\n\n<p>However, it doesn't seem to quite work right for my calculations.  The moving average seems to be correct over the first 9 days, because their tuples all have the same hour ID, but when I get to the final day, instead of using the values from the previous 9 tuples, it performs the average over the previous 9 days with the 12 Hour ID.</p>\n\n<p>What am I doing wrong here, is there a better way that I can filter my time dimension down to eliminate unwanted rows from my calculations?</p>\n"},{"tags":["scala","data-structures","olap"],"answer_count":4,"favorite_count":3,"up_vote_count":5,"down_vote_count":0,"view_count":158,"score":5,"question_id":12980043,"title":"Is there a data structure / library to do in memory olap / pivot tables in Java / Scala?","body":"<h2>Relevant questions</h2>\n\n<p>This question is quite relevant, but is 2 years old: <a href=\"http://stackoverflow.com/questions/4510343/in-memory-olap-engine-in-java\">In memory OLAP engine in Java</a> </p>\n\n<h2>Background</h2>\n\n<p>I would like to create a pivot-table like matrix from a given tabular dataset, in memory</p>\n\n<p>e.g. an age by marital status count (rows are age, columns are marital status).</p>\n\n<ul>\n<li><p><strong>The input</strong>: List of People, with age and some Boolean property (e.g. married), </p></li>\n<li><p><strong>The desired output</strong>: count of People, by age (row) and isMarried (column)</p></li>\n</ul>\n\n<h2>What I've tried (Scala)</h2>\n\n<pre><code>case class Person(val age:Int, val isMarried:Boolean)\n\n...\nval people:List[Person] = ... //\n\nval peopleByAge = people.groupBy(_.age)  //only by age\nval peopleByMaritalStatus = people.groupBy(_.isMarried) //only by marital status\n</code></pre>\n\n<p>I managed to do it the naive way, first grouping by age, then <code>map</code> which is doing a  <code>count</code> by marital status, and outputs the result, then I <code>foldRight</code> to aggregate</p>\n\n<pre><code>TreeMap(peopleByAge.toSeq: _*).map(x =&gt; {\n    val age = x._1\n    val rows = x._2\n    val numMarried = rows.count(_.isMarried())\n    val numNotMarried = rows.length - numMarried\n    (age, numMarried, numNotMarried)\n}).foldRight(List[FinalResult]())(row,list) =&gt; {\n     val cumMarried = row._2+ \n        (if (list.isEmpty) 0 else list.last.cumMarried) \n     val cumNotMarried = row._3 + \n        (if (list.isEmpty) 0 else l.last.cumNotMarried) \n     list :+ new FinalResult(row._1, row._2, row._3, cumMarried,cumNotMarried) \n}.reverse\n</code></pre>\n\n<p>I don't like the above code, it's not efficient, hard to read, and I'm sure there is a better way.</p>\n\n<h2>The question(s)</h2>\n\n<p>How do I groupBy \"both\"? and how do I do a count for each subgroup, e.g. </p>\n\n<blockquote>\n  <p>How many people are exactly 30 years old and married?</p>\n</blockquote>\n\n<p>Another question, is how do I do a running total, to answer the question: </p>\n\n<blockquote>\n  <p>How many people above 30 are married?</p>\n</blockquote>\n\n<hr>\n\n<p><strong>Edit:</strong></p>\n\n<p>Thank you for all the great answers.</p>\n\n<p>just to clarify, I would like the output to include a \"table\" with the following columns </p>\n\n<ul>\n<li>Age (ascending)</li>\n<li>Num Married </li>\n<li>Num Not Married </li>\n<li>Running Total Married </li>\n<li>Running Total Not Married </li>\n</ul>\n\n<p>Not only answering those specific queries, but to produce a report that will allow answering all such type of questions.</p>\n"},{"tags":["sql-server","ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":56,"score":0,"question_id":12975973,"title":"How Exactly Is NONEMPTY Working Here?","body":"<p>I have a cube with two measure groups, one in MOLAP format and the other in ROLAP format.  I've also created a calculated member (<code>[C]</code>) from a single column in each of the member groups (<code>[A]</code> <strong>MOLAP</strong> and <code>[B]</code> <strong>ROLAP</strong>).  All I want is for <code>[C]</code> to return me the value of <code>[A]</code> if it is not empty, otherwise return <code>[B]</code>.  This is achieved pretty easily with a <code>CASE</code> statement:</p>\n\n<pre><code>WITH MEMBER [C] AS\n    CASE\n        WHEN ISEMPTY([A]) THEN [B]\n        ELSE [A]\n    END\n</code></pre>\n\n<p>This works great, and running the following query displays the results exactly like I would expect them to be displayed, where <code>[C]</code> is <code>[B]</code> only when <code>[A]</code> is empty.</p>\n\n<pre><code>SELECT\n    { [A]\n    , [B]\n    , [C]\n    } ON COLUMNS\n    , [Time].CHILDREN ON ROWS\nFROM    \n    [Cube]\n</code></pre>\n\n<p>However,  there are some cases where both <code>[A]</code> and <code>[B]</code> are empty, and I would like to filter them out of the result set.  Normally, I would be able to just wrap the <code>[Time]</code> dimension in <code>NONEMPTY</code> to achieve this:</p>\n\n<pre><code>SELECT\n    { [A]\n    , [B]\n    , [C]\n    } ON COLUMNS\n    , NONEMPTY([Time].CHILDREN) ON ROWS\nFROM    \n    [Cube]\n</code></pre>\n\n<p>But when I try this with the above query, the results filter out all of the rows where <code>[A]</code> is empty, regardless of whether or not <code>[B]</code> is empty.  Rows where <code>[B]</code> is empty are not filtered out.</p>\n\n<p>I would expect that NONEMPTY would either:</p>\n\n<ol>\n<li>Filter out only rows where <code>[C]</code> is empty (<code>[A]</code> and <code>[B]</code> are empty) <strong>OR</strong></li>\n<li>Filter out all rows where <code>[A]</code> OR <code>[B]</code> is empty</li>\n</ol>\n\n<p>Why is <code>NONEMPTY</code> only taking <code>[A]</code> in to account here?</p>\n"},{"tags":["sql-server-2008-r2","ssas","mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":46,"score":0,"question_id":12962305,"title":"SSAS queries run in 0ms. Going through SSRS they take 1.3 seconds","body":"<p>these queries show up as running in 0ms using SSMS/SSAS natively.</p>\n\n<p>but when I send them through Reporting Services, they're showing up as 1.3 seconds. That is ~1300 times slower than 0ms.</p>\n\n<p>I know I'm a little bit rusty on MDX, but I'd LOVE it if someone would take a look at this.</p>\n\n<p>I'm using SQL Enterprise, the SSAS server is an I7 desktop with SSD.</p>\n\n<pre><code>\n=\"SELECT NON EMPTY {[Measures].[Cost Amt] } ON COLUMNS, \nNON EMPTY { \n([Vendor].[Vendor].ALLMEMBERS * [Cost Code].[Cost Code].ALLMEMBERS ) \n} ON ROWS \nFROM [DspAlloc] \nWHERE [InvoiceNumber].[All InvoiceNumber].[\" + Parameters!InvoiceNumber.Value + \n\"] CELL PROPERTIES VALUE, BACK_COLOR, FORE_COLOR, FORMATTED_VALUE, FORMAT_STRING,\nFONT_NAME, FONT_SIZE, FONT_FLAGS\"\n\n=\"SELECT NON EMPTY { \n[Measures].[Total Freight], [Measures].[Incl Frt], [Measures].[Total Qty],\n[Measures].[Total Ship Wt] } ON COLUMNS, \nNON EMPTY { ([Item_No].[Item_No].ALLMEMBERS ) } ON ROWS \nFROM [InvoiceDetail] \nWHERE [InvoiceNumber].[All InvoiceNumber].[\" + Parameters!InvoiceNumber.Value + \n\"] CELL PROPERTIES VALUE, BACK_COLOR, FORE_COLOR, FORMATTED_VALUE, FORMAT_STRING,\nFONT_NAME, FONT_SIZE, FONT_FLAGS\"\n</code></pre>\n"},{"tags":["mdx","olap","mondrian","msas"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":40,"score":0,"question_id":12681096,"title":"How to groupby and filter on the same dimension in MDX","body":"<p>I want to create a barchart with a bar for each month and some measure. </p>\n\n<p>But i also want to filter on a range of day which might not completly overlap some of the month. </p>\n\n<p>When that happen I would like the aggregate count for those month to only aggregat over the days that fall in my date range not get the aggregate for the whole month.</p>\n\n<p>Is that possible with MDX and if it is how should the request look like?</p>\n"},{"tags":["sql","sql-server","ssas","mdx","olap"],"answer_count":4,"favorite_count":0,"up_vote_count":5,"down_vote_count":0,"view_count":90,"score":5,"question_id":12896019,"title":"Combining Relational and OLAP data in an MDX Query","body":"<p>I have an SSAS 2008 cube that is being used to house end of day financial data from the stock market.  The cube is only processed once a day after the market closes, so it never has any information about the current intraday trading data.  I also have a relational database that houses the current intraday trading information for stocks.  I am trying to find a way to combine those two data sources so that I can perform calculations such as a 30 day moving average for a stock that is based off of its current price, as well as the previous 29 days of historical data.  I am using SSAS Standard edition, so I don't have access to features such as Proactive Caching or multiple partitions to help me process the current data in near real time.  </p>\n\n<p>Is there any way that can somehow dynamically include rows from my SQL database into my fact table, for the context of an individual query?  Essentially just bring in a small subset of data into the cube temporarily in order to process a certain calculation?</p>\n"},{"tags":["data","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":22,"score":0,"question_id":12935314,"title":"Database read issues and OLAP analysis","body":"<p>I have to change my database engine, and I would know what guys do you think about it.\nActually, I have something like +10 millions rows and it's growing exponentialy mostly it's write and I have to analyse the data something like every hour or 2 would be great.</p>\n\n<p>For now we used MySQL but there's too much write on the master, so it's getting slow and crash somehow.</p>\n\n<p>thanks for your idea guys !</p>\n"},{"tags":["oracle","parent-child","hierarchy","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":69,"score":2,"question_id":12898369,"title":"Getting parent-child data into an Oracle level-based OLAP hierarchy","body":"<p>We have some organisational data which we need to represent in an Oracle OLAP 10g dimension, preferably populated using Warehouse Builder.</p>\n\n<p>The organisational hierarchy is listed as parent-child pairs, and is both ragged (unbalanced) and skip-level (noncovering). This would lend itself to a value-based hierarchy, but our client would rather we use ROLAP rather than MOLAP, i.e. avoid the use of an Analytical Workspace, which rules out the use of a value-based hierarchy.</p>\n\n<p>Is there a straightforward way to populate a level-based hierarchy using parent-child pair data, and if so how can it be done?</p>\n\n<p>Pointers to tutorials would be welcome, especially if they use Warehouse Builder.</p>\n"},{"tags":["sql-server","excel","olap","analysis-services","powerpivot"],"answer_count":6,"favorite_count":2,"up_vote_count":4,"down_vote_count":0,"view_count":909,"score":4,"question_id":2848471,"title":"Analysis Services with excel as front end - is it possible to get the nicer UI that powerpivot provides","body":"<p>I have been looking into PowerPivot and concluded that for \"self service BI\" and ahoc buidling of cubes it has its uses. In particular I like the enhanced UI that you get from using PowerPivot rather than just using a PivotTable hooked up to an analysis services datasource.</p>\n\n<p><strong>However</strong> it seems that hooking up PowerPivot to an existing analysis services cube is not a solution for \"organisational BI\". It is not always desireable to suck millions of rows into excel at once and the interface between PowerPivot and analysis services is very poor in my book.</p>\n\n<p><strong>Hence the question is</strong> can an existing analysis services solution get the enhanced ui features that power pivot brings, <strong>without</strong> using powerpivot as the design tool? If powerpivot is aimed at self service/personal BI then it seems bizare that the UI for this is better than for bigger/more costly analysis services solutions.</p>\n"},{"tags":["olap","adomd.net"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":363,"score":0,"question_id":1076449,"title":"Writing updates to OLAP cube","body":"<p>What is the easiest way to write user entered measure values (sales forcast) to the SQL Server Analysis Services OLAP cube from a .Net client application?</p>\n\n<p>I'm aware that underlying fact table can be updated with DML statements and that cube can be reprocessed but I'm looking for alternatives.</p>\n\n<p>Regards,\nAleksandar</p>\n"},{"tags":["sql-server","database-design","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":1937,"score":3,"question_id":420193,"title":"Process dimension fails with message \"A FileStore error from WriteFile occurred\"?","body":"<p>I am trying to <em>process</em> a <em>dimension</em> using <strong>SQL Server 2005 Analysis Services</strong>. This has worked in the past without problems but recently fails.</p>\n\n<p>The dimension is hierarchical using 4 columns from a single table (the entire cube uses a single table).</p>\n\n<p>The error message received (regardless if I process the entire cube or the dimension, whether I \"Process full\" or not) is this:</p>\n\n<pre><code>File system error: A FileStore error from WriteFile occurred. Physical file: \n\\\\?\\L:\\Microsoft SQL Server\\MSSQL.3\\OLAP\\Data\\MSMDCacheRowset_xxx.tmp.\nLogical file: . .\n</code></pre>\n\n<p>My guess is that this is related to the amount of growing data (currently 15 million rows in the specific table).</p>\n\n<ul>\n<li>It has worked before (no changes has been made)</li>\n<li>The processing reads 11 million rows before displaying the error</li>\n<li>Physical memory on the server runs out at the time the error is displayed</li>\n<li>Googling the error message results in a few hits indicating column size as a problem.</li>\n</ul>\n\n<p>Could anyone point me in the right direction? I guess that one way out could be to try using smaller columns (varchar(x) instead of varchar(y)) but it feels like going around the problem instead of solving the issue.</p>\n\n<p>Best regards<br />\nErik Larsson</p>\n"},{"tags":["olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":21,"score":1,"question_id":12761970,"title":"How to calculate lines per order in a cube","body":"<p>I cant think this one through, any help would be appreciated. I have a measure of the count of number of sales (distinct count of transaction numbers). Now what I'm looking for is the average number of lines per order.</p>\n\n<p>How can I calculate that in Analysis Server 2008 R2?</p>\n"},{"tags":["excel","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":46,"score":0,"question_id":12737763,"title":"MDX: Drillthough not filtering out rows","body":"<p>I have a drillthrough that I am building where I want to filter on two members of the same hierarchy:</p>\n\n<pre><code>    DRILLTHROUGH MAXROWS 1000 SELECT FROM \n(\n  SELECT (\n  { [Product].[Product Exclusion Reason].[Product Exclusion Reason].&amp;[6],[Product].[Product Exclusion Reason].[Product Exclusion Reason].&amp;[1] } ) ON COLUMNS\n  FROM [Sales]\n )\n WHERE ([Fiscal Date].[Yr-Qtr-Mo].[Year].&amp;[2013])\n</code></pre>\n\n<p>The sub-select does not seem to filter these rows out. If I instead add a critieria to the where clause:</p>\n\n<pre><code> DRILLTHROUGH MAXROWS 1000 SELECT FROM \n(\n  SELECT (\n  { [Product].[Product Exclusion Reason].[Product Exclusion Reason].&amp;[6],[Product].[Product Exclusion Reason].[Product Exclusion Reason].&amp;[1] } ) ON COLUMNS\n  FROM [Sales]\n )\n WHERE ([Fiscal Date].[Yr-Qtr-Mo].[Year].&amp;[2013],\n</code></pre>\n\n<p>[Product].[Product Exclusion Reason].[Product Exclusion Reason].&amp;[1])</p>\n\n<p>This will filter the data as expected. However, I want to include multiple members of <code>[Product].[Product Exclusion Reason].[Product Exclusion Reason]</code> in my filtering.</p>\n"},{"tags":["sql-server","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":109,"score":1,"question_id":8770553,"title":"mdx specification?","body":"<p>I'm looking for the formal specification of MDX. Going via xmla specification site, I found it may be in \"OLE DB for OLAP specification\" which is supposed to be available from microsoft, but I can't find it on their site anywhere.</p>\n\n<p>Any clues? I'm looking for the structure of MDX queries essentially.</p>\n"},{"tags":["ssas","mdx","olap","ssas-2008"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":82,"score":0,"question_id":12408437,"title":"Ordering by a generic calculated measure results in infinite recursion? (MDX)","body":"<p>I need to write a calculated measure that would show a share of <code>Measure1</code> comparing to the total sum by any given dimension. I managed to do it like this:</p>\n\n<pre><code>CREATE MEMBER CURRENTCUBE.[Measures].[Test] AS\n  [Measures].[Measure1] / ( AXIS( 1 ).ITEM( 0 ).DIMENSION.LEVELS( 0 ).ITEM( 0 ), [Measures].[Measure1] )\n</code></pre>\n\n<p>But due to the generic nature of <code>[Test]</code>, it is not possible to order a dimension by this measure.</p>\n\n<pre><code>SELECT [Measures].[Measure1] ON 0,\nORDER( [Dimension1].MEMBERS, [Measures].[Test] ) ON 1\nFROM [MyCube]\n</code></pre>\n\n<p>Executing the above code results in the following error:</p>\n\n<blockquote>\n  <p>Infinite recursion detected. The loop of dependencies is: Test -> Test.</p>\n</blockquote>\n\n<p>Which is rather logical â€” to get <code>AXIS( 1 ).ITEM( 0 )</code>, we need a set of dimension members on axis 1, but this set is impossible to obtain until the members are sorted by <code>[Test]</code>.</p>\n\n<p>On the other hand, if I define <code>[Test]</code> as specific to some dimension, it works as expected:</p>\n\n<pre><code>CREATE MEMBER CURRENTCUBE.[Measures].[Test] AS\n  [Measures].[Measure1] / ( [Dimension1].[All], [Measures].[Measure1] )\n</code></pre>\n\n<p>It works, because <code>[Dimension1].[All]</code> addresses a particular member, without requiring axis 1 to evaluate its member set first.</p>\n\n<p>Is there a way to make this calculated measure generic? Maybe, it's possible to get current dimension's <code>[All]</code> member in another way?</p>\n"},{"tags":["reporting-services","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":36,"score":0,"question_id":12647887,"title":"Need tips for optimizing OLAP cube for queries","body":"<p>We're designing an OLAP cube (I think it's currently SSAS 2008) with the following dimensions, and roughly the\nfollowing amount of data:</p>\n\n<ul>\n<li>Market (about 50)</li>\n<li>Station (about 25 per market)</li>\n<li>Period/year (about 75 periods)</li>\n<li>Advertiser (about 35,000 per market, classified into about 150 industries and sub-industries)</li>\n<li>Agency (about 9,000 per market)</li>\n<li>Account type (about 5)</li>\n<li>Revenue type (about 5; may end up being omitted from the cube)</li>\n<li>Account executive (about 25 per market)</li>\n</ul>\n\n<p>Each of the \"per market\" elements is associated with exactly one\nprimary market.  Some are also associated with one or more secondary\nmarkets (either subsets or supersets of primary markets).</p>\n\n<p>Measures are Revenue, RevenueYTD, PriorRevenue (same period prior\nyear), PriorRevenueYTD, plus several rank-related measures.</p>\n\n<p>The cube is sparse by advertiser and agency:</p>\n\n<ul>\n<li>About 80% of advertisers are only associated with one agency.</li>\n<li>Only about 5% of advertisers are associated with more than three agencies.</li>\n<li><p>Maximum agencies per advertiser is probably about 35.</p></li>\n<li><p>Elements with RevenueYTD = 0 will only exist if there was some prior-year revenue for the same set of non-time dimensions.</p></li>\n<li><p>We estimate that each combination of (market + station + year + period) will have at most about 2,000 elements, including at most about 1,000 advertisers and 1,000 agencies.</p></li>\n</ul>\n\n<p>All queries will come from Reporting Services (I think it's currently SSRS 2008), which will be driven\nby an ASP.NET form with a ReportViewer control.</p>\n\n<p>Most queries are filtered by market and period/year, compare revenue\nsums for one or more selected stations against revenue sums for the\nentire market, and sort by advertiser name or one of the revenue\nsums.  (Which stations varies by user.  Rank is only applicable when\nexactly one station is selected.)</p>\n\n<p>We need to optimize for query speed first (web users), processing speed\nsecond (each market's data is typically updated once per month by\ninternal users).</p>\n\n<p>Questions:</p>\n\n<ol>\n<li><p>What's the optimum way to define dimensions?  Currently, they're\n defined in the following order, one hierarchy per dimension:</p>\n\n<ol>\n<li>Market ID, Market Name, Minimum Stations YTD</li>\n<li>Station ID, Station Name</li>\n<li>Year, Year and Period, Period</li>\n<li>Industry ID, Industry Name, Sub Industry ID, Sub Industry Name, Advertiser ID, Advertiser Name</li>\n<li>Agency ID, Agency Name</li>\n<li>Account Type ID, Account Type Name</li>\n<li>Account Executive ID, Account Executive Name\n<br /><br /></li>\n</ol></li>\n<li><p>Given the dual nature of sums (selected stations vs. entire\n market), what's the optimum way to define aggregations?</p></li>\n<li><p>Can we do anything else to optimize the cube design? (We're already partitioning it by Market ID, as we need to update each market separately each month.)</p></li>\n</ol>\n"},{"tags":["olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":23,"score":0,"question_id":12635680,"title":"Olap Reports not working in Oracle database","body":"<p>I'm new to jasper. i have developed the Olap reports, it was working fine until i use Microsoft sql server database. when i create the same olap report with oracle data base it throws me the exception.</p>\n\n<pre><code>select sum(\"report_instance\".\"print_copies\") as \"m0\", sum(\"report_instance\".\"purge_days \") as \"m1\" from \"report_instance\" \"report_instance\"\n</code></pre>\n\n<p>when running the above query its not execute in oracle database. \"report_instance\".\"print_copies\" not accepted in oracle. if i give report_instance\".\"print_copies like this its executes.  why jasper internally appends the double quotes before table and column name. is it any setup change? what i need to do to fix this issue.</p>\n\n<p>Kindly do the needful. thanks in advance.\nError Message</p>\n\n<pre><code>com.jaspersoft.ji.ja.JasperAnalysisException: Internal error: Error while loading segment; sql=[select sum(\"report_instance\".\"print_copies\") as \"m0\", sum(\"report_instance\".\"purge_days \") as \"m1\" from \"report_instance\" \"report_instance\"]\n</code></pre>\n\n<p>Error Trace</p>\n\n<blockquote>\n  <p>com.jaspersoft.ji.ja.JasperAnalysisException: Internal error: Error while loading segment; sql=[select sum(\"report_instance\".\"print_copies\") as \"m0\", sum(\"report_instance\".\"purge_days \") as \"m1\" from \"report_instance\" \"report_instance\"] at mondrian.resource.MondrianResource$_Def0.ex_aroundBody3$advice(MondrianResource.java:101) at mondrian.resource.MondrianResource$_Def0.ex(MondrianResource.java:1) at mondrian.olap.Util.newInternal(Util.java:1490) at mondrian.olap.Util.newError(Util.java:1506) at mondrian.rolap.SqlStatement.handle(SqlStatement.java:277) at mondrian.rolap.SqlStatement.execute(SqlStatement.java:193) at mondrian.rolap.RolapUtil.executeQuery_aroundBody2(RolapUtil.java:230) at mondrian.rolap.RolapUtil.executeQuery_aroundBody3$advice(RolapUtil.java:150) at mondrian.rolap.RolapUtil.executeQuery(RolapUtil.java:1) at mondrian.rolap.RolapUtil.executeQuery_aroundBody0(RolapUtil.java:189) at mondrian.rolap.RolapUtil.executeQuery_aroundBody1$advice(RolapUtil.java:150) at mondrian.rolap.RolapUtil.executeQuery(RolapUtil.java:1) at mondrian.rolap.agg.SegmentLoader.createExecuteSql(SegmentLoader.java:381) at mondrian.rolap.agg.SegmentLoader.load(SegmentLoader.java:110) at mondrian.rolap.agg.Aggregation.load(Aggregation.java:172) at mondrian.rolap.agg.AggregationManager.loadAggregation(AggregationManager.java:96) at mondrian.rolap.FastBatchingCellReader$Batch.loadAggregation(FastBatchingCellReader.java:495) at mondrian.rolap.FastBatchingCellReader$Batch.loadAggregation(FastBatchingCellReader.java:430) at mondrian.rolap.FastBatchingCellReader.loadAggregation(FastBatchingCellReader.java:206) at mondrian.rolap.FastBatchingCellReader.loadAggregations(FastBatchingCellReader.java:187) at mondrian.rolap.RolapResult.executeBody(RolapResult.java:802) at mondrian.rolap.RolapResult.(RolapResult.java:416) at mondrian.rolap.RolapConnection.execute_aroundBody0(RolapConnection.java:593) at mondrian.rolap.RolapConnection.execute_aroundBody1$advice(RolapConnection.java:118) at mondrian.rolap.RolapConnection.execute(RolapConnection.java:1) at com.tonbeller.jpivot.mondrian.MondrianModel.getResult(MondrianModel.java:295) at com.tonbeller.jpivot.olap.model.OlapModelDecorator.getResult(OlapModelDecorator.java:56) at com.tonbeller.jpivot.olap.model.CachingOlapModel.getResult(CachingOlapModel.java:49) at com.tonbeller.jpivot.olap.model.OlapModelDecorator.getResult(OlapModelDecorator.java:56) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at javax.el.BeanELResolver.getValue(BeanELResolver.java:261) at javax.el.CompositeELResolver.getValue(CompositeELResolver.java:143) at com.sun.el.parser.AstValue.getValue(Unknown Source) at com.sun.el.ValueExpressionImpl.getValue(Unknown Source) at weblogic.servlet.jsp.ELHelper.evaluate(ELHelper.java:32) at jsp_servlet._web_45_inf._jsp._modules.<em>olap.</em>_viewolap.<em>jsp</em>_tag95(__viewolap.java:4495) at jsp_servlet._web_45_inf._jsp._modules.<em>olap.</em>_viewolap.<em>jspService(</em>_viewolap.java:625) at weblogic.servlet.jsp.JspBase.service(JspBase.java:34) at weblogic.servlet.internal.StubSecurityHelper$ServletServiceAction.run(StubSecurityHelper.java:227) at weblogic.servlet.internal.StubSecurityHelper.invokeServlet(StubSecurityHelper.java:125) at weblogic.servlet.internal.ServletStubImpl.execute(ServletStubImpl.java:300) at weblogic.servlet.internal.ServletStubImpl.onAddToMapException(ServletStubImpl.java:416) at weblogic.servlet.internal.ServletStubImpl.execute(ServletStubImpl.java:326) at weblogic.servlet.internal.TailFilter.doFilter(TailFilter.java:26) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at com.opensymphony.module.sitemesh.filter.PageFilter.parsePage(PageFilter.java:127) at com.opensymphony.module.sitemesh.filter.PageFilter.doFilter(PageFilter.java:56) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at weblogic.servlet.internal.RequestDispatcherImpl.invokeServlet(RequestDispatcherImpl.java:524) at weblogic.servlet.internal.RequestDispatcherImpl.forward(RequestDispatcherImpl.java:253) at org.springframework.web.servlet.view.InternalResourceView.renderMergedOutputModel(InternalResourceView.java:236) at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:257) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1183) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:902) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:807) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:571) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:501) at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) at javax.servlet.http.HttpServlet.service(HttpServlet.java:820) at weblogic.servlet.internal.StubSecurityHelper$ServletServiceAction.run(StubSecurityHelper.java:227) at weblogic.servlet.internal.StubSecurityHelper.invokeServlet(StubSecurityHelper.java:125) at weblogic.servlet.internal.ServletStubImpl.execute(ServletStubImpl.java:300) at weblogic.servlet.internal.TailFilter.doFilter(TailFilter.java:26) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at com.tonbeller.wcf.controller.RequestFilter$MyHandler.normalRequest(RequestFilter.java:158) at com.tonbeller.wcf.controller.RequestSynchronizer.handleRequest(RequestSynchronizer.java:129) at com.tonbeller.wcf.controller.RequestFilter.doFilter(RequestFilter.java:311) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:399) at com.jaspersoft.jasperserver.api.security.IPadSupportFilter.doFilter(IPadSupportFilter.java:67) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.api.security.JSSwitchUserProcessingFilter.doFilterHttp(JSSwitchUserProcessingFilter.java:154) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.intercept.web.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:109) at org.springframework.security.intercept.web.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:83) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.ui.ExceptionTranslationFilter.doFilterHttp(ExceptionTranslationFilter.java:101) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.ji.license.LicenseCheckFilter.doFilter(LicenseCheckFilter.java:108) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.ji.license.JILicenseFilter.doFilter(JILicenseFilter.java:96) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.providers.anonymous.AnonymousProcessingFilter.doFilterHttp(AnonymousProcessingFilter.java:105) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.api.metadata.user.service.impl.MetadataAuthenticationProcessingFilter.doFilter(MetadataAuthenticationProcessingFilter.java:139) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.war.util.RequestParameterAuthenticationFilter.doFilter(RequestParameterAuthenticationFilter.java:97) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.multipleTenancy.MTBasicProcessingFilter.doFilterHttp(MTBasicProcessingFilter.java:180) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.war.UserPreferencesFilter.doFilter(UserPreferencesFilter.java:184) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.ui.AbstractProcessingFilter.doFilterHttp(AbstractProcessingFilter.java:278) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.war.UserPreferencesFilter.doFilter(UserPreferencesFilter.java:184) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.api.logging.filter.BasicLoggingFilter.doFilter(BasicLoggingFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.api.security.JSCsrfGuardFilter.doFilter(JSCsrfGuardFilter.java:81) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.softeon.sso.SofteonSSOFilter.doFilter(SofteonSSOFilter.java:131) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.api.security.WebAppSecurityFilter.doFilter(WebAppSecurityFilter.java:83) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at com.jaspersoft.jasperserver.war.MultipartRequestWrapperFilter.doFilter(MultipartRequestWrapperFilter.java:90) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.context.HttpSessionContextIntegrationFilter.doFilterHttp(HttpSessionContextIntegrationFilter.java:235) at org.springframework.security.ui.SpringSecurityFilter.doFilter(SpringSecurityFilter.java:53) at org.springframework.security.util.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:411) at org.springframework.security.util.FilterChainProxy.doFilter(FilterChainProxy.java:188) at org.springframework.security.util.FilterToBeanProxy.doFilter(FilterToBeanProxy.java:99) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at com.jaspersoft.jasperserver.war.util.CharacterEncodingFilter.doFilter(CharacterEncodingFilter.java:67) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:236) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:167) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at com.jaspersoft.jasperserver.api.security.CrossScriptingFilter.doFilter(CrossScriptingFilter.java:49) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at weblogic.servlet.internal.RequestEventsFilter.doFilter(RequestEventsFilter.java:27) at weblogic.servlet.internal.FilterChainImpl.doFilter(FilterChainImpl.java:56) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.wrapRun(WebAppServletContext.java:3715) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.run(WebAppServletContext.java:3681) at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321) at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:120) at weblogic.servlet.internal.WebAppServletContext.securedExecute(WebAppServletContext.java:2277) at weblogic.servlet.internal.WebAppServletContext.execute(WebAppServletContext.java:2183) at weblogic.servlet.internal.ServletRequestImpl.run(ServletRequestImpl.java:1454) at weblogic.work.ExecuteThread.execute(ExecuteThread.java:209) at weblogic.work.ExecuteThread.run(ExecuteThread.java:178)</p>\n</blockquote>\n"},{"tags":[".net","ssas","data-warehouse","olap","performancepoint"],"answer_count":1,"favorite_count":2,"up_vote_count":2,"down_vote_count":0,"view_count":115,"score":2,"question_id":12248151,"title":"SSAS Controls with decomposition tree","body":"<p>I am currently working on an BI solution and I need to make some design decisions. We have already made the ELT process and have designed the cube in SSAS so now we need to present the data to the end user.</p>\n\n<p>The senario is as follows. We have the measures, KPIs and dimensions and we know what data we need to present to the End-User.</p>\n\n<p>An easy solution would be to use a Sharepoint server via PerfomancePoint-Dashboard designer which provides a decomposition tree amongst the OLAP controls it offers. The problem here is that we only need to show the data generated from the cube. There is no need for any of the collaboration and/or content management features of sharepoint.</p>\n\n<p>Another would be to make a new web application (WebForms for example) using one of the 3rd party olap tools for .Net! This I suppose would be simpler from a development point of view but no decomposition tree is a deal breaker for us.</p>\n\n<p>The most important question here is, if there are any olap Controls out there (3rd party or not) that include a decomposition tree.</p>\n\n<p>Is there any way (in the form of a library) to strip the OLAP controls from sharepoint and use them in a web forms project?</p>\n\n<p>Is it possible - and if it is, is it a proper practice - to strip the sharepoint site of any additional controls and leave only the dashboard surrounded by any theme we choose?</p>\n\n<p>How would you advise me to present the SSAS data to a client who is a simple user with little to none IT knowledge who just wants to view statistics and charts without needing/wanting to understand an entire new and complex environment?</p>\n"},{"tags":["data-warehouse","olap","pentaho","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":44,"score":0,"question_id":12566778,"title":"Impossible situation while doing OLAP","body":"<p>I have a normal star schema with about 5 dimension and 1 fact. It's about book rental store.</p>\n\n<p>When I'm analyzing using Pentaho Analyzer. I encoutered very weird situation that I think can't be happen. I dragged my 'Book Rent Count' measurement and drag 'Quarter' field from Date Dimension. It should be impossible to show duplicate 'Quarter' but it does :</p>\n\n<pre>\nQuarter        Book Rent Count\n1              1\n3              1\n4              2\n4              1\n4              1\n4              2\n</pre>\n\n<p>What condition should keep it to NOT group the Quarter 4? Be it a Q4 from different year it should group nicely.</p>\n\n<p>This happen with other field too. Something is keeping it from grouping. In the database I already have utf8_general_ci collation for each table.</p>\n\n<p>(This happen exactly the same when I tried using Saiku to analyze instead of Pentaho User Console.)</p>\n"},{"tags":["sql-server","olap","business-intelligence"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":1,"view_count":44,"score":0,"question_id":12556023,"title":"SSAS olap alternative","body":"<p>I'm currently using SQL Server where I have my data warehouse. I'd like to use this DW to create BI system but without SSAS. Basically i need olap server which is alternative to SSAS and where i can store data from SQL Server DW. Do you have any suggesctions?</p>\n"},{"tags":["olap","pentaho","mondrian"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":158,"score":0,"question_id":11792933,"title":"Can We show the string value as a measure on mondrian olap","body":"<p>I want to show the string value as one of the measure value. When a fact table has a integer value and string value respectively and also has some foreign table's keys. Then I could show the integer value as a measure value, but I couldn't show the string value as a measure. Because <a href=\"http://mondrian.pentaho.com/documentation/xml_schema.php#Measure\" rel=\"nofollow\">Measure element</a> in schema of cube (written in XML) doesn't allow that a measure value doesn't have 'aggregator'(It specify the aggregate function of measure values). Of course I understood that we can't aggregate some string values. But I want to show the string value of the latest level in hierarchy.</p>\n\n<p>I read following article. <a href=\"http://type-exit.org/adventures-with-open-source-bi/wp-content/uploads/2010/07/display_props.png\" rel=\"nofollow\">A figure</a> (around middle of this page) shows a cube that contains string value as a measure value. But this is an example of Property value of Dimension table, so this string value isn't contain in fact table. I want to show the string value that contains in fact table.</p>\n\n<p><a href=\"http://type-exit.org/adventures-with-open-source-bi/2010/07/a-simple-date-dimension-for-mondrian-cubes/\" rel=\"nofollow\">A Simple Date Dimension for Mondrian Cubes</a></p>\n\n<p>Anyone have some idea that can be shown the string value as a measure value? Or I have to edit Mondrian's source code?</p>\n"},{"tags":["java","olap"],"answer_count":4,"favorite_count":0,"up_vote_count":4,"down_vote_count":0,"view_count":1067,"score":4,"question_id":4510343,"title":"In memory OLAP engine in Java","body":"<p>Is there an in memory OLAP (slice and dice data) Java library.\n(The equivalent of Microsoft Analytic Services).\nEspecially would like to hear if anyone has used one for real.</p>\n"},{"tags":["stored-procedures","ssas","mdx","olap","ssas-2008"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":70,"score":0,"question_id":12511327,"title":"Creating a generic calculation (as a stored procedure?) in SSAS","body":"<h2>What I need</h2>\n\n<p>There are many-to-many relationships between dimensions <code>[D1]</code>, <code>[D2]</code>, <code>[D3]</code> and measure <code>[M]</code>.</p>\n\n<p>I need to create a generic calculated measure that would have the following formula: <code>[M] / Î£( [M] )</code>, where <code>Î£</code> stands for the sum of all measure's facts that are associated with at least one member of a given dimension.</p>\n\n<h2>What I've tried</h2>\n\n<p>It is possible to define <code>Î£( [M] )</code> as a calculated measure, using MDX:</p>\n\n<pre><code>CREATE HIDDEN [Total M] =\n  AGGREGATE(\n    DESCENDANTS(\n      AXIS( 1 ).ITEM( 0 ).DIMENSION.LEVELS( 0 ).ITEM( 0 ),\n      AXIS( 1 ).ITEM( 0 ).DIMENSION.LEVELS.COUNT\n    ) - AXIS( 1 ).ITEM( 0 ).DIMENSION.LEVELS( 0 ).ITEM( 0 ),\n    [Measures].[M]\n  );\n</code></pre>\n\n<p>I have to aggregate over all members, except the <code>[All]</code> member. But this solution works. <sup>(If I don't exclude <code>[All]</code>, the total value of <code>[M]</code> in the cube is returned, because I'm not slicing by this dimension. And also because the relationship is many-to-many.)</sup></p>\n\n<p>Using <code>AXIS( 1 )</code> makes the measure generic, being able to work with any of the \"many-to-many\" dimensions. <sub>(Actually, I use <code>AXIS( [DimInd] )</code>, where <code>[DimInd]</code> is a measure I wrote that returns the index of the first axis that contains a dimension).</sub></p>\n\n<p>Now I can define my desired measure:</p>\n\n<pre><code>CREATE MEMBER CURRENTCUBE.[Measures].[Share of M] AS\n  [Measures].[M] / [Measures].[Total M]\n</code></pre>\n\n<p>But the generic nature of it has downsides as well. For example, the following query fails because of infinite recursion:</p>\n\n<pre><code>SELECT [Measures].[Share of M] ON 0,\nORDER( [D1].MEMBERS, [Measures].[Share of M] ) ON 1\nFROM [MyCube]\n</code></pre>\n\n<p>Which is actually logical â€” to get <code>AXIS( 1 ).ITEM( 0 )</code> in <code>[Total M]</code>, SSAS needs to first get a set of members on axis 1, but this set is impossible to obtain until the members are sorted by <code>[Share of M]</code>. It is a circular dependency.</p>\n\n<p>This example shows that this generic measure can only be used in very simple queries. In real life, it is as good as useless.</p>\n\n<h2>What to do?</h2>\n\n<p>Maybe there is a way of implementing this using MDX, but I really don't see it. Please give me an advice in case you know of a solution.</p>\n\n<p>Another direction I want to try is writing a stored procedure, which would perform all needed calculations in a generic way. But I'm stuck on that route as well.</p>\n\n<p>Can I, in my stored procedure, somehow find out which dimension is currently being used (similarly to <code>AXIS( 1 )</code>)?</p>\n"},{"tags":["architecture","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":38,"score":0,"question_id":12499025,"title":"olap cubes architecture - how many olap cubes?","body":"<p>I am working on a project, where there are a couple of BIG cubes. The used technology is SSAS. We have hundreds of reports and lot of calculations is in report definition. I do not think it is correct way do calculations in reports. It adds complexity to testing. I think that better solution is doing calculations in OLAP. But developers complain that MDX query would run years as the cube will became bigger and more complex. My idea is to have lot of small cubes and do calculations in them.</p>\n\n<p>Is it good idea? Do you have another ideas how to decrease complexity of testing of values in reports?</p>\n"},{"tags":["olap","olap-cube","mondrian","rolap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":26,"score":0,"question_id":12492321,"title":"Mondrian single cell value query","body":"<p>I'm wondering if there is a way to in mondrian execute a SQL query for every cell data based on what is chosen on the dimensions withouth a fact table.</p>\n\n<p>To clarify,<br>\nlets say we have a fact table consisting of companyId's and values(the measure) and a dimension table with companyId's and companyNames.\nUsusally what happens is:<br>\n1. A couple of companies are chosen from the dimensiontable.<br>\n2. The selected companies are joined with the fact table.<br>\n3. Each cell will correspond to one point and the selected measure is represented.</p>\n\n<p>What I want to do is:<br>\n1. A couple of companies are chosen from the dimension table.<br>\n2. A SQL query is generated and executed for every selected row in the dimension table.<br>\n3. Each cell will represent it's correspond query result as it's measure.<br></p>\n\n<p>The documentation mentions something called a \"cell reader\", is this what I'm looking for?\nIn that case, since it doesn't seem to be implemented, does there exist another solution?</p>\n\n<p>//Tanks in advance</p>\n"},{"tags":["metadata","ssas","olap","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":39,"score":0,"question_id":12473201,"title":"Error Loading metadata in visual studio","body":"<p>Error loading metadata: The 'My Cube Name' cube could not be retrieved from the server . Verify that the server is running and that the cube is processed. </p>\n\n<p>I am getting the same error message after proces and deploying the cube....</p>\n\n<p>Any ideas......</p>\n"},{"tags":["real-time","olap","snapshot","activepivot"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":67,"score":1,"question_id":12409841,"title":"Real-time, incremental snapshots of OLAP cubes with ActivePivot","body":"<p>We are using the ActivePivot in-memory analytics solution (version 4.2.6) to aggregate financial trades in real-time.</p>\n\n<p>The server is started the morning with a stock of about one billion trades, and intraday we record about 10 million updates. Updates are submited to the cube in real-time, and can be new trades or modifications to existing trades.</p>\n\n<p>Out of the box ou architecture solves our main (but conflicting ;) ) requirements:</p>\n\n<ul>\n<li>OLAP intuitive navigation</li>\n<li>High performance, sub-second queries (in-memory engine)</li>\n<li>Pauseless, continuous data updates</li>\n</ul>\n\n<p>So the ActivePivot cube always reflects the current state, including all updates, but like a time machine we would like to be able to go back to a previous state of our system. Ideally we would like not to limit ourselves to look at our cube \"as it was 10:15 this morning\", but also be able to have the system timeline as a dimension (ultimately to draw the intraday changes of a range of aggregates, in ActivePivot Live).</p>\n\n<p>Can you share best practices to implement this kind of incremental snapshotting?</p>\n"},{"tags":["java","aggregate","olap","activepivot"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":92,"score":1,"question_id":12408950,"title":"real-time, cross-currency OLAP aggregation with ActivePivot","body":"<p>We are using the ActivePivot in-memory analytics solution (version 4.2.6) to aggregate financial trades in real-time.</p>\n\n<p>We have setup an OLAP cube with about a hundred dimensions, one of those dimensions is the currency of the trade. Each trade comes with a notional amount (number) that is expressed in the trade currency.</p>\n\n<p>Of course it makes no sense to aggregate two numbers expressed in different currencies. So when we browse our cube in Excel or ActivePivot Live,  we always have the currency dimension expanded on one of the axis, otherwise totals are meaningless.</p>\n\n<p>We would like to extend the basic aggregation in ActivePivot with on the fly FX rate conversions, to provide meaningful totals in one (user defined) currency. We don't want to convert amounts before feeding the cube because the trades are submitted in real-time during the day, and the FX rates change in real-time too. We don't want a static table of currency rates either, for the same reason. We already have some internal FX Service than can be called in real-time.</p>\n\n<p>What is the common way to do that with ActivePivot?</p>\n"},{"tags":["scope","ssas","mdx","olap","ssas-2008"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":106,"score":0,"question_id":12409612,"title":"How to correctly replace value of ( [Some Dimension].[All], [Some Measure] )? (MDX, SCOPE())","body":"<p>I'm using SQL Server Analysis Servises 2008 R2.</p>\n\n<p>I need<sup>1</sup> to replace the value of <code>[Some Dimension].[All]</code> when calculated against <code>[Some Measure]</code>. Here's what I have tried:</p>\n\n<pre><code>SCOPE( [Some Dimension].[All] );\n  [Measures].[Some Measure] = 123; // for simplicity sake\nEND SCOPE;\n</code></pre>\n\n<p>This works as expected when I query against <code>[Some Dimension]</code> â€“ the <code>[All]</code> member returns <code>123</code>, and other members are untouched, showing the actual associated <code>[Some Measure]</code> values.</p>\n\n<p>But for some strange reason, all of the members in all other dimensions now return <code>123</code> for <code>[Some Measure]</code>. I am really lost. Please advice me how to fix this, and why this is happening.</p>\n\n<p><sup>1</sup> <sub><em>For the ones who are curious:</em> the reason I want to replace the value of <code>[All]</code> is because <code>[Some Dimension]</code> and <code>[Some Measure]</code> are related as many-to-many. Because of this, tuple <code>( [Some Dimension].[All], [Some Measure] )</code> always returns the total count for <code>[Some Measure]</code> in the cube. What I <em>want</em> it to return is the count of <code>[Some Measure]</code> that are actually associated with at least one member of <code>[Some Dimension]</code></sub>.</p>\n"},{"tags":["python","olap","pandas","pytables","cubes"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":119,"score":0,"question_id":12425602,"title":"Python package recommendation for data analysis and learning","body":"<p>I want to build an analytics engine on top of an article publishing platform. More specifically, I want to track the users' reading behaviour (e.g. number of views of an article, time spent with the article open, rating, etc), as well as statistics on the articles themselves (e.g. number of paragraphs, author, etc).</p>\n\n<p>This will have two purposes:</p>\n\n<ol>\n<li>Present insights about users and articles</li>\n<li>Provide recommendations to users</li>\n</ol>\n\n<p>For the data analysis part I've been looking at <a href=\"http://packages.python.org/cubes/\" rel=\"nofollow\">cubes</a>, <a href=\"http://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> and <a href=\"http://www.pytables.org/moin\" rel=\"nofollow\">pytables</a>. There is a lot of data, and it is stored in MySQL tables; I'm not sure which of these packages would better handle such a backend.</p>\n\n<p>For the recommendation part, I'm simply thinking about feeding data from the data analysis engine to a clustering model.</p>\n\n<p>Any recommendations about how to put all this together, as well as cool python projects out there that can help me out?\nPlease let me know if I should give more information.</p>\n\n<p>Thank you</p>\n"},{"tags":["olap","hbase"],"answer_count":3,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1495,"score":1,"question_id":2516857,"title":"Hbase schema design -- to make sorting easy?","body":"<p>I have 1M words in my dictionary. Whenever a user issue a query on my website, I will see if the query contains the words in my dictionary and increment the counter corresponding to them individually. Here is the example, say if a user type in \"Obama is a president\" and \"Obama\" and \"president\" are in my dictionary, then I should increment the counter by 1 for \"Obama\" and \"president\".</p>\n\n<p>And from time to time, I want to see the top 100 words (most queried words). If I use Hbase to store the counter, what schema should I use? -- I have not come up an efficient one yet.</p>\n\n<p>If I use word in my dictionary as row key, and \"counter\" as column key, then updating counter(increment) is very efficient. But it's very hard to sort and return the top 100.</p>\n\n<p>Anyone can give a good advice? Thanks.</p>\n"},{"tags":["php","mysql","jdbc","olap","mondrian"],"answer_count":1,"favorite_count":2,"up_vote_count":6,"down_vote_count":0,"view_count":133,"score":6,"question_id":12369793,"title":"Connecting to Database Cube that uses MySQL database from PHP (using JDBC)","body":"<p>My database team has set up a database Cube using MySQL database. I need to connect to this Cube from PHP and get the data using MDX queries.</p>\n\n<p>I can't find how to do that. Could someone please help me with this ASAP?</p>\n\n<p>Reference document :- <a href=\"http://www.scribd.com/doc/2569392/Creating-Interactive-OLAP-Applications-with-MySQL-Enterprise-and-Mondrian\"> Creating Interactive OLAPApplications with MySQLEnterprise and Mondrian</a></p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":21,"score":0,"question_id":12349765,"title":"How to reuse process result of fixed data","body":"<p>In a financial system, transactions of every year is stored in a separate table. So, there are Transactions2007, Transactions2008, ..., Transactions2012 tables in the system. They all have the same table design. The data in tables of previous years never change. But current years data is updated in a daily manner.\nI want to build a cube on the union of tables of all years. The question is how to prevent SSAS from reprocessing previous years.</p>\n"},{"tags":["sql-server","olap","cube","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":166,"score":0,"question_id":12256367,"title":"Cube project doesn't work because of permissions","body":"<p>I'm doing \"Multidimensional Project\" with MS SQL Server 2012 (Server Data Tools - Visual Studio 2010 Shell).  I can't run (debug) it.</p>\n\n<p>If the data source's impersonation information is set to \"use the service account\", this error occures:</p>\n\n<blockquote>\n  <p>Error 2   Internal error: The operation terminated unsuccessfully.        0   0   </p>\n  \n  <p>Error 3   OLE DB error: OLE DB or ODBC error: Login failed for user 'NT Service\\MSSQLServerOLAPService'.; 28000.      0   0   </p>\n  \n  <p>Error 4   Errors in the high-level relational engine. A connection could not be made to the data source with the DataSourceID of 'Data Warehouse', Name of 'Data Warehouse'.      0   0   </p>\n  \n  <p>Error 5   Errors in the OLAP storage engine: An error occurred while the dimension, with the ID of 'Items', Name of 'Items' was being processed.      0   0   </p>\n  \n  <p>Error 6   Errors in the OLAP storage engine: An error occurred while the 'Id' attribute of the 'Items' dimension from the 'Warehouse_MultidimensionalProject_Cube' database was being processed.      0   0<br>\n  Error 7   Server: The current operation was cancelled because another operation in the transaction failed.        0   0   </p>\n</blockquote>\n\n<p>I guessed that this account has no premissions but (1) I coudn't even add this account (it seems that it doesn't exist) and (2) how is that even possible for it to not have built-it poremissions?</p>\n\n<p>When I'm setting impersonation to \"use the credentials of current user\" (which is the owner of the data source, btw.), another error occures:</p>\n\n<blockquote>\n  <p>Error 2   Internal error: The operation terminated unsuccessfully.        0   0   </p>\n  \n  <p>Error 3   The datasource, 'Data Warehouse', contains an ImpersonationMode that is not supported for processing operations.        0   0   </p>\n  \n  <p>Error 4   Errors in the high-level relational engine. A connection could not be made to the data source with the DataSourceID of 'Data Warehouse', Name of 'Data Warehouse'.      0   0   </p>\n  \n  <p>Error 5   Errors in the OLAP storage engine: An error occurred while the dimension, with the ID of 'Items', Name of 'Items' was being processed.      0   0   </p>\n  \n  <p>Error 6   Errors in the OLAP storage engine: An error occurred while the 'Id' attribute of the 'Items' dimension from the 'Warehouse_MultidimensionalProject_Cube' database was being processed.      0   0   </p>\n  \n  <p>Error 7   Server: The current operation was cancelled because another operation in the transaction failed.        0   0   </p>\n</blockquote>\n\n<p>Any help?</p>\n"},{"tags":["olap","execute","mondrian"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":47,"score":0,"question_id":12202000,"title":"mondrian.olap.Connection.execute(Query arg0) is depreceated","body":"<p>I am trying to build a webservice on top of mondrian API.\nThe service would expose a REST API which would get a mdx query, execute it and return a json.\nI have built the web service but stuck with a problem. The MDX query execute function of mondrian </p>\n\n<pre><code>mondrian.olap.Connection.execute(Query arg0) \n</code></pre>\n\n<p>is depreceated.</p>\n\n<p>Would this cause any problem later on ? Or is there any other function with the same functionality.</p>\n\n<p>Thanks.</p>\n"},{"tags":["olap","pentaho","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":67,"score":0,"question_id":12209435,"title":"How to install pentaho mondrian OLAP server?","body":"<p>I want to install the OLAP pentaho server for the purpose of reports generation. I tried with the installation of pentaho Mondrian but, It was failed. I need help from somebody to do this installation and configuration.</p>\n"},{"tags":["mdx","olap","measure","iccube"],"answer_count":1,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":50,"score":3,"question_id":12141134,"title":"How do I create custom rollup types in icCube?","body":"<p>How do I create custom rollup types in icCube?</p>\n\n<p>Say, I need WAvg (which is already implemplemented there) instead of plain Avg function. But I it is not on the dropdown list in measure creation form. What should I do now?</p>\n"},{"tags":["query","ssas","mdx","olap","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":107,"score":0,"question_id":11969988,"title":"Aggregating MDX query results on existing facts only","body":"<p>I am very new to MDX, so probably I'm missing something very simple.</p>\n\n<p>In my cube, I have a dimension <code>[Asset]</code> and a measure <code>[Visits]</code>, calculating (in this case) how many visits an asset has been consumed by. An important thing to note is that not every visit is associated with an asset.</p>\n\n<p>What I need to find out is how many visits there are that consumed at least one asset. I wrote the following query:</p>\n\n<pre><code>SELECT\n  [Asset].[All] ON COLUMNS,\n  [Measures].[Visits] ON ROWS\nFROM\n  [Analytics]\n</code></pre>\n\n<p>But this query just returns the total number of visits in the cube. I tried applying the <code>NON EMPTY</code> modifier to both axes, but that doesn't help.</p>\n"},{"tags":["query","ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":117,"score":0,"question_id":12051735,"title":"Slicing inside of a calculated measure defintion? (MDX)","body":"<p>I have a many-to-many relationship between dimension D and measure M.</p>\n\n<p>I need to create a generic calculated measure that would have the following formula: M/Î£(M), where Î£ stands for the sum of all measure's facts that are associated with at least one member of a given dimension.</p>\n\n<p>It's easy for other (one-to-many) dimensions, but getting Î£ in many-to-many... well, if it was just a regular MDX query, that would be easy as well. I could just slice on all children of a dimension:</p>\n\n<pre><code>SELECT [Measures].[M] ON 0\nFROM [MyCube]\nWHERE [D].[All].CHILDREN\n</code></pre>\n\n<p>But how do I slice in a calculated measure?</p>\n\n<p>A simplified example of what I would <em>expect</em> to work:</p>\n\n<pre><code>CREATE MEMBER [Measures].[Calc] AS\n  [Measures].[M] / ( DRILLUPLEVEL( AXIS( 1 ).ITEM( 0 ).HIERARCHY.MEMBERS ).ITEM( 0 ), [Measures].[M] )\n  WHERE DRILLUPLEVEL( AXIS( 1 ).ITEM( 0 ).HIERARCHY.MEMBERS ).ITEM( 0 ).CHILDREN\n</code></pre>\n\n<p>But of course, MDX doesn't support a <code>WHERE</code> clause in <code>MEMBER</code> definitions.</p>\n\n<p>Please advise me how to approach this.</p>\n"},{"tags":["oracle","cursor","dry","olap"],"answer_count":0,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":47,"score":1,"question_id":12091057,"title":"Generalising Oracle Static Cursors","body":"<p>I am creating an OLAP-like package in Oracle where you call a main, controlling function that assembles its returning output table by making numerous left joins. These joined tables are defined in 'slave' functions within the package, which return specific subsets using static cursors, parameterised by the function's arguments. The thing is, these cursors are all very similar.</p>\n\n<p>Is there a way, beyond generating dynamic queries and using them in a <code>ref cursor</code>, that I can generalise these. Every time I add a function, I get this weird feeling, as a developer, that this isn't particularly elegant!</p>\n\n<hr>\n\n<p>Pseduocode</p>\n\n<pre><code>somePackage\n  function go(param)\n    return select    myRows.id,\n                     stats1.value,\n                     stats2.value\n           from      myRows\n           left join table(somePackage.stats1(param)) stats1\n           on        stats1.id = myRows.id\n           left join table(somePackage.stats2(param)) stats2\n           on        stats2.id = myRows.id\n\n  function stats1(param)\n    return [RESULTS OF SOME QUERY]\n\n  function stats2(param)\n    return [RESULTS OF A RELATED QUERY]\n</code></pre>\n\n<p>The <code>stats</code> queries all have the same structure:</p>\n\n<ul>\n<li>First they aggregate the data in a useful way</li>\n<li>Then they split this data into logical sections, based on criteria, and aggregate again (e.g., by department, by region, etc.) then union the results</li>\n<li>Then they return the results, cast into the relevant <code>object</code> type, so I can easily do a <code>bulk collect</code></li>\n</ul>\n\n<p>Something like:</p>\n\n<pre><code>cursor myCursor is\n  with fullData as (\n    [AGGREGATE DATA]\n  ),\n  fullStats as (\n    [AGGREGATE FULLDATA BY TOWN]\n    union all\n    [AGGREGATE FULLDATA BY REGION]\n    union all\n    [AGGREGATE FULLDATA BY COUNTRY]\n  )\n  select myObjectType(fullStats.*)\n  from   fullStats;\n\n...\n\nopen myCursor;\nfetch myCursor bulk collect into output limit 1000;\nclose myCursor;\n\nreturn output;\n</code></pre>\n"},{"tags":["architecture","olap","business-intelligence"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":1,"view_count":38,"score":-1,"question_id":12076093,"title":"Multi OLAP architecture","body":"<p>I've read about some virtual cubes, currency cubes, control cubes. I met some of these on some projects. In fact, it was very interesting and enlightening for me to see couple of reporting cubes and lot of supporting cubes in some OLAP architectures. But I only \"touch the surface.\"</p>\n\n<p>Unfortunately, i am now on long term project, where architecture is quite messy, so I cannot learn about good OLAP solutions by practice. Are there some good and actual study materials or best practices for building good OLAP architectures?</p>\n\n<p>Aims: Performance, easy maintenance of big solutions</p>\n"},{"tags":["ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":198,"score":0,"question_id":12059409,"title":"Creating NON ADDITIVE Measures in SSAS Cube with \"No Aggregation\"","body":"<p>Have an issue with creating NON ADDITIVE Measure in SSAS Cube.</p>\n\n<p>Even though the NON ADDITIVE measure is categorised under \"NO AGGREGATIONS\" and a Degenerative Fact Table created only with the KEY , no results are being shown in the Cube.</p>\n\n<p>However once the categorisation is put to \"SUM\" values are displayed along with a GRAND TOTAL.\nThis looks fine theoratically, but since the field is supposed to be NON ADDITIVE in nature this is wrong.</p>\n\n<p>Any suggestion to display the values along side the KEY, while putting the field categorisation under  \"NO AGGREGATIONS\" .Help would be greatly appreciated.</p>\n\n<p>Thankyou</p>\n"},{"tags":["asp.net","sql-server-2005","reporting-services","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":5,"down_vote_count":0,"view_count":611,"score":5,"question_id":10513342,"title":"Display an OLAP SQL Server in a web page?","body":"<p>I have this scenario:</p>\n\n<p>WServer 2008, SQL Server 2005, MS Analysis services (SSAS), ISS7 and a OLAP CUBE.</p>\n\n<p>I need to <strong>embed the OLAP result</strong> in a webpage in an existing site.</p>\n\n<p><strong>I don't need any</strong> selection of dimension, no any drill down, no any 3 dimension, just a passive result of a preset MDX query.</p>\n\n<p>Below here an example of MDX query used: <strong>(Sell statistic for an agent in a period)</strong></p>\n\n<pre><code>SELECT NON EMPTY { [Measures].[Valore] } ON COLUMNS,\n    NON EMPTY { ([Prodotti].[Top Marca].[Top Marca].ALLMEMBERS * [Calendario].[Anno -  Mese].[Mese].ALLMEMBERS * [Agenti].[Cod Agente].[Cod Agente].ALLMEMBERS ) }\n    DIMENSION PROPERTIES MEMBER_CAPTION, MEMBER_UNIQUE_NAME ON ROWS FROM ( SELECT ( { [Calendario].[Anno].&amp;[2012] } ) ON COLUMNS \n    FROM ( SELECT ( { [Agenti].[Vw Agenti].&amp;[005] } ) ON COLUMNS FROM [Vendite])) \n    CELL PROPERTIES VALUE, BACK_COLOR, FORE_COLOR, FORMATTED_VALUE, FORMAT_STRING, FONT_NAME, FONT_SIZE, FONT_FLAGS\n</code></pre>\n\n<p>Below an easy result that i need to show in the website:</p>\n\n<p><img src=\"http://i.stack.imgur.com/5f95X.jpg\" alt=\"olap result\"></p>\n\n<p>I tried to use Report Viewer but seem I can't due this error:</p>\n\n<blockquote>\n  <p>Remote report processing requires Microsoft SQL Server 2008 Reporting Services or later</p>\n</blockquote>\n\n<p>and I can't install SQL Server 2008 so I need an alternative solution.</p>\n\n<p>I tried some open source but they need install JAVA and more, most also not connect to SQL Server or required a different web server.</p>\n\n<p>I tried also use a TSQL query but it return only 1 column for the months when in real i need many columns as months calculated</p>\n\n<p><em>NOTE: the users are many with many different operating system and browser as iPad, Mac, Windows, Linux, ... so the result must be an HTML output</em></p>\n\n<p><strong>So my question is:</strong></p>\n\n<p>What is the best way to develop a simple webpage (asp or aspx) (server side or client side) to query the cube to get a simple result <strong>(must be HTML)</strong> as show above, without any selection by the user ?</p>\n\n<p>Or what didn't I understand at all with this scenario ?</p>\n\n<p>Thanks in advance for who can help me!</p>\n"},{"tags":["mysql","olap","d3.js","mondrian"],"answer_count":1,"favorite_count":2,"up_vote_count":0,"down_vote_count":0,"view_count":267,"score":0,"question_id":9773809,"title":"How to generate a JSON file from Mondrian output","body":"<p>I am new to Mondrian. I am using it in my project for OLAP operations. \n    I am testing it with Foodmart database. \n    The problem is that I need the OLAP operations results in JSON format. \n    I know that mondrian has the same structure as JSON in the form of hierarchies. \n    I want to generate a JSON file as an output from the result of mondrian MDX query. \n    The result should be similar to OLAP operations. \n    I don't know how to iterate over the result generated from MDX query. \n    Here is the code.</p>\n\n<pre><code>String connStr =   \"Provider=mondrian;\" +\n                    \"Catalog=/WEB-INF/FoodMart.xml;\" +\n                    \"JdbcDrivers=com.mysql.jdbc.Driver;\" +\n                    \"Jdbc=jdbc:mysql://localhost/foodmart;\" +\n                    \"jdbcUser=root;\" +\n                    \"jdbcPassword=;\";\n\nString queryStr =\"select {[Measures].[Unit Sales], [Measures].[Store Cost], [Measures].&gt;Store Sales]} ON COLUMNS,\"+\"Crossjoin(Hierarchize(Union({[Promotion Media].[All Media]}, &gt;[Promotion Media].[All Media].Children)), {[Product].[All Products]})\nON ROWS\"+\" from [Sales]\"+\"where [Time].[1997]\";\n\nConnection connection = DriverManager.getConnection(connStr, null);        \nQuery query = connection.parseQuery(queryStr);\n\nResult result = connection.execute(query);\nresult.print(new PrintWriter(System.out));\n</code></pre>\n\n<p>Actually I need to perform OLAP operations on data warehouse which is stored in MySQL. \nThe resulted data should be in JSON format which I will pass to  D3 <a href=\"http://mbostock.github.com/d3\" rel=\"nofollow\">http://mbostock.github.com/d3</a> for visualizations. \nFor data format I have to use JSON format. \nPlease any suggestions how to iterate MDX result and convert it in JSON file. \nI am using Pentaho Mondrian for this purpose.\nThanks.</p>\n"},{"tags":["java","mysql","reporting","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":586,"score":0,"question_id":10586660,"title":"MySQL reporting engine like excel pivot tables or SQL reporting manager","body":"<p>I have several fact tables and need engine to generate reports based on them. Excel could do it but I need to be able to:</p>\n\n<ul>\n<li>Publish report on the web (it should query data each time it requested)</li>\n<li>Make it configurable. i.e: I should be able to use variables provided by user</li>\n</ul>\n\n<p>SQL Reporting Services could do it but I use java/mysql and need MySQL solution. </p>\n\n<p>So it should work like that:</p>\n\n<ul>\n<li>User asks me for report</li>\n<li>I write code that creates fact tables periodically</li>\n<li>I create report using GUI or some kind of \"OLAP query language\" like MDX</li>\n<li>User looks at this report configuring and filtering it like \"show only this country\" or \"only rows where this column > 15\"</li>\n</ul>\n\n<p>Do you know any?</p>\n\n<p>Thanks</p>\n"},{"tags":["sql-server-2008-r2","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":246,"score":1,"question_id":11899250,"title":"How to determine which SSAS Cube is processing now?","body":"<p>There is a problem when several users can process the same cube simultaniously and as a result processing of cube fails. So I need to check if certain cube is processing at current moment.</p>\n"},{"tags":["ssas","mdx","analysis","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":54,"score":0,"question_id":11988157,"title":"Filling a drop down list box with member properties using MDX query","body":"<p>I am new to SSAS, How can i fill a drop drown list box with the member properties using MDX query? eg i want only the member properties of Fiscal Year to apper in the box. Thank you.</p>\n"},{"tags":["sql-server","sql-server-2008","olap","powerpivot"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":91,"score":1,"question_id":11727179,"title":"Self Joining a Table in Power Pivot","body":"<p>I would like to know whether Excel Power Pivot can handle a self join on a table. This is to derive parent child relationships from the data (I know this could be done in SSAS).</p>\n\n<p>For example consider the following:</p>\n\n<pre><code>ID  Level         Individual       ImmediateParent\n2   son            Tom               3\n3   father         John              4\n4   grandpa        Lee               5\n5   great grandpa  Sam               6\n6   root           Root\n</code></pre>\n\n<p>I would like Power Pivot, when producing the pivot table, to show only one raw when called for the level, for example son, and all the others to be contained with in it to drill-down and look.    </p>\n"},{"tags":["java","charts","olap"],"answer_count":7,"favorite_count":3,"up_vote_count":2,"down_vote_count":0,"view_count":1301,"score":2,"question_id":412695,"title":"Java Chart library for OLAP","body":"<p>Is there any java chart library that supports OLAP data, like \n<a href=\"http://www.softwarefx.com/Extensions/filmsLarge.aspx?movieName=olapAxesLarge&amp;movieWidth=749&amp;movieHeight=565\" rel=\"nofollow\">ChartFX Olap</a> or <a href=\"http://www.dundas.com/Gallery/Chart/NET/index.aspx?Img=OLAP6\" rel=\"nofollow\">Dundas Chart</a> ?</p>\n\n<p>Thanks</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":42,"score":0,"question_id":11969773,"title":"SSAS fill missing gaps","body":"<p>lets say I have a fact table like this:</p>\n\n<pre><code>ID  Date      Amount\n1   Jan2012    100\n1   Feb2012    110\n1   April2012  150\n</code></pre>\n\n<p>and a dimension dimDate that contains all months in 2012.</p>\n\n<p>When browsing my cube I see exactly what's above, but I would like to see one row to all dates on the dimDate dimension but, whats more important, I would like to see the March2012 row with the value 110 (last available value)</p>\n\n<p>Is it something that can be done on the cube? I know it can be done on the DW by inserting a row for april or maybe with a left join query but I want to know if it can be done on the cube</p>\n"},{"tags":["ssas","data-mining","olap","ssas-2008"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":53,"score":0,"question_id":11962970,"title":"Should I take a relational or multidimensional/ OLAP approach to a stock market historical analysis project?","body":"<p>this isn't a syntax/ coding specific question per se, but I'm unable to find any real articles online of any significance that speak to it directly. As I begin to delve into data mining using Sql Server Analysis Services (2008R2), I am wondering if I should be taking a relational data approach (as my data currently exists) or begin with an OLAP model. I am studying daily stock market data on 5,000 symbols. This translates to 12 tables or so, low millions of rows each. At my basic, current understanding, OLAP seems like an extra layer of complexity added that I don't see justified. Any thoughts?</p>\n"},{"tags":["crystal-reports","connection","database-connection","olap","xmla"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":140,"score":0,"question_id":11846290,"title":"Crystal Reports against OLAP / XMLA / SimbaO2X-server","body":"<p>I'm trying to convert some old Excel-reports to Crystal Reports. The excel sheets uses OLAP-cubes and connects to a database using a XMLA connection over a SimbaO2X driver.\nI just can't figure out which connection settings to use in Crystal Reports to be able to connect to the database.<br>\nI've tried both XML and OLAP connections, but just can't get a database connection.</p>\n\n<p>Any help with the connection setting would be appreciated!</p>\n\n<p><strong>Edit:</strong> The database is a bit of a black box; it's <em>probably</em> an Oracle database (it was an Oracle database before the end user frontend was rewritten in java. They could have changed the database as well.) I have however no success with neither the Oracle Server nor the Microsoft OLE DB for Oracle connection method.  </p>\n\n<p>I have also this morning found a SimbaO2X provider under the OLE DB folder. While not working it's the best so far -- it accepts the username and password and lets me select which database to connect to but then fails with ADO Error Code: 0x80040e73 (Format of the initialization string does not conform to the OLE DB specification.) At least I have something to go on.</p>\n\n<p>I'm running Crystal Reports XI if someone needs to know.</p>\n"},{"tags":["database","microsoft","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":61,"score":0,"question_id":11831350,"title":"How is technically resolved SSAS OLAP cube?","body":"<p>i am new to SSAS platform. I am curious about how it is technically solved.</p>\n\n<p>I heard that SQL query is not working on this OLAP (MOLAP). Is it true?</p>\n\n<p>I imagined that it is in technical way just some standard DB table of facts with links to dimension DB tables. Am I wrong? Where are that data? In RAM or on hard drive? Are they structured in classic DB model or in another way?</p>\n\n<p>Thank you for answer.</p>\n"},{"tags":["database-design","olap","pentaho"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":35,"score":0,"question_id":11831861,"title":"OLAP: Need advice on modelling dimensions based on multiple key-value pairs","body":"<p>I'm using BI Server 4.5 with Saiku plugin 2.3 installed to explore data gathered by a web traffic tracking application.\nIt is the first time I'm trying OLAP, and it works rather well.</p>\n\n<p>However, I'm having trouble in modelling schema to analyze some part of my data, and I hope that you can guide me in the right direction.</p>\n\n<p>My fact table consists of clicks. I've created a few measures and dimensions, and I'm already able to run some of the reports.</p>\n\n<p>The problem is, that there can be some additional variables, that are connected to each click - basically, they are just key-value pairs.\nIn SQL it is a table which consists of 3 columns: click_id - FK to a click object, name(varchar) - name of the additional property, and value(varchar) - value of the additional property.</p>\n\n<p>So each click has some (not more than 5-10) key-value pairs connected to it with arbitrary names.</p>\n\n<p>How can I model this with OLAP?</p>\n\n<p>The only option I see is to create a separate reporting database, where each of the possible property names would be a separate table in a star-schema, and a separate dimension in OLAP schema. Is this the way to go or are there some better possibilities?</p>\n\n<p>Thanks!</p>\n"},{"tags":["ssas","mdx","olap","olap-cube","tabular"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":72,"score":1,"question_id":11633451,"title":"Convert 3D cube to Tables(Rows x Columns)","body":"<p>I was just wondering is there possible ways to display the data from 3d cube in a tabular format withoug slicing through MDX Query- </p>\n\n<p>Suppose, I have a cube with 3 dimensions - Class(A,B,C,D..), Vendor(V1,V2,V3), Period(2010,2011) and the measure would be <strong>SaleValue</strong>..</p>\n\n<p>Now, I would like to view the records like this..</p>\n\n<pre>\n**Class| Vendor|Period|SaleValue**\n\nA | V1  | 2010  |  987\nA | V2  | 2011  |  654\nA | V3  | 2010  |  214\nA | V1  | 2011  |  5643\nA | V2  | 2010  |  698\nA | V3  | 2011  |  212\n\nB | V1  | 2010  |  224\nB | V2  | 2011  |  668\nB | V3  | 2010  |  741\nB | V1  | 2011  |  3216\nB | V2  | 2010  |  953\nB | V3  | 2011  |  2114\n\nC | V1  | 2010  |  159\nC | V2  | 2011  |  852\nC | V3  | 2010  |  369\nC | V1  | 2011  |  147\nC | V2  | 2010  |  123\nC | V3  | 2011  |  654\n</pre>\n\n<p>Is this possible to implement using MDX queries ? If so, please tel me any of sample queries..</p>\n\n<p>Thanks in advance..</p>\n"},{"tags":["olap","business-intelligence","dimensional-modeling"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":82,"score":1,"question_id":7706788,"title":"How to report on sparse areas of sparse fact table","body":"<p>A source system tracks student attendance for a school district by reporting absence events. Attendance on any particular day can be determined by examining three datasets: school calendar, student enrollment, and absence.</p>\n\n<p>On any given school day, the number of enrolled students in attendance is usually much larger than the number that are absent, so this approach reduces the number of records stored to track attendance significantly.</p>\n\n<p>I am trying to determine the proper way to represent daily attendance in a dimensional model. The most obvious way is to create a factless table with a grain per school day per student, and an attendance dimension that has values for both attendance and absence reasons. This is quite straightforward to work with OLAP, but the downside is the size of the fact table.</p>\n\n<p>For example, for 30,000 students and 188 school days means that there are approximately 0.5 million records per year (if this doesn't seem large enough to be an issue, then consider an example in which attendance must be reported on per period rather than per day). Contrast this to a fact table that records only absences and the number is considerably smaller. However, if I do this, then I am not sure how to build cubes that aggregate daily attendance facts.</p>\n\n<p>The specific OLAP technology being used is SQL Server Analysis Services 2008 R2. Any thoughts?</p>\n"},{"tags":["excel","ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":70,"score":0,"question_id":11662019,"title":"show image in tooltips properties in excel from olap cube","body":"<p>I have a olap cube and can send along tooltip data. When the end-user (using excel) is quering against the data i want it to be possible for him/her to show/hide either a tooltip or include in report a picture.</p>\n\n<p>I can send the URL to the picture, but then I want exel to show it as a picture instead of an URL. </p>\n\n<p>Is this possible?</p>\n"},{"tags":["oracle","oracle10g","olap","toad"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":56,"score":0,"question_id":11396956,"title":"Viewing contents of OLAP DML program","body":"<p>I have come across the following stored procedure within an Oracle database:</p>\n\n<pre><code>CREATE OR REPLACE PROCEDURE PRICING.sp_run_interface\nas\nbegin\nDBMS_OUTPUT.ENABLE(1000000);\ndbms_aw.execute('aw attach bewpsp ro');\ndbms_aw.execute('aw attach bewpsd ro');\ndbms_aw.execute('run.interface');\ndbms_aw.execute('aw detach noq bewpsp');\ndbms_aw.execute('aw detach noq bewpsd');\nEND;\n/\n</code></pre>\n\n<p>After much research, I believe that these statements are executing an <a href=\"http://docs.oracle.com/cd/B13789_01/olap.101/b10339/program001.htm\" rel=\"nofollow\">OLAP DML Program</a>.  However I've no idea how to actually view the contents of these programs, or indeed where they are stored.</p>\n\n<p>I'm using TOAD and would appreciate being pointed in the right direction.</p>\n"},{"tags":["jasper-reports","ireport","mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":160,"score":0,"question_id":11628681,"title":"iReport: Report from crosstab with datasource as the OLAP cube + MDX Query?","body":"<p>I am trying to create report from the OLAP cube as the datasource in iReports.</p>\n\n<p>I am using following MDX query for my data:</p>\n\n<pre><code>SELECT CROSSJOIN(HealthCheckStatusD.Members, Measures.Patient) ON Columns,\nNONEMPTYCROSSJOIN(ChannelD.Members,HealthCheckDateD.Members) ON Rows\nFROM CubeReport2\n</code></pre>\n\n<p>and after that I am making crosstab and taking HealthCheckDate + ChannelName in rows and HealthCheckStatus in columns and selecting Patient count as meansure.</p>\n\n<p>But when I am trying to execute the report I am getting following exception</p>\n\n<pre><code>ErrorÂ fillingÂ print...Â NoÂ suchÂ tupleÂ ([Measures].[Patient]Â onÂ axisÂ 0. \nnet.sf.jasperreports.engine.JRRuntimeException:Â NoÂ suchÂ tupleÂ ([Measures].[Patient]Â onÂ axisÂ 0.\n Â Â Â Â atÂ net.sf.jasperreports.olap.JROlapDataSource.getTuplePosition(JROlapDataSource.java:724\n Â Â Â Â atÂ net.sf.jasperreports.olap.mapping.MappingParser.axisPosition(MappingParser.java:601)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.mapping.MappingParser.axisPositions(MappingParser.java:550)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.mapping.MappingParser.dataMapping(MappingParser.java:233)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.mapping.MappingParser.mapping(MappingParser.java:139)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.JROlapDataSource.init(JROlapDataSource.java:322)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.JROlapDataSource.&lt;init&gt;(JROlapDataSource.java:122)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.JRMondrianDataSource.&lt;init&gt;(JRMondrianDataSource.java:41)\nÂ  Â Â Â atÂ net.sf.jasperreports.olap.JRMondrianQueryExecuter.createDatasource(JRMondrianQueryExecuter.java:103)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.fill.JRFillDataset.createQueryDatasource(JRFillDataset.java:1073)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.fill.JRFillDataset.initDatasource(JRFillDataset.java:667)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.fill.JRBaseFiller.setParameters(JRBaseFiller.java:1235)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.fill.JRBaseFiller.fill(JRBaseFiller.java:859)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.fill.JRFiller.fill(JRFiller.java:126)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.JasperFillManager.fill(JasperFillManager.java:464)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.JasperFillManager.fill(JasperFillManager.java:300)\nÂ  Â Â Â atÂ net.sf.jasperreports.engine.JasperFillManager.fillReport(JasperFillManager.java:757)\nÂ  Â Â Â atÂ com.jaspersoft.ireport.designer.compiler.IReportCompiler.run(IReportCompiler.java:988)\nÂ  Â Â Â atÂ org.openide.util.RequestProcessor$Task.run(RequestProcessor.java:572)\n Â Â Â Â atÂ org.openide.util.RequestProcessor$Processor.run(RequestProcessor.java:997)Â  \nPrint not filled. Try to use an EmptyDataSource...\n</code></pre>\n\n<p>Where as this MDX query is working fine in OLAP designer... help me out..in solving this issue.. How Can I frame my MDX query with is acceptable by iReport so that I can make report using crosstabs.</p>\n"},{"tags":["mysql","olap","xmla"],"answer_count":0,"favorite_count":1,"up_vote_count":3,"down_vote_count":0,"view_count":164,"score":3,"question_id":11613527,"title":"OLAP Solution for MySQL","body":"<p>I'm developing a project on .NET and I need to include an OLAP-based reporting module.\nWhat is the better OLAP solution for the large MySQL DB(each month there will be about 10 millions new rows), that supports XML for Analysis (XMLA)?</p>\n\n<p>I've already tried icCube, MicroStrategy, Tableau and Mondrian. Are there other alternatives?</p>\n"},{"tags":["jasper-reports","ireport","mdx","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":205,"score":0,"question_id":11575010,"title":"iReport : How to design report from OLAP cube with multiple dimension and calculated measure in iReport?","body":"<p>I have designed OLAP cube in <em>Jaspersoft OLAP Designer</em>. Now I have imported this Cube in <em>iReport</em> by making OLAP connection.</p>\n\n<p>I am tested my result set using following MDX query</p>\n\n<pre class=\"lang-sql prettyprint-override\"><code>select  HealthCheckStatusD.Members ON AXIS(0),\n{ChannelD.Members} ON AXIS(1), {HealthCheckDateD.Members } ON AXIS(2) from  CubeReport2 where Measures.[Patient]\n</code></pre>\n\n<p><em><strong>Also modified version of above query:</em></strong></p>\n\n<pre class=\"lang-sql prettyprint-override\"><code>select  HealthCheckStatusD.Members ON Columns,\nCrossJoin(ChannelD.Members,HealthCheckDateD.Members) ON Rows from  CubeReport2\n</code></pre>\n\n<p>As far as I know both queries are logically same. </p>\n\n<p>Logical cube structure is as follows:</p>\n\n<pre><code>--Cube\n----HealthCheckDateDimension\n----ChannelDimension\n----HealthCheckStatusDimension\n---------PatientMeasure\n</code></pre>\n\n<p>Now I want to prepare report in <em>iReport</em> in the way I am getting result from MDX query.</p>\n\n<p>How to do that with <em>iReport</em>? I tried using crosstabs in <em>iReports</em> but when I specify above MDX query I am not getting any way to specify measure in the crosstabs.</p>\n\n<p>Is there any another approach in <em>iReport</em> of designing reports for OLAP views? kindly help</p>\n"},{"tags":["java","swing","olap","pivot-table"],"answer_count":4,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":518,"score":2,"question_id":7741272,"title":"Swing component for Olap analysis","body":"<p>We're creating a desktop application which will use OLAP server to perform analysis. I'm searching for a Swing component which can provide functionality similar to JPivot. We need to:</p>\n\n<ul>\n<li>Be able to add cube's dimension as a row/column</li>\n<li>Retrieve data from cube and display it</li>\n<li>Expand/collapse hierarchies (aka slice&amp;dice)</li>\n</ul>\n\n<p>Also JPalo is a good showcase, still it's a Web solution.\n<a href=\"http://www.jpalo.com/en/palo_pivot.php?sent=yes&amp;option%5b%5d=OpenApp&amp;option%5b%5d=ViewTabs&amp;option%5b%5d=AutoLogin&amp;option%5b%5d=AutoUser&amp;option%5b%5d=OpenView1&amp;option%5b%5d=Toolbar1&amp;option%5b%5d=HorizonalAxis1&amp;option%5b%5d=Save1&amp;option%5b%5d=POV1&amp;option%5b%5d=VerticalAxis1&amp;option%5b%5d=Toolbar3&amp;option%5b%5d=HorizonalAxis3&amp;option%5b%5d=POV3&amp;option%5b%5d=VerticalAxis3#pivot\" rel=\"nofollow\">demo</a></p>\n\n<p>We've considered few solutions:</p>\n\n<ul>\n<li>JRubik. Project is outdated and is a standalone application with Mondrian OLAP server embedded, it can't work with remote XMLA sources from scratch. We consider forking the project and rewriting to our needs</li>\n<li>OpenSwing pivot table/JIDE pivot table. There are 2 pivot table components available in network, so we were considering to build our own solution around this components. Anyway, either of them didn't work for us, as both take flat model and do all aggregations inside swing code. Instead, we want to make all aggregations on OLAP side and our swing component should just display it.</li>\n<li>La Azada. It's a another all-in-one application similar to JRubit, built on top of Eclipse RCP. It contains functionality we need, but depends on SWT and Eclipse RCP, so it might be too much effort to embed it into existing Swing application.</li>\n<li>Build our own solution. This is the last option we consider, but it may happen that we will chose this one. In that case, we want to simplify our just as much as possible, so if there is any Swing component with collapsible rows and columns, which may be adopted to connect to XMLA, please let me know.</li>\n</ul>\n\n<p>At this moment we're not happy with neither of proposed solutions, so I would like hear ideas and suggestions from the community. Let me know if question is unclear, so I will try to explain things better. Thanks.</p>\n"},{"tags":["c#","silverlight","usercontrols","olap","cubes"],"answer_count":5,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":3176,"score":1,"question_id":1302560,"title":"Silverlight OLAP Data Grid?","body":"<p>Is there any control around where I can have something like Flex OLAP Data Grid for Silverlight?</p>\n\n<p>I tried to create one on my own, but hitting the wall all the time, if there aren't something like this in the market, can we brainstorm a bit on how to approach creating a control like this?</p>\n\n<p>Thanks</p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":80,"score":1,"question_id":10212482,"title":"SSAS using hierarchy without putting it in the select","body":"<p>We have a hierarchy in the time dimension and we try to get some data using the hierarchy of the dimension but we do not want to put the hierarchy in the where clause.\nThis is the code:</p>\n\n<pre><code>with\n\nmember Measures.last_month as   \n        sum(\n        ParallelPeriod(\n                [TIME].[Periods].[Level 06],1\n        ), \n        [Ims Units])\nselect \n\n    {[Ims Units],last_month} on columns,\n     [TIME].[Periods].[Level 06].members on rows\nfrom [Analyzer cube]\n</code></pre>\n\n<p>It returns all the months, specifically:</p>\n\n<p>February 2011: 47271 on [ims units] and, 51103 on last_month</p>\n\n<p>March 2011: 55293 on [ims units] and, 47271 on last_month</p>\n\n<p>But if I add the the were clause and remove the hierarchy in the select clause:</p>\n\n<pre><code>with\n\nmember Measures.last_month as   \n        sum(\n        ParallelPeriod(\n                [TIME].[Periods].[Level 06],1\n        ), \n        [Ims Units])\nselect \n    {[Ims Units],last_month} on columns\nfrom [Analyzer cube]\nwhere [TIME].[MONTH NAME].&amp;[201103 March]\n</code></pre>\n\n<p>It shows:</p>\n\n<p>March 2011: 55293 on [ims units] and, null on last_month</p>\n\n<p>We have the null on the last_month because it has been filtered the time dimension.\nIs there any way to get the last month without putting the hierarchy on the select clause and either on the where clause and still using the parallelperiod function? (the use of the ParallelPeriod is just an example)</p>\n\n<p>Thanks,\nFrancisco</p>\n"},{"tags":["olap","projection","vertica"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":89,"score":0,"question_id":11548791,"title":"What is the best way to create projections in Vertica?","body":"<p>Hy all <br/>\n I am trying to understand how Vertica DB works.<br/>\nI want to know what is the best way to create the projections that will be used by my queries.<br/>\n1 -I know i can create by writing the code on the vsql line.<br/>\n2 -Provide the query that will be used to the Vertica Database Designer so that Vertica will create the proper projections for itself .<br/></p>\n\n<p>I am a bit confused, as i create them by hand(without the Db Designer), but Vertica does not seam to use them.<br/>\n Example :<br/>\n- i have table AAA(id, name , address) <br/>\n And i am plannig to make the folowing select on it :<br/>\n   select count(name) from AAA;<br/>\n-for this i am creating a projection called proj1:<br/>\n   create projection  proj1 as select name from AAA ;<br/>\nGreat now i have my created projection:<br/>but when i run the \"explain\" form my select count script the plan shows that the created projection is not used !!!????<br/></p>\n\n<p>Anybody can explain this better to me then the Vertica docs ?<br/>\nTHX</p>\n"},{"tags":["excel","ssas","data-warehouse","olap","mondrian"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":231,"score":0,"question_id":11418287,"title":"Can a Mondrian Cube be Browsed By Microsoft Excel?","body":"<p>Is it possible to browse a Mondrian Cube through Microsoft Excel? like it is done with Microsoft SSAS? If not is there a possibility to use Sharepoint as a front end to browse a Mondrian cube? </p>\n"},{"tags":["sql","connection","ssas","olap","cube"],"answer_count":3,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":307,"score":2,"question_id":11460108,"title":"OLAP Cube deployment issues","body":"<p>I'm really new to this, so I am probably making a simple mistake.</p>\n\n<p>I need to make an OLAP cube using a remote database.\nAfter I set up the dimensions and measures and create the cube, I can not get the cube to launch to the local server. \nI keep getting the error,\n\"The project could not be deployed to the 'localhost' server because of the following connectivity problems :  A connection cannot be made. Ensure that the server is running.  To verify or update the name of the target server, right-click on the project in Solution Explorer, select Project Properties, click on the Deployment tab, and then enter the name of the server.\"</p>\n\n<p>However, the local SQL server is running(from as far as I can tell), and I have no idea on how to go about fixing this. I've tried replacing \"localhost\" with \".\" and the IP, but that hasn't worked either.</p>\n\n<p>Here's the guide I was following:\n<a href=\"http://www.mssqltips.com/sqlservertip/1532/build-a-cube-from-an-existing-data-source-using-sql-server-analysis-services/\" rel=\"nofollow\">http://www.mssqltips.com/sqlservertip/1532/build-a-cube-from-an-existing-data-source-using-sql-server-analysis-services/</a></p>\n\n<p>Maybe the SQL Server isn't really running? How can I check? \nOr am I skipping over something important when I try to process the cube?</p>\n"},{"tags":["sql-server","ssas","olap","dimensions"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":69,"score":0,"question_id":11478364,"title":"SSAS 2008 and Excel 2010 misterious","body":"<p>I have MS SQL 2008 R2 Enterprise.\nAlso I have Microsoft Excel 2010.</p>\n\n<p>I have created a cube wich contains 1 dimensions - number of discount cards and Year-Month-Day</p>\n\n<p>also I have created a cube with a measure 'Amount'</p>\n\n<p>Then I connect to the cube via Excel and I make a column with my dimension 'DiscountCard'.\nThis dimension contains 55000 members.</p>\n\n<p>BUT ! Once I filter this dimension (for example exclude a discount card #2344 ) I have a miracle thing. I can see only 3844 member (other ones are cut).</p>\n\n<p>What to do I can see all my rest members ?</p>\n\n<p>Thanks in advance.</p>\n"},{"tags":["relational-database","olap","database-performance","olap-cube","datamart"],"answer_count":1,"favorite_count":1,"up_vote_count":3,"down_vote_count":1,"view_count":104,"score":2,"question_id":10551541,"title":"What makes access to OLAP Cubes / Datamarts and similar datastructures, faster than to relational databases?","body":"<p>What makes access to OLAP Cubes/Datamarts and similar datastructures, faster than to relational databases?</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>A bounty of 200 will be provided asap.</p>\n"},{"tags":["jasper-reports","olap","jasperserver","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":166,"score":0,"question_id":11451940,"title":"No charts option in JasperServer Adhoc report from OLAP Connection?","body":"<p>I have made a OLAP cube using Jasper OLAP designer. Than I have made a OLAP connection using that OLAP schema in Jasper Server.</p>\n\n<p>My aim is to generate report using that OLAP cube. Basically the scheduled report in PDF format having tabular as well as Chart in it.</p>\n\n<p>Now when I select Create->Ad Hoc report -> OLAP connection.. I don't get the option of charts. Only option there is Crosstab. From this I am able to get tabular report only.</p>\n\n<p>I don't know what wrong.. My concern is how to make this report with charts.. My question may be wrong.. I am new in Jasper, OLAP and all. Kindly give me some guidance.</p>\n\n<p>Thanks in advance.</p>\n"},{"tags":["ssas","mdx","olap","business-intelligence"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":210,"score":1,"question_id":11448464,"title":"MDX OLAP Calculated Measure with non aggregatable measure","body":"<p>I am currently trying to model a cube with the following dimensions : Product, Currency, Date.\nThe measure is ProductSaleValueInStock (all this data is stored in a denormalized SQL table).\nBasically this measure cannot be summed over the Currency and Date dimensions.\nMy goal is to create a calculated measure on top of ProductSaleValueInStock that would allow summing over all other dimensions except for currency and date.\nThe MDX i am trying is like : </p>\n\n<pre><code>IIF( [Currency].CurrentMember = [Currency].[All] OR [Date].[CurrentMember] = [Date].[All],\n      null,\n      SUM({([Currency].CurrentMember, [Date].[CurrentMember])},    [Measures].ProductSaleValueInStock ])) \n</code></pre>\n\n<p>Unfortunately, when i look at my data by currency and date (Or filter using a where clause), i get null values with my expression even though the condition is False and the SUM clause returns a value if alone inside another calculated member. I am very new to OLAP so any tips would be appreciated.\nThanks     </p>\n"},{"tags":["mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":90,"score":0,"question_id":10881147,"title":"how to retrieve the structure of an OLAP cube","body":"<p>I have access to an OLAP catalog, but I am not familiar with MDX. I am looking for the MDX equivalent of SQL:</p>\n\n<pre><code>SHOW DATABASES; \nSHOW TABLES;\n</code></pre>\n\n<p>I was looking at <a href=\"http://msdn.microsoft.com/en-us/library/ms145595\" rel=\"nofollow\">MDX language reference</a>, but I could not find a way of getting the schema, the cube metadata. Thanks for helping.</p>\n"},{"tags":["silverlight","connection-string","ssas","olap","adomd.net"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":316,"score":0,"question_id":11397222,"title":"ADOMD Connection String for OLAP Cube on SSAS using User Name and Password","body":"<p>I want to establish a connection to <strong>OLAP Cube</strong> deployed on <strong>SSAS</strong> from a <strong>Silverlight</strong>  Application.\nI'm using the <strong>ADOMD library</strong> and i want to know the format of the <strong>Connection String</strong>. I have the server URL, the Cube Name, User Name and Password.\nIn <a href=\"http://msdn.microsoft.com/en-us/library/ms123468\" rel=\"nofollow\">the official documentation</a>  i didn't find how to to specify the <strong>Authentification Parameters</strong> ...</p>\n\n<p>//From <strong>SQL Server Management Studio</strong> i'm using windows authentification to connect to the OLAP Cube.</p>\n"},{"tags":["c#","silverlight","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":339,"score":1,"question_id":11294471,"title":"Connecting to OLAP Cube via Silverlight","body":"<p>I want to create a <strong>Silverlight</strong> app to extract and manipulate data from an existing <strong>OLAP Cube</strong>. It's my first time with <strong>MS Technologies</strong> and I want to know the best way to do that.</p>\n\n<ol>\n<li>Should I use some libraries? Which ones?</li>\n<li>Can I do this directly without external dependencies?</li>\n<li>I found some articles talking about <strong>Web Services</strong> with <strong>MS Analysis Services</strong> ... Should I avoid connecting directly to the <strong>OLAP Cube</strong> and make some <strong>Web Services</strong>?</li>\n</ol>\n\n<p>I have searched on <strong>Google</strong> but haven't found good tutorials and the libraries I found are not free.</p>\n\n<p>// PS : I already have a Telerik License, in case that helps.</p>\n\n<p>What is the best way to do this?</p>\n\n<p><strong>Progress :</strong></p>\n\n<p>The cube is deployed on <strong>SSAS</strong>, i have access and i tested many <strong>MDX query</strong> from <strong>MS SQL Server Management Studio</strong>. Someone can just give an example how to launch an <strong>MDX Query</strong> from a <strong>Silverlight</strong> page and display the result ?\nI don't need any library, i just need to get the query result and i will display it my self ...</p>\n"},{"tags":["c#","wpf","olap","pivot-table"],"answer_count":2,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":578,"score":2,"question_id":4866878,"title":"XAML PivotTable from Mosha Pasumansky","body":"<p>Does anyone have sources of his pivot table? Sources were hosted at <a href=\"http://wpf.netfx3.com/files/folders/5672/download.aspx\" rel=\"nofollow\">http://wpf.netfx3.com/files/folders/5672/download.aspx</a>, but now this site is down. Or may be there are similar samples of pivot grid(with source)? </p>\n\n<p>Here is a pic of it : <img src=\"http://i.stack.imgur.com/VWVC2.png\" alt=\"XAML PivotTable\"></p>\n"},{"tags":["sql-server","sql-server-2008","ssas","olap","business-intelligence"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":103,"score":0,"question_id":11105865,"title":"Chaining Many-To-Many Dimensional Relationships in SSAS","body":"<p>I'm developing a cube in SSAS and attempting to model the following relationships:</p>\n\n<ul>\n<li>Many Facts to 1 Customer </li>\n<li>Many Customers to Many Sales Reps</li>\n<li>Many Sales Reps (Subordinates) to Sales Reps (Managers)</li>\n<li>Each M2M relationship is facilitated by a bridge table which also acts as a fact table in the cube</li>\n</ul>\n\n<p>I have most of this working.  I can slice Facts by Customer and by Sales Rep (Subordinate), but when I add Sales Rep (Manager) to the query it appears to return every subordinate/manager combination regardless of whether or not that relationship exists in the bridge table.</p>\n\n<p>Any ideas as to what I might be doing wrong?</p>\n"},{"tags":["linux","data-structures","multidimensional-array","olap","multidimensional"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":80,"score":1,"question_id":8168639,"title":"Linux Alternative for http://www.olapcube.com/","body":"<p>I don't want any server solutions, just store my (multidimensial) data into a file and have a kind of reader for it.</p>\n\n<p>Any ideas?</p>\n"},{"tags":["sql-server-2008","ssas","olap","business-intelligence","multidimensional"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":117,"score":0,"question_id":11263321,"title":"Type 3 Slowly Changing Dimension for a Variable Number of Alternate Realities","body":"<p>I'm designing a custom BI application using SSAS with write back operations.  Basically users want to analyze the current state of their sale reps and territories, tweak territory boundaries and assignments in a \"what if\" scenario, then commit the changes if they like the way that scenario looks.  Each user can have a number of different scenarios to show his/her boss and when a scenario is approved then that becomes the new current state of the sales organization.  I'll be making heavy use of some combination of ROLAP and HOLAP to achieve this.</p>\n\n<p>My boss and I are at odds on how to implement the scenario feature.  He has the executive level summary of how SSAS works and is leveraging his years of experience building database applications while I have been experimenting with SSAS for weeks and read the Kimball bible but I'm still relatively new to multidimensional modeling.  I just need some one who knows what their doing to approve, reject or tweak my idea which is as follows.</p>\n\n<p>I have a number of Type 2 SCD tables that look roughly like this:</p>\n\n<pre><code>Create Table SlowlyChangingDimension\n(\n    SurrogateId Int Identity(1,1) Not Null,\n    NaturalId NVarChar(50) Not Null,\n    BeginDate DateTime Not Null,\n    EndDate DateTime Not Null,\n    IsCurrent Bit Not Null,\n    IsCommitted Bit Not Null,\n    -- Data columns\n    Constraint PK_SlowlyChangingDimension Primary Key Clustered (SurrogateId),\n    Constraint Ck_SlowlyChangingDimension_DateRange Check (EndDate &gt; BeginDate)\n)\n</code></pre>\n\n<p>I maintain historical data through appropriate use of the BeginDate, EndDate and IsCurrent columns.  When new data comes in, I end the current version of the object and create a new current version.</p>\n\n<p>Now to handle scenarios, I want to add a scenario table that I will use to tag specific versions of objects in the SCD.  When a new scenario is created, I will tag the committed versions of each object in the SCD with the scenario.  Since the committed version can exist in multiple scenarios in this way, the M2M link will be facilitated by a bridge table.</p>\n\n<p>Now that the scenario has been created and it's initial state is identical to the committed state, the user can start making changes.  Changes will be stored in the SCD table as additional current rows where IsCommitted = False.  When a change is made, the scenario bridge table will be updated such that it drops the link to the committed version of the object and is now linked to the new alternate version of the object.  When a scenario is committed, the old committed version is ended, the alternate current version is committed and the scenario and all it's links to rows in the SCD table are deleted.</p>\n\n<p>To me, this sounds reasonable.  My boss however, wants to create additional schema elements at runtime when a new scenario is created such that scenario data is stored in separate tables and viewed through a separate cube.  This rubs me the wrong way because I'm pretty sure altering schema at runtime is an anti-pattern.</p>\n"},{"tags":["ssas","mdx","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":183,"score":0,"question_id":11249734,"title":"Add Dimension Attributes Using MDX script","body":"<p>Hello I want to know if is possible to modify a cube dimension in order to Add a New attribute through a MDX script. I can do it using the MS BIDS, but I need to add this attribute for a single customer.</p>\n\n<p>Thanks.</p>\n"},{"tags":["sql","sqlite","normalization","olap","denormalization"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":180,"score":0,"question_id":11106732,"title":"Importance of normalization in SQLite","body":"<p>I have developed a blackberry app(ledger management system) which makes use of SQLite for data storage.</p>\n\n<p>There are several relations among the tables that i have created in my app</p>\n\n<p>Following are some of the tables and their columns:</p>\n\n<pre><code>1. Customer Details-Name,Phone,Email\n2. Bills-Name,Amount\n3. Update Customer-Name\n4. Update Bills-ID\n</code></pre>\n\n<p>and many other temporary tables.</p>\n\n<p>While i developed the app, i never really bothered to look up whether my tables were normalized.</p>\n\n<p>Now after i have completed my app, i wonder whether normalization was required or not.</p>\n\n<p>Most of my queries were based on selecting the records that were inserted into Customer and bills form and then manipulating on them.</p>\n\n<p>For instance, i have Customer Details table which captures all the customer data.Now once a name is recorded in the database,i do not want the same name to again be present in the table,so will this require normalization concept.</p>\n\n<p>Also in a RDBMS like SQLite is normalization essential.Does it hold the same meaning as with DBMS based tables.</p>\n\n<p>Also is there any difference between a OLAP and OLTP system wrt to database normalization.\nIf yes, what would my blackberry app be categorized into?</p>\n\n<p>Appreciate a guidance if any one sound on this.</p>\n"},{"tags":["olap","olap-cube","essbase"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":168,"score":0,"question_id":10293379,"title":"Calculate database size in Oracle Essbase","body":"<p>Classical question at tests:\nI have 4 dimensions:\nMarkets: Sparse, 10 stored members, 10 total members\nProducts: Sparse, 5 stored members, 7 total members\nAccounts: Dense , 10 stored members, 11 total members\nTime : Dense, 5 stored, 12 total</p>\n\n<p>What is the size of that BSO? How do I calculate it?</p>\n"},{"tags":["jquery","jquery-ui","rest","gridview","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1887,"score":1,"question_id":6766974,"title":"JQuery grid plugin with OLAP suport","body":"<p>I found the folowing free jQuery grid plugin with olap. Someone know better free olap plugins ? The JQuery UI Grid project will implement it ? \n<br>\n<br><a href=\"http://code.google.com/p/olap-js/\" rel=\"nofollow\">olap-js</a>\n<br><a href=\"http://demo.analytical-labs.com/\" rel=\"nofollow\">analytical-labs</a>\n<br>jqgrid > 'http://trirand.com/blog/jqgrid/jqgrid.html\n<br>\n<br>Thanks</p>\n"},{"tags":["javascript","database","widget","olap","cube"],"answer_count":7,"favorite_count":1,"up_vote_count":8,"down_vote_count":1,"view_count":3572,"score":7,"question_id":380011,"title":"browsing olap cubes","body":"<p>dows anybody know any fine open source cube browser???</p>\n\n<p>ideally it would be something built with plain javascript...</p>\n\n<p>does it even exists???</p>\n\n<p>I'm planing to use it with classic asp agains a sql database...</p>\n\n<p>thanks a lot</p>\n"},{"tags":["sql-server-2005","index","data-warehouse","olap","star-schema"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":86,"score":1,"question_id":11056330,"title":"Usefulness of a covering index on a fact table","body":"<p>Consider a fact table of the form:</p>\n\n<pre><code>CREATE TABLE Fact1\n(\n    Dim1 int NOT NULL,\n    Dim2 int NOT NULL,\n    Dim3 int NOT NULL,\n    Data1 int NOT NULL,\n    Data2 int NOT NULL\n    ...\n)\n</code></pre>\n\n<p><code>Fact1</code> has a single column index on each of the dimensions. <code>Dim1</code> is assumed to be the time dimension with a granularity down to range of hours (e.g. between 2 PM and 6 PM on March 12 2011). Would it be useful to include <code>Dim2</code> and <code>Dim3</code> as covering columns within Dim1? Or likewise on any of them?</p>\n\n<p>More generally, would it ever be useful to include the other dimension table FK columns as a covering column on an index for a given dimension?</p>\n\n<p><em>Note: For the fact table, we are assuming there is no need to uniquely identify a given fact. Hence, the lack of a primary key or surrogate key. The uniqueness is guaranteed by (Dim1, Dim2, Dim3) always being a unique tuple.</em></p>\n"},{"tags":["olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":627,"score":1,"question_id":1346924,"title":"Does non-relational OLAP Engine exist?","body":"<p>like non-sql db but for olap. In Opensource of course :)</p>\n\n<p>Edit:</p>\n\n<p>OLAP engine uses Relational DB underground. For example SAPBW can use Oracle, etc. What I mean is kind of OLAP engine WIHTOUT underlying Relation DB like a sort of Google BigTable with OLAP functionality.</p>\n\n<p>OLAP DB can be gigantic since BigTable is about the same amount of Data, I want to know if anybody has made a model for fusionning both.</p>\n"},{"tags":["database","database-design","nosql","olap","business-intelligence"],"answer_count":3,"favorite_count":1,"up_vote_count":5,"down_vote_count":0,"view_count":491,"score":5,"question_id":4458921,"title":"Database selection for a web-scale analytics application","body":"<p>I want to build a web-application similar to Google-Analytics, in which I collect statistics on my customers' end-users, and show my customers analysis based on that data.</p>\n\n<p>Characteristics:</p>\n\n<ul>\n<li>High scalability, handle very large volume</li>\n<li>Compartmentalized - Queries always run on a single customer's data</li>\n<li>Support analytical queries (drill-down, slices, etc.)</li>\n</ul>\n\n<p>Due to the analytical need, I'm considering to use an OLAP/BI suite, but I'm not sure it's meant for this scale. NoSQL database? Simple RDBMS would do?</p>\n"},{"tags":["php","zend-framework","olap"],"answer_count":3,"favorite_count":2,"up_vote_count":4,"down_vote_count":0,"view_count":2571,"score":4,"question_id":5181278,"title":"Open source OLAP tools in PHP?","body":"<p>Are there any good open source OLAP tools for PHP, preferably using Zend Framework? Will be building a report generating part of an application and was thinking of prehaps integrating an existing solution instead of starting from scratch.</p>\n\n<p>The idea is to have a web interface to it that you can setup different cubes in and then let people with different privileges query cubes based on their privileges and print reports, graphs etc.</p>\n"},{"tags":["c#","vb.net","excel","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":885,"score":1,"question_id":801377,"title":"Building a local cube","body":"<p>I need to build a local .cub file for my Excel-using clients.</p>\n\n<p>I have scrounged together some VB code but it fails :</p>\n\n<pre><code>ConnLocation = \"LOCATION=C:\\test.cub;\"\nConnDSN = \"SOURCE_DSN=DSN=TEST;UID=test;PWD=pass;\"\nConnCreateCube = _\n\"CREATECUBE=CREATE CUBE [TestCube] (\" &amp; _\n\"DIMENSION [account_code]);\"\nConnection = CreateObject(\"ADODB.Connection\")\nConnection.Provider = \"msolap\"\nConnection.ConnectionString = _\n    ConnLocation &amp; _\n   ConnDSN &amp; _\nConnCreateCube\n</code></pre>\n\n<p>I have trimmed this down to the above code and am getting a mysterious <code>OLE DB error: OLE DB or ODBC error.</code>\" when I try to run it.</p>\n\n<p>Any help on the above or suggestions on a different way to approach this would me much appreciated.</p>\n"},{"tags":["c#","sql-server","ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":107,"score":1,"question_id":10953769,"title":"SqlCommand.ExecuteScalar with linked OLAP server doesn't return any value","body":"<p>I have problem  with executing query using <code>SqlCommand</code>, I'm using <code>ExecuteScalar()</code> method and passing open query to it: </p>\n\n<pre><code> SELECT * FROM OpenQuery(MY_OLAP,\n'WITH MEMBER [Measures].[Out] AS\n''[Measures].[Hours]''\n SELECT NON EMPTY [Machine].[Stops].[All]\n ON ROWS, [Measures].[Out] ON COLUMNS FROM [Machines]')\n</code></pre>\n\n<p>and trying to execute query against linked OLAP server but only thing \nI get is <code>object=null</code> or empty result, but  when I run same query in management studio it's returning correct values.</p>\n\n<pre><code> SqlConnection cubeConnection = new SqlConnection(cubeConnectonString);\n            using (SqlCommand cubeCmd = new SqlCommand(cubeQuery, cubeConnection))\n            {\n                cubeConnection.Open();\n                var tmp = cubeCmd.ExecuteScalar();\n                if (tmp==null) {\n                    cuberesult = \"0\";\n                }\n                else tmp.ToString();\n\n            }\n</code></pre>\n\n<p>I added linked OLAP server than I add linked server login with my domain user in order to have access to this cube, I login to server using standard authentication,  but this doesn't help. Some one have idea what I'm missing. </p>\n\n<pre><code>EXEC sp_addlinkedserver\n    @server='MY_OLAP',\n    @srvproduct='', \n    @provider='MSOLAP', \n    @datasrc='MYSQLSERVER', \n    @catalog='CUBE' \n</code></pre>\n"},{"tags":["ssis","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":133,"score":0,"question_id":10947475,"title":"Could not process SSIS Package with Web Service?","body":"<p>I have created a new cube on SQL Server 2005. And I tried to process it with a web service. I use this web service to process other cube that I created before and They processes succesfully. Bu This new cube does not process. This is the error mesage</p>\n\n<pre><code>System.Web.Services.Protocols.SoapException: Server was unable to process request. \n   at System.Web.Services.Protocols.SoapHttpClientProtocol.ReadResponse(SoapClientMessage message, WebResponse response, Stream responseStream, Boolean asyncCall)\n   at System.Web.Services.Protocols.SoapHttpClientProtocol.Invoke(String methodName, Object[] parameters).....\n</code></pre>\n\n<p>I could not figure out the problem. Could you help me? Thank you...</p>\n"},{"tags":["postgresql","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":535,"score":0,"question_id":10933420,"title":"OLAP/MDX - define calculated member, sum all time to date data","body":"<p>I would like to define \"all time to date\" calculated member in OLAP cube. I'm able to calculate YTD by using the following:</p>\n\n<pre><code>SUM(YTD([Time].[Month].CurrentMember), [Measures].[Suits])\n</code></pre>\n\n<p>How can I include all dates since the beginning of my data? My time dimension looks like:</p>\n\n<pre><code>&lt;Dimension type=\"TimeDimension\" visible=\"true\" foreignKey=\"granularity\" highCardinality=\"false\" name=\"Time\"&gt;\n  &lt;Hierarchy name=\"Time\" visible=\"true\" hasAll=\"true\" primaryKey=\"eom_date\"&gt;\n    &lt;Table name=\"v_months\" schema=\"bizdata\"&gt;\n    &lt;/Table&gt;\n    &lt;Level name=\"Year\" visible=\"true\" column=\"year_number\" type=\"String\" uniqueMembers=\"false\" levelType=\"TimeYears\" hideMemberIf=\"Never\"&gt;\n    &lt;/Level&gt;\n    &lt;Level name=\"Quarter\" visible=\"true\" column=\"quarter_number\" type=\"String\" uniqueMembers=\"false\" levelType=\"TimeQuarters\" hideMemberIf=\"Never\"&gt;\n    &lt;/Level&gt;\n    &lt;Level name=\"Month\" visible=\"true\" column=\"month_number\" type=\"String\" uniqueMembers=\"false\" levelType=\"TimeMonths\" hideMemberIf=\"Never\"&gt;\n    &lt;/Level&gt;\n  &lt;/Hierarchy&gt;\n&lt;/Dimension&gt;\n</code></pre>\n\n<p>Not sure if relevant: I'm using mondrian olap server (running on tomcat), Saiku as frontend, postgres as database</p>\n\n<p>I've tried a lot of combinations, but I can't figure it out.</p>\n\n<p>Update: I've tried to use syntax suggested by Gonsalu:</p>\n\n<pre><code>&lt;CalculatedMember name=\"YTD Suits\" formatString=\"\" formula=\"SUM(YTD([Time].[Month].CurrentMember), [Measures].[Suits])\" dimension=\"Measures\" visible=\"true\"&gt;\n&lt;/CalculatedMember&gt;\n&lt;CalculatedMember name=\"PTD Suits\" formatString=\"\" formula=\"Sum({NULL:[Time].[Month].CurrentMember },[Measures].[Suits])\" dimension=\"Measures\" visible=\"true\"&gt;\n&lt;/CalculatedMember&gt;    \n</code></pre>\n\n<p>Using this I get the following error message when starting mondrian (note that YTD function works well without the second calculated member):</p>\n\n<pre><code>Caused by: mondrian.olap.MondrianException: Mondrian Error:Failed to parse query\n 'WITH\nMEMBER [Measures].[Measures].[YTD Suits]\n  AS 'SUM(YTD([Time].[Month].CurrentMember), [Measures].[Suits])',\n    [$member_scope] = 'CUBE',\nMEMBER_ORDINAL = 6\nMEMBER [Measures].[Measures].[PTD Suits]\n  AS 'Sum({NULL:[Time].[Month].CurrentMember },[Measures].[Suits])',\n[$member_scope] = 'CUBE',\nMEMBER_ORDINAL = 7\nSELECT FROM [Project Performance]'  \n</code></pre>\n\n<p>Thank you for any ideas.</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":87,"score":0,"question_id":10880300,"title":"OLAP Database support HIJRI date?","body":"<p>I want to know if the OLAP database support HiJRI dates , my data source is oracle database . if it is not support,  any workaround available?</p>\n\n<p>Thanks in advance</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":174,"score":2,"question_id":10860768,"title":"SQL Server Analysis Services, update OLAP dimensions from relational database","body":"<p>I have OLAP analysis services related with relational database.when the data updated or changed in relational database I must make process operation manually in my project(project to build the OLAP from relational database) to push the new data in OLAP. </p>\n\n<p>I want every change in relational database to affect the OLAP automatically. </p>\n\n<p>Thanks in advance</p>\n"},{"tags":["python","analytics","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":390,"score":0,"question_id":8956744,"title":"Advice for building a web analytics tool (preferably Python friendly) - OLAP/Python","body":"<p>I'm about to start the development of a web analytics tool for an e-commerce website.</p>\n\n<p>I'm going to log several different events, basically clicks on various elements of the page and page views.</p>\n\n<p>These events carry metadata (username of the loggedin user, his country, his age, etc...)  and the page itself carries other metadata (category, subcategory, product etc...).</p>\n\n<p>My companies would like something like an OLAP cube, to be able to answer questions like:</p>\n\n<p>How many customer from country x visited category y?\nHow many pageviews for category x in January 2012?\nHow many customer from country x visited category y?</p>\n\n<p>My understanding is that I should use an OLAP engine to record these events, and then build a reporting interface to allow my colleagues to use it.</p>\n\n<p>Am I right? Do you have advices on the engine and frontend/reporting tool I should use? I'm a Python programmer, so anything Python-friendly would be nice.</p>\n\n<p>Thank you!</p>\n"},{"tags":["sql-server","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":123,"score":3,"question_id":10792392,"title":"Cumulative Sum - Choosing Portions of Hierarchy","body":"<p>I have a bit of an interesting problem.</p>\n\n<p>I required the cumulative sum on a set that is created by pieces of a Time dimension.  The time dimension is based on hours and minutes. This dimension begins at the 0 hour and minute and ends at the 23 hour and 59 minute.</p>\n\n<p>What I need to do is slice out portions from say 09:30 AM - 04:00 PM or 4:30PM - 09:30 AM.  And I need these values in order to perform my cumulative sums.  I'm hoping that someone could suggest a means of doing this with standard MDX.  If not is my only alternative to write my own stored procedure which forms my Periods to date set extraction using the logic described above?</p>\n\n<p>Thanks in advance!</p>\n"},{"tags":["sql-server","ssas","mdx","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":203,"score":3,"question_id":10729005,"title":"Grabbing first or last value for custom time period","body":"<p>First off, very new to SSAS.  But what I would like to accomplish seems fairly trivial (I hope).</p>\n\n<p>I have transactional data which occurs by the second.  And I have created two time dimensions.  One dimension is based on the standard time dimension using the time dimension wizard.  The other is a time dimension that was generated by my own script where I have a record for each second of the day.</p>\n\n<p>I've linked my fact table to my dimensions and have my cube deployed properly.  Within my fact data, one of the attributes is price. Now using min and max I have been able to obtain the highest price and lowest price which occurred over a specific time period.  What I would like to obtain is the first and last price that occurred over a time period.  I've tried using \"first value\" and \"last value\" but what is being returned is not correct, it seems to be some sort of aggregation.</p>\n\n<p>So for example. If my prices over a 1 minute period were:</p>\n\n<p>1233, 1233.85, 1300,1250</p>\n\n<p>First should return, 1233 and last should return 1250.  This should work at all time periods.</p>\n\n<p>To add, for my custom time dimension I've tried setting its type to \"Time\" but the results remain the same.  I appreciate any suggestions.  I am basically looking to get the first value of the underlying and the last value.</p>\n\n<p>Example query that gets me part of the way there:</p>\n\n<pre><code>SELECT NON EMPTY \n     { [Measures].[High]\n     , [Measures].[Low]\n     , [Measures].[Price Count]\n     , [Measures].[Price]\n     } ON COLUMNS\n     , NON EMPTY\n     { [Dim Date].[Year -  Week -  Date].[Date].ALLMEMBERS\n     * HEAD( [Dim Time].[Hour - Second].[Second].ALLMEMBERS )\n     } ON ROWS \nFROM [Cube]\n</code></pre>\n\n<p><img src=\"http://i.stack.imgur.com/vH9M6.png\" alt=\"enter image description here\"></p>\n\n<p>Notice that the price count column has multiple records.  I need the first record from within here I don't want the actual sum.</p>\n"},{"tags":["sql","ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":10,"down_vote_count":0,"view_count":300,"score":10,"question_id":8120954,"title":"Calculated Member for last-child in non-time dimensions?","body":"<p>In as SSAS cube, how do I create measures that are aggregated as LastChild for a non-time dimension?</p>\n\n<p>The source data has many versions of the same business record on any given day. The time dimension has a granularity of DATE, not seconds &amp; milliseconds.</p>\n\n<p>The fact records have a timestamp and an incremental (identity) primary key - and in effect what I want is to calculate a measure as being the last value for all edits on a given date.</p>\n\n<p>The option's I've seen so far fall into one of two categories:</p>\n\n<ul>\n<li>Produce a time dimension that goes down to seconds. This would result in a very large and inefficient time dimension.\nOR</li>\n<li>Hide the measures and replace them with calculated measures that look up the last value based on the primary key, for any given date. This is cumbersome and less efficient.</li>\n</ul>\n\n<p>Is there a sweet-spot or alternative technique to solve this problem?</p>\n\n<p>The natural hierarchy of the data is:</p>\n\n<ol>\n<li>Bussines Key</li>\n<li>Record TimeStamp (links to TIME dimension)</li>\n<li>Surrogate Key</li>\n</ol>\n"},{"tags":["sql-server","sql-server-2005","ssas","olap","mdx"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1515,"score":0,"question_id":380616,"title":"How to use 3rd dimension in MDX query (ON PAGES syntax)","body":"<p>I have a problems with 3rd dimension in MDX Query (on MS SQL Server 2005). I can use 3rd dimension in Visual Basic (I have a cube there, using browser I can make 3 dim. queries -- owing to ON PAGES). I snooped it via MS SQL Profiler (it records databases queries). But when I tried to put the query into MS SQL SERVER, only thing what I've received was: </p>\n\n<p>Executing the query ...\nObtained object of type: Microsoft.AnalysisServices.AdomdClient.CellSet\nFormatting.\nResults cannot be displayed for cellsets with more than two axes.\nExecution complete</p>\n\n<p>I tried a few different ways to implement query, but this^ answer, was an only answer from a server.</p>\n\n<p>The question is: What I need to do to use third dim in my OLAP? </p>\n"},{"tags":["olap","google-bigquery"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":187,"score":0,"question_id":10433940,"title":"What OLAP features are in BigQuery?","body":"<p>In the BigQuery documentation it is mentioned that it uses OLAP functions. But the developer documentation does not mention MDX query language, dimension or fact tables. What OLAP features, if any, are in BQ and how are they </p>\n"},{"tags":["sql-server-2008","mdx","data-warehouse","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":124,"score":0,"question_id":10758412,"title":"Calculated measures in MSSQL Server 2008 BDS cube","body":"<p>I want to define 3 calculated members. I have a cube based on 2 tables, TrackInfo and Chart Positions. Chart Positions table consists of 36 week columns, which contain given track's position on top 100 list in given week (or 0 if the song didn't make it on the list):</p>\n\n<pre><code>[Entry ID] FOREIGN KEY,\n[1st Week] FLOAT,\n[2nd Week] FLOAT,\n</code></pre>\n\n<p>and so on, until week 36.</p>\n\n<p>I'd like to calculate the following measures:</p>\n\n<p>1) The amount of weeks the song has been in top 10</p>\n\n<p>2) The amount of weeks the song has been in top 20</p>\n\n<p>3) \"Popularity meter\", which would be done by the formula:</p>\n\n<p>1 / ((average of all nonzero positions) * (37 - (weeks featured on List)))</p>\n\n<p>Can anyone help me with those?</p>\n"},{"tags":["salesforce","olap","apex-code","rolap"],"answer_count":3,"favorite_count":0,"up_vote_count":8,"down_vote_count":0,"view_count":195,"score":8,"question_id":8021383,"title":"Building OLAP style applications with SalesForce/Apex","body":"<p>We are considering moving a planning and budgeting app to the Salesforce platform.  The existing app is built on a dimensional data model, and has extensive ad-hoc query capability implemented through star joins.</p>\n\n<p>We see how the platform will allow us to put together the data entry screens quickly, but the underlying datamodel and query languages do not seem suitable for our reporting requirements.</p>\n\n<p>Is it possible to have fast and flexible reporting with this platform?  If not, how cumbersome  is it to extract the data on a regular basis to bring it into an analytical application?</p>\n"},{"tags":["sql-server","olap","business-intelligence","analysis-services"],"answer_count":4,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":577,"score":1,"question_id":2140784,"title":"Delivering Business Intelligence with SQL Server Analysis Services over the web","body":"<p>I have a cube developed using SQL Server Analysis Services (2005). Its hooked up to an excel front end.</p>\n\n<p>At the moment users have their own logon to the reporting server and access the reports that way. However, it would be nice of they could access the reports over the web.</p>\n\n<p>Are there options for this? I could upgrade to 2008 if there was a compelling case.</p>\n"},{"tags":["ssas","olap","cube","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":63,"score":0,"question_id":10692158,"title":"Custom Interval In Dimension","body":"<p>I'm looking for recommendations on a best practice here.</p>\n\n<p>I have a requirement where on a given day I must have an arbitrary number of intervals (think buckets of time which are composed of transactions)  where I can have at most N intervals per day.  These intervals are like time but can be arbitrary lengths i.e. some are seconds, others are minutes.</p>\n\n<p>How the intervals should be formed is based on my source data.  On any given day, we always start with interval 1 and it is unknown the total number of intervals we will have by EOD, each interval is defined by a fixed number of transactions.  For every interval I am going to need to know the end time as well.</p>\n\n<p>What is the best approach here?  Should I be bucketing my fact table and connecting to a standard hour/minute/second dimension or should I be using my transactional data to be making a dimension that accommodates it?</p>\n\n<p>I appreciate your feedback.</p>\n"},{"tags":["data-warehouse","olap","oltp"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":111,"score":0,"question_id":9081816,"title":"Data warehouse - OLTP","body":"<p>I'm doing this paper work for university about DataWarehouse, more specifically about OLTP. I couldn't find much information on the web. I find general and superficial summaries, but nothing that coould give me the possibility to do a more detailed work.</p>\n\n<p>I would really apreciate any help about finding that kind of information, which im a bit lost right now.</p>\n\n<p>So, is there any pdf ou e-book or something which i can use to base my work?</p>\n\n<p>Thanks in advanced,\nJohn</p>\n\n<p>PS. about OLTP, datawarehouse i can find enought information</p>\n"},{"tags":["tsql","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":306,"score":0,"question_id":10553912,"title":"Olap cube and MDX and NON EMPTY","body":"<p>I am pretty new to SSAS, OLAP and MDX syntax.</p>\n\n<p>So I have this <code>MDX</code> to query the cube by <code>TSQL</code> (by linked server to SSAS) and it works fine:</p>\n\n<pre><code>select * from openquery(GCUBE, \n'SELECT NON EMPTY { [Measures].[Valore] } ON COLUMNS, \nNON EMPTY {\n( [Prodotti].[Top Marca].[Top Marca].ALLMEMBERS \n* [Prodotti].[Top Codice].[Top Codice].ALLMEMBERS \n* [Agenti].[Vw Agenti].[Vw Agenti].ALLMEMBERS\n* [Calendario].[AnnoMese].[Mese].ALLMEMBERS \n* [Prodotti].[Ordinamento].[Ordinamento].ALLMEMBERS \n* [Prodotti].[Top].[Top].ALLMEMBERS )\n}\nDIMENSION PROPERTIES MEMBER_CAPTION\nON ROWS FROM ( SELECT ( { [Calendario].[Anno].&amp;[2012] } )\nON COLUMNS FROM ( SELECT ( { [Agenti].[Vw Agenti].&amp;[005] } )\nON COLUMNS FROM [Vendite])) WHERE (  [Calendario].[Anno].&amp;[2012] )'\n)\n</code></pre>\n\n<p>Well, the <code>[Prodotti].[Top Marca]</code> is a dimension based on a table with the 50 top selling brands and this MDX is filtered by a specific ID Agent <code>[Vw Agenti] = 005</code>.</p>\n\n<p>The purpose of the query is to find out <strong>how the agent is selling the company's 50 top selling brands.</strong></p>\n\n<p>The query works fine but there is one brand not sold by this agent and I need to show the empty row.</p>\n\n<p>The figure below shows the <strong>missing record relative to the position (rank) 31</strong>.</p>\n\n<p><img src=\"http://i.stack.imgur.com/IYUke.jpg\" alt=\"MDX Query result\"></p>\n\n<p>I understand the concept about <code>NON EMPTY</code> but I can't find the right syntax to also show the empty record.</p>\n\n<p>How should I modify the MDX?</p>\n\n<p>I tried to remove <code>NON EMPTY</code> but I get a generic error:</p>\n\n<pre><code>Cannot execute the query against OLE DB provider \"MSOLAP\" for linked server \"GCUBE\"\n</code></pre>\n\n<p>Do I need to change the dimension <code>Top Marca</code> in the cube?</p>\n\n<p>Thanks in advance to anyone who can help me or give the right tips to solve this.</p>\n"},{"tags":["tsql","mdx","olap","openquery"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":105,"score":0,"question_id":10679992,"title":"SQL OpenQuery MDX fails for ParentChild Hierarchy","body":"<p>I have some MDX which works OK in Reporting Services query designer. It includes pulling data down to the leaf node of a hierarchy dimension that is built around a parent child table, that is 'flattened' via a view to a series of fields labelled Level1, Level2 etc. The cube works fine, and the MDX returns the data at all levels down to a specified hierarchy level.</p>\n\n<p>When I attempt to call this same MDX in Management Studio via OpenQuery, using a linked server pointing at my OLAP server, the query thinks for a few seconds then bails with: A severe error occurred on the current command.  The results, if any, should be discarded. There are no results.</p>\n\n<p>Interestingly, if I remove the reference to the hierarchy dimension in the MDX then it works fine via OpenQuery. It just seems unable to handle the structure within the hierarchy. Reporting services returns it as a simple 2 dimensional dataset like any other dimension in the cube, showinf all levels down to the specified leaf node, so I can't see why OpenQuery wouldn't do the same.</p>\n\n<p>Side note: if I open the cube in management studio and execute the same MDX, it runs ok, but returns ONLY the hierarchy level specified in the MDX, not all levels down to it, as when run in reporting services query designer. So I guess that's 3 different outcomes from 3 different environments! I'm not sure of the relevance of this.</p>\n\n<p>Any ideas?</p>\n\n<p>UPDATE:\nBlimey. I removed 'MEMBER_UNIQUE_NAME' from near the end of the MDX, and the problem seemed to go away! If anyone wants to explain that that'd be much appreciated.</p>\n"},{"tags":["olap","dimension"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":24,"score":0,"question_id":10667637,"title":"Create a dimension from a view on OLAP?","body":"<p>I create a view on Data Source views. It is consist of two tables, Procedures and Materials. And the fact table has two column contain procedure and material. I made two relations between this view and procedure and material column.  And I created a dimension from this view. \nNow I want to show this dimension on the cube. This dimension shows materials and procedures together. But I could not set uo the dimesion usage method. How could I design this scenario? Any idea?</p>\n"},{"tags":["mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":18,"score":0,"question_id":10663929,"title":"jdbc4olap feedback","body":"<p>I've stumbled upon <a href=\"http://www.jdbc4olap.org/\" rel=\"nofollow\">jdbc4olap</a> (note that I know about olap4j and the like). </p>\n\n<p>As my Google search has failed, I'm looking for some direct feedback from the community. Is this project used outside Prelytis? Any comment?</p>\n"},{"tags":["hadoop","olap","pig","hypertable","hypercube"],"answer_count":1,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":383,"score":2,"question_id":5181595,"title":"Hadoop Hypercube","body":"<p>Hey,\ni am starting a hadoop based hypercube with a flexible number of dimensions.\nDoes anybody know any existing approaches for this?</p>\n\n<p>I just found <a href=\"http://wiki.apache.org/pig/PigOLAPSketch\" rel=\"nofollow\">PigOLAPSketch</a>, but there is no code to use it.</p>\n\n<p>Another approach is <a href=\"http://www.zohmg.com/\" rel=\"nofollow\">Zohmg</a> from lastfm, which uses hbase, but seems to be very dead.</p>\n\n<p>I think i will start a pig solution, maybe you have some advices?</p>\n"},{"tags":["ssas","olap","cube","ssas-2008"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":163,"score":2,"question_id":10592439,"title":"million rows dimension in ssas cube","body":"<p>I have a large dimension in my cube which has 5 million rows. when I drag that dimension column in excel to view metric value it times out. Is there any way I can limit the data dynamically or selecting only top 10K rows when that large dimension is pulled in excel? or any other best approch?</p>\n"},{"tags":["java","mysql","olap","jasperserver","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":382,"score":1,"question_id":9760584,"title":"Jasper report Server connection fail when connect to mysql","body":"<p>when i am creating the connection in jasper report server with mysql and then testing the connection it shows me CONNECTION FAILED. Plz help me \nalso tell me how i can create olap connection between jasper report server and java</p>\n"},{"tags":["olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":83,"score":0,"question_id":10578751,"title":"How MOLAP cube grows in size with Palo?","body":"<p>It is my first time to design a OLAP system. I don't have any idea how MOLAP cube grows in size in Palo when adding more and more data. I have read some articles saying MOLAP tools are not good at handling large amount of data. My data is like this:</p>\n\n<ol>\n<li>I have to import 60 million raw records per month(I import data per month)</li>\n<li>each raw record in current PostrgeSQL database is about 150 byte</li>\n<li>There is 5 diementions.</li>\n</ol>\n\n<p>another question about Palo:</p>\n\n<p>It's website says: Palo is a in-memory MOLAP solution. This means if we reboot server, all aggregated results will gone?</p>\n"},{"tags":["olap"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1091,"score":0,"question_id":3203306,"title":"What is use of OLAP?","body":"<p>How the data access can be faster using OLAP ?</p>\n"},{"tags":["oracle","odbc","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":1,"view_count":307,"score":0,"question_id":7574117,"title":"to OLAP or not to OLAP","body":"<p>I want to ask what are the performance gains of pulling reports in sharepoint 2010 directly from an oracle DW using an ODBC Connection as compared to building an OLAP Layer using SSAS and accessing data through that.</p>\n\n<p>thanks</p>\n"},{"tags":["c#","sqlite","sql-server-ce","olap","oltp"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":207,"score":1,"question_id":10478840,"title":"Portable OLAP Database similar to SQLite or SQL CE","body":"<p>I am developing an application with C# and trying to choose the right database platform. My application is a some sort of data analysis tool. I will always make SELECT queries after the initial import of data into the database. I am planning to use SQLite because of the better read performance compared to SQL CE. (I have seen comparisons somewhere)</p>\n\n<p>However, I feel like I need an OLAP database instead of an OLTP database for this purpose. I also read somewhere that SQLite supports only OLTP. Do you know any other PORTABLE library which supports OLAP similar to SQLite? Or what do you recommend for me?</p>\n"},{"tags":["database-design","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":37,"score":0,"question_id":10473698,"title":"How to design multidimensional elements basing on this example?","body":"<p>I am writing thesis in my university about automated relational model transformation to multidimensional model. For multidimensional elements discovery I am using algorithms presented in this article <a href=\"http://www-db.deis.unibo.it/~srizzi/PDF/dawak10.pdf\" rel=\"nofollow\">pdf</a>. For start I have taken this db <a href=\"https://wiki.openmrs.org/download/attachments/5047323/demo-1.9.0.sql.zip\" rel=\"nofollow\">sql.zip</a> to practice with.</p>\n\n<p>My question is how to design multidimensional elements in presented situations:</p>\n\n<p><strong>Situation 1</strong>:</p>\n\n<p>Tables in relational db:</p>\n\n<pre><code>obs (suppose it will fact table)\nconcept (dimension table, M:1 related to obs)\nconcept_class (dimension table, M:1 related to concept)\nusers (dimension table, M:1 related to concept_class\n\n\n\nhttp://i.stack.imgur.com/RgpIS.png\n</code></pre>\n\n<p>I assume that in multidimensional model <strong>obs</strong> will go to fact table and other tables will be joined together (denormalized) and will go to dimension table (one dimension table overall).There will be as many dimensions as there are attributes in dimension tables that can be used for measures aggregation (correct me if I am wrong).<br>\nBut what to do if <strong>obs</strong> table is related to <strong>concept</strong> with several foreign keys:  </p>\n\n<pre><code>obs.value_coded --&gt; concept.concept_id\nobs.concept_id  --&gt; concept.concept_id\n</code></pre>\n\n<p><strong>Situation 2</strong>:<br>\nTable <strong>users</strong> is \"M:1\" related from several other tables. How to consider such kind of table ? Maybe it is shared table ? But from theory I know that shared table is table which is used to aggregate measures between several fact tables... Is here any dimension levels hierarchy present ?</p>\n\n<pre><code>http://i.stack.imgur.com/0q6JL.png\n</code></pre>\n"},{"tags":["ssas","mdx","olap","msas"],"answer_count":3,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1157,"score":1,"question_id":305457,"title":"How to view MS SSAS 2005 sessions and queries","body":"<p>When browsing the cube in Microsoft SQL Server Analysis Services 2005, I would like to peek at the MDX (supposedly) queries generated by client access tools such as Excel. Is there a tool or method that enables me to do just that?</p>\n\n<p>I'm really looking for something like Oracle's v$sessions -- I know about sp_who and sp_who2 for the relational SQL Server, but is there one for MSAS?</p>\n"},{"tags":["tsql","ssis","ssas","olap","dimensional-modeling"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":81,"score":0,"question_id":10423891,"title":"How to assign combinations of members into specifc groups (for OLAP dimensions)","body":"<p>I've got what I believe would be a fairly common scenario in OLAP but a really great way of addressing it isnt jumping out at me:</p>\n\n<p>ive got say a sales transaction with multiple items, with different products for each one..</p>\n\n<p><img src=\"http://i.stack.imgur.com/DLtrs.jpg\" alt=\"enter image description here\">  </p>\n\n<p>What I want to do is assign the product group combinations into a categories\ni.e. 'dog only', 'cat only', 'cat and dog'</p>\n\n<p>So you'd end up with something like..</p>\n\n<p><img src=\"http://i.stack.imgur.com/ZQc4i.jpg\" alt=\"enter image description here\"></p>\n\n<p>If possible I'm hoping to achieve this in Transact-SQL or SSIS, I found calculated members/measures to be slow, put I'm open to that solution if that is the best way to do it</p>\n\n<p>Any help much appreciated</p>\n"},{"tags":["database-design","olap"],"answer_count":5,"favorite_count":0,"up_vote_count":4,"down_vote_count":0,"view_count":2272,"score":4,"question_id":34362,"title":"What if analysis on multi dimensional cubes (OLAP)","body":"<p>I have a multi dimensional OLAP cube with a number of dimensions. Some of these dimensions have hierarchies. The users would like to perform 'what-if' analysis on the measures in the cube by changing the hierarchies in the dimensions. </p>\n\n<p>For example, they want to know the impact on departmental resource budgets by moving employees between departments or the movement in cost of manufacture if a product is moved from one factory to another.</p>\n\n<p>Does anyone have a straight forward way to do this in a modern OLAP engine?</p>\n"},{"tags":["parent-child","olap","mdx","mondrian"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":862,"score":1,"question_id":4427127,"title":"MDX Query for Parent Child Relationship","body":"<p>I have an OLAP Basically there is a dimension that has parent-child relationship.\nSo the dimension has a parent-id and a child-id.</p>\n\n<p>There is a fact table that exists that has the child-id. I would like to get data for a child and all its given children when I provide the parent id. </p>\n\n<p>How could I achieve this in a MDX query ? </p>\n\n<pre><code> &lt;Dimension foreignKey=\"child_id\"  name=\"SUPPLIER\"&gt;\n  &lt;Hierarchy hasAll=\"true\" allMemberName=\"all\" allMemberCaption=\"all\" primaryKey=\"child_id\" &gt;\n    &lt;Table name=\"suppliers\"&gt;\n    &lt;/Table&gt;\n    &lt;Level name=\"SUPPLIER_L\"  column=\"child_id\" nameColumn=\"child_id\" parentColumn=\"parent_id\"  \n    uniqueMembers=\"true\" levelType=\"Regular\" hideMemberIf=\"Never\" &gt;\n    &lt;/Level&gt;\n  &lt;/Hierarchy&gt;\n&lt;/Dimension&gt;\n</code></pre>\n\n<p>I have my dimension where this hierarchy occurs.</p>\n"},{"tags":["sql-server","olap","business-intelligence","cubes"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":239,"score":0,"question_id":10351736,"title":"SQL Server BI: SIngle cube, multiple fact tables","body":"<p>I'm new to creating cubes, so please be patient.</p>\n\n<p>Here's an example of my data\nI have multiple companies, each company has multiple stores.\nSales are each linked to a particular company, with a particular store on a particular date.\nex:5 sales took place for Company A, Store 1, on 5/19/2011\nReturns are linked to a particular company on a particular date.\nex: 3 returns took place for Company A on 3/11/2012\nSometimes my users want to see a list of stores, the date, and how many returns took place, and how many sales.\nSometimes they want to see a list of companies, the specific stores, and the number of sales.</p>\n\n<p>I have a table that stores \nCOMPANY - DATE - STORE- SALES - RETURNS\nI end up having the value for returns repeated for each store under a particular COMPANY - DATE pair.\nso if I'm writing a query, and I want to find out returns, I just do a \nselect distinct company, date, returns from mytable</p>\n\n<p>but I am not sure how to this into a cube (using SS BI and Visual Studio).\n(I've only made a couple of cubes so far)</p>\n\n<p>Thanks! (also, feel free to point me at appropriate references)</p>\n"},{"tags":["html5","mobile","olap","business-intelligence","cube"],"answer_count":0,"favorite_count":2,"up_vote_count":3,"down_vote_count":0,"view_count":353,"score":3,"question_id":10349133,"title":".Net OLAP Cube Explorer control with HTML5 mobile compatibility","body":"<p>I'm currently looking for control suite that supports mobile business intelligence reporting. The mobile BI site will be a complimentary site for an existing SharePoint BI solution that presents SSRS / PerformancePoint information to the user.</p>\n\n<p>The mobile site should allow users to view pivot grids of information sourced from an OLAP cube as well as normal SQL query results of information. The controls present on the mobile site should be completely compatible with iOS, Android and WinPhone devices as the information will primarily be used on mobile devices by users who are often off-site.</p>\n\n<p>At the moment, the only control suite I can find that seems to fit the bill is the <a href=\"http://www.componentart.com/services/\" rel=\"nofollow\">ComponentArt suite for mobile dashboarding</a>.</p>\n\n<p>I had a look at Telerik / Infragistics but neither have any native OLAP cube controls.</p>\n\n<p>Does anyone else have any other suggestions that I can investigate?</p>\n\n<p>Thanks,\nBrian.</p>\n"},{"tags":["mysql","xml","olap","business-intelligence","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":187,"score":0,"question_id":9936634,"title":"Mondrian - Fact Table Data as XML","body":"<p>I am evaluating a Mondrian-Saiku solution for a client.</p>\n\n<p>After analyzing their current database schemas, I realize that what constitutes as their 'fact table data' is currently being stored in XML's. The XML 's themselves are stored as blob datatypes in a MySQL table. Think of it like this: the table holds all the transactions of the company; the details of each transaction are stored in their own XML; each XML string is stored as one of the field values in a given transaction row.</p>\n\n<p>This presents a slight dilemma since the Mondrian XML schema requires the explicit use of column names.</p>\n\n<p>Short of having to extract and transfer the XML data to new tables (not realistic for my purposes due to the size of data and dependencies from other systems), is there any way I can work my client's existing setup for the purposes of a Mondrian-Saiku implementation?</p>\n"},{"tags":["ssas","mdx","olap","business-intelligence","measure"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":139,"score":0,"question_id":10301677,"title":"SSAS & OLAP cube: twice same measure","body":"<p>I'm not very experienced in OLAP Cube + MDX, and I'm having a hard time trying to use twice the same measure in a cube.</p>\n\n<p>Let's say that we have 3 Dimensions: <code>D_DATE</code>, <code>D_USER</code>, <code>D_TYPE_OF_SALE_TARGET</code> and 3 tables of Fact: <code>F_SALE</code>, <code>F_MEETING</code>, <code>F_SALE_TARGET</code></p>\n\n<ul>\n<li><code>F_SALE</code> is linked to <code>D_USER</code> (who make the sale) and <code>D_DATE</code> (when)</li>\n<li><code>F_SALE_TARGET</code> is linked to <code>D_USER</code>, <code>D_DATE</code>, <code>D_TYPE_OF_SALE_TARGET</code> (meaning: user has to reach various goals/targets for a given month).</li>\n</ul>\n\n<p>I can browse my cube: </p>\n\n<ul>\n<li>Rows = Date * User</li>\n<li>Cols = Number of sale, Total amount of sale + the value of 1 target (in the <code>WHERE</code> clause, I filter on <code>[Dim TYPE SALE TARGET].[Code].&amp;[code.numberOfSales]</code>)</li>\n</ul>\n\n<p>How can I add other columns for other targets? As all the targets are in the same table, I don't see how to add a second measure from <code>[Measures].[Value - F_SALE_TARGET]</code> linked to a different code, ie. <code>[Dim TYPE SALE TARGET].[Code].&amp;[code.amountOfSale]</code>.</p>\n"},{"tags":["application","components","olap","powerbuilder"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":49,"score":0,"question_id":10311731,"title":"How to incorporate into Powerbuilder Applications a reporting / OLAP Component?","body":"<p>We need to incorporate into Powerbuilder Applications a Reporting / OLAP Component ( ie ActiveX ).</p>\n\n<p>Does anyone have previous experience in this in order to suggest us some controls ?</p>\n"},{"tags":["olap","business-intelligence","pentaho","star-schema"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":120,"score":0,"question_id":10242933,"title":"sum and distinct-count measures (star schema design koan)","body":"<p>I am quite a beginner in Data Warehouse Design. I have red some theory, but recently met a practical problem with a design of a OLAP cube. I use star schema.<br/>\nLets say I have 2 dimension tables and 1 fact table:</p>\n\n<hr>\n\n<p><strong>Dimension Gazetteer:</strong><br/>\ndimension_id<br/>\ncountry_name<br/>\nprovince_name<br/>\ndistrict_name<br/></p>\n\n<hr>\n\n<p><strong>Dimension Device:</strong><br/>\ndimension_id<br/>\ndevice_category<br/>\ndevice_subcategory<br/></p>\n\n<hr>\n\n<p><strong>Fact table:</strong><br/>\ngazetteer_id <br/>\ndevice_dimension_id<br/>\nhazard_id (measure column)<br/>\narea_m2 (measure column)<br/></p>\n\n<hr>\n\n<p>A \"business object\" (which is a mine field actually) can have multiple devices, is located in a single location (Gazetteer) and ocuppies X square meters.<br/>\nSo in order to know which device categories there are, I created a fact per each device in hazard like this:</p>\n\n<pre><code>+--------------+---------------------+-----------------------+-----------+\n| gazetteer_id | device_dimension_id | hazard_id             | area_m2   |\n+--------------+---------------------+-----------------------+-----------+\n| 123          | 321                 | 0a0a-502c-11aa1331e98 | 6000      |\n+--------------+---------------------+-----------------------+-----------+\n| 123          | 654                 | 0a0a-502c-11aa1331e98 | 6000      |\n+--------------+---------------------+-----------------------+-----------+\n| 123          | 987                 | 0a0a-502c-11aa1331e98 | 6000      |\n+--------------+---------------------+-----------------------+-----------+\n</code></pre>\n\n<p>I defined a measure \"number of hazards\" as distinct-count of hazard_id.<br/>\nI also defined a \"total area occupied\" measure as a sum of area_m2.<br/>\nNow I can use the dimension gazetteer and device and know how many hazards there are with given dimension members.<br/>\nBut the problem is the area_m2: because it is defined as a sum, it gives a value n-times higher than the actual area, where n is th number of devices of the hazard object. For example, with the data above would give 18000m2.<br/>\nHow would you solve this problem?<br/></p>\n\n<p>I am using the Pentaho stack.</p>\n\n<p>Thanks in advance</p>\n"},{"tags":["sql-server-2008","olap","powerbuilder","cube","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":140,"score":1,"question_id":10278352,"title":"Cubes in Powerbuilder","body":"<p>I am working as Powerbuilder/SQL Server Junior Programmer, and I need to use OLAP cubes in my Powerbuilder app, but I do not know how to link them.</p>\n\n<p>Does anyone know how to do it?</p>\n"},{"tags":["database","olap","redundancy"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":269,"score":0,"question_id":10070618,"title":"How to reduce data redundancy of text field in database","body":"<p>I am using a OLAP system, some of table has text field. the text length can be from some Bytes to KB, while the size of other fix size fields in one row is only about 100 Bytes. </p>\n\n<p>some of my tables have billions of rows and the value of text field is highly repeatable, how can i reduce this kind of redundancy to save the storage space and does not lose query performance?</p>\n"},{"tags":["database","performance","monitor","olap","time-series"],"answer_count":6,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":200,"score":1,"question_id":4670025,"title":"Database for managing large volumes of (system) metrics","body":"<p>I'm looking at building a system for managing and reporting stats on web page performance. I'll be collecting a lot more stats than are available in the standard log formats (approx 20 metrics) but compared to most types of database applications, the base data structure will be very simple. My problem is that I'll be accumulating a lot of data - in the region of 100,000 records (i.e. sets of metrics) per hour.</p>\n\n<p>Of course, resources are very limited!</p>\n\n<p>So that its possible to sensibly interact with the data, I'd need to consolidate each metric into one minute bins, broken down by URL, then for anything more than 1 day old, consolidated into 10 minute bins, then at 1 week, hourly bins.</p>\n\n<p>At the front end, I want to provide a view (prefereably as plots) of the last hour of data, with the facility for users to drill up/down through defined hierarchies of URLs (which do not always map directly to the hierarchy expressed in the path of the URL) and to view different time frames.</p>\n\n<p>Rather than coding all this myself and using a relational database, I was wondering if there were tools available which would facilitate both the management of the data and the reporting.</p>\n\n<p>I had a look at <a href=\"http://mondrian.pentaho.com/\" rel=\"nofollow\">Mondrian</a> however I can't see from the documentation I've looked at whether it's possible to drop the more granular information while maintaining the consolidated views of the data.</p>\n\n<p><a href=\"http://oss.oetiker.ch/rrdtool/index.en.html\" rel=\"nofollow\">RRDTool</a> looks promising in terms of managing the data consolidation, but seems to be rather limited in terms of querying the dataset as a multi-dimensional/relational database.</p>\n\n<p>What else whould I be looking at?</p>\n"},{"tags":["java","drupal","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":159,"score":0,"question_id":9894210,"title":"Saiku and Drupal","body":"<p>I've been browsing through the web but haven't been able to find any concrete topics on the integration of <a href=\"http://analytical-labs.com/\" rel=\"nofollow\">Saiku</a> with Drupal. The main challenge seems to be that Saiku is java-based while Drupal runs off PHP.</p>\n\n<p>I am wondering if anyone has implemented, or can provide thoughts on this union.</p>\n\n<p>Is there anything similar to Saiku that would work with Drupal?</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":232,"score":0,"question_id":10236137,"title":"How to include a set of different attributes from same dimension in MDX crossjoin query","body":"<p>I have an MDX query that is returning one column of values. Row-wise, I am doing a cross-join to break out a set of four elements of one dimension attribute by all elements of a second dimension attribute. </p>\n\n<pre><code>SELECT\n[Measures].[Fact Compt Importance Categorical Count] ON COLUMNS,\nCROSSJOIN\n(\n    {[Dim Model Elements].[Element No].[9], [Dim Model Elements].[Element No].[10]},\n    {[Dim Importance Level Bands].[Importance Bands].[All].Children} \n) ON ROWS\nFROM EstimationEngineCube\n</code></pre>\n\n<p>So I get a result set along the following lines:</p>\n\n<p><img src=\"http://i.stack.imgur.com/4fbLz.jpg\" alt=\"initial crossjoin query result \"></p>\n\n<p>I now need to add an additional cross-join, where for a new set of elements, I cycle through all the elements already included in the query so far. However, the challenge I have is that the elements are a set that spans different attributes of the same dimension. I have tried to place all these elements into a named set, and then cross-join with that:</p>\n\n<pre><code>WITH SET [ContextSet] AS\n    {\n        (\n            [Dim Job SOC Context Aggregated].[s3context3008].[4],\n            [Dim Job SOC Context Aggregated].[s3context3014].[3],\n            [Dim Job SOC Context Aggregated].[s3context3017].[3]\n        )\n    }\nSELECT \n    [Measures].[Fact Compt Importance Categorical Count] ON COLUMNS,\n    CROSSJOIN\n    (\n        [ContextSet],\n                CROSSJOIN\n                (\n                    {[Dim Model Elements].[Element No].[9], [Dim Model Elements].[Element No].[10]},\n                    {[Dim Importance Level Bands].[Importance Bands].[All].Children} \n                )\n    )\n        ON ROWS \nFROM EstimationEngineCube\n</code></pre>\n\n<p>However, this does not work â€“ the set is just treated as what effectively looks like a slicer or where condition:</p>\n\n<p><img src=\"http://i.stack.imgur.com/qtaJg.jpg\" alt=\"unsuccessful crossjoin\"></p>\n\n<p>What I was hoping to get was a resultset with this structure:\n<img src=\"http://i.stack.imgur.com/ZuLHv.jpg\" alt=\"enter image description here\"></p>\n\n<p>As I am relatively new to MDX, I assume (hope?) that I have got some wires crossed that can easily be uncrossed.....</p>\n"},{"tags":["ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":31,"score":0,"question_id":10207799,"title":"SSAS retrieving previos data from a filtered dimesion","body":"<p>I am trying to get the data from a previous member in a filtered dimension. Actually the problem is in our time dimesion when we filter by for example 2011 december, and we want to retrieve 2 months back wiht lag(1) and lag(2).</p>\n\n<p>This is the MDX code:</p>\n\n<pre><code>with\nset tam3 as\n{\n    [TIME].[MONTH NAME].lag(0) ,\n    [TIME].[MONTH NAME].lag(1) ,\n    [TIME].[MONTH NAME].lag(2)\n}\n\nmember Measures.tam3_sales__without_set as\n    sum(    \n        {[TIME].[MONTH NAME].lag(0),\n        [TIME].[MONTH NAME].lag(1),\n        [TIME].[MONTH NAME].lag(2)},\n    [Measures].[Ims Units])\n\nmember Measures.tam3_sales__with_set as\n    sum(tam3,[Measures].[Ims Units])\n\nmember Measures.lag0 as\n    sum([TIME].[MONTH NAME].lag(0),[Measures].[Ims Units])\n\nmember Measures.lag1 as\n    sum([TIME].[MONTH NAME].lag(1),[Measures].[Ims Units])\n\nmember Measures.lag2 as\n    sum([TIME].[MONTH NAME].lag(2),[Measures].[Ims Units])\n\nselect \n    {tam3_sales__without_set, tam3_sales__with_set,lag0, lag1, lag2} on columns\nfrom [Analyzer cube]\nwhere [TIME].[MONTH NAME].&amp;[201112 Diciembre]\n</code></pre>\n\n<p>The result:\ntam3_sales__without_set: 143251\ntam3_sales__with_set: 49577\nlag0: 49577\nlag1: 47129\nlag2: 46545\ntam3_sales__with_set returns us the the sales of just December, but it is not the sum of December November and October. But tam3_sales__without_set does it correctly with the sum of the 3 months. What is wrong with the set or what I do wrong? </p>\n\n<p>I would like to have tam3_sales__with_set with the sum of the 3 months. </p>\n\n<p>Thanks,\nFrancisco</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":88,"score":0,"question_id":8830119,"title":"Calculate prorata share with MDX","body":"<p>I have a SSAS cube that shows Investors and their investment value in funds.  The fund value and prorata shares are in fact table.  I've created a calculated measure that simply multiplies fund value * share.  The problem comes in the Total line.  The row marked as WRONG is what shows now.  The row marked RIGHT is what I want to show.</p>\n\n<pre><code>Investor    Fund Value  Share   Investor Value\nInvestor 1  100,000     0.4     40,000\nInvestor 1  200,000     0.3     60,000\nTotal       300,000     0.7     210,000   &lt;== WRONG\nTotal                           100,000   &lt;== RIGHT\n</code></pre>\n"},{"tags":["ssas","mdx","olap","cube","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":57,"score":0,"question_id":10145084,"title":"mdx query \"sales one year vs (one year)-1(year)) show it on months","body":"<p>i have \"ways\" called \"rutas\", every way has sales, i need something as it\ni have dimensions called, rutas, productos, i need this was only for productos with id 191 \nmeasures.facts i have sales.</p>\n\n<pre><code>rutas|enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre\n----------------------------------------------------------------------------------------------\n237  |30000|45000  |-1000|-400 |238 |-4125|20000|134111|-123      |41234  |-3241    |-1900    |\n238  |20000|34550  |-4000|-400 |248 |-4111|20000|131231|-123      |41234  |-3241    |-1900    |\n239  |50000|-2330  |-3000|-400 |238 |-4153|20000|132331|-123      |41234  |-3241    |-1900    |\n240  |-3000|-2340  |-2000|-400 |228 |-4143|20000|134511|-123      |41234  |-3241    |-1900    |\n241  |-7800|12310  |-1000|-400 |218 |-4133|20000|134523|-123      |41234  |-3241    |-1900    |\n242  |300  |45000  |-5000|-400 |238 |-5123|20000|134111|-123      |41234  |-3241    |-1900    |\n</code></pre>\n\n<p>its calculated (sales) of month of one way - sales of a month of one way(less one year)\nexample enero=january</p>\n\n<pre><code>237 on 2012 sold 50000\n237 on 2011 sold 20000\nthen 237 on enero is 30000\n</code></pre>\n\n<p>after i am going to need PERCENTAJES of this numbers wich is calculated as it:</p>\n\n<pre><code>(50000-20000)*100/2000\nwhen 20000 is null then  it is\n(5000-0)*100/5000\n</code></pre>\n\n<p>this is my first query on MDX i could do it on sql but on mdx i am super noob.</p>\n"},{"tags":["ssas","olap","bids"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":307,"score":0,"question_id":10112021,"title":"Dimension attribute with duplicate values allowed in SSAS 2008, gets error in 2005","body":"<p>I have a cube in SQL Server Analysis services 2008 that contains a time dimension comprised of years and quarters.  There is a separate YearQuarterID column as well.</p>\n\n<p>The Quarter attribute (type Quarters) consists of integer values 1 - 4 for each year, as you might expect.  Since this is not the key attribute for the dimension, the non-uniqueness shouldn't be a problem, and in fact the cube builds cleanly.</p>\n\n<p>Inspecting the properties for this attribute in BIDS 2008, I see that it does have a KeyColumns property.  (Not sure what this means for a non-key attribute.)  It says \"DimYearQuarter.Quarter (Integer)\".</p>\n\n<p>Now, I'm trying to retrofit this cube to SSAS 2005.  I have a similar dimension, created from a similar relational database table with similar values.  As far as I can tell, the properties for the attribute are identical in BIDS 2005, nevertheless, when I try to process the cube, I get the error:</p>\n\n<blockquote>\n  <p>Errors in the OLAP storage engine: The attribute key is a duplicate:\n  Table: dbo_DimYearQuarter, Column: Quarter, Value: 1.</p>\n</blockquote>\n\n<p>I did notice that the Properties window in VS2005 doesn't allow the KeyColumns property to be expanded.  So I can't drill down to compare details of the property between versions.</p>\n\n<p>If the attribute is not a key for the dimension, why are duplicates a problem in 2005?</p>\n"},{"tags":["sql-server","tsql","olap","sql-server-2012","rownumber"],"answer_count":2,"favorite_count":2,"up_vote_count":5,"down_vote_count":0,"view_count":251,"score":5,"question_id":10065057,"title":"SQL Server: row_number partitioned by timeout","body":"<p>I have a table with a series of (IP varchar(15), DateTime datetime2) values. Each row corresponds to an HTTP request made by a user. I want to <strong>assign session numbers</strong> to these rows. Different IP-addresses have different session numbers. The same IP should be assigned a new session number <strong>if the last request is older than 30min</strong>. Here is a sample output:</p>\n\n<pre><code>IP,      DateTime,         SessionNumber, RequestNumber\n1.1.1.1, 2012-01-01 00:01, 1,             1\n1.1.1.1, 2012-01-01 00:02, 1,             2\n1.1.1.1, 2012-01-01 00:03, 1,             3\n1.1.1.2, 2012-01-01 00:04, 2,             1 --different IP =&gt; new session number\n1.1.1.2, 2012-01-01 00:05, 2,             2\n1.1.1.2, 2012-01-01 00:40, 3,             1 --same IP, but last request 35min ago (&gt; 30min)\n</code></pre>\n\n<p>Columns 1 and 2 are inputs, 3 and 4 are the desired outputs. The table shows two users.</p>\n\n<p>As the underlying is table is truely large, <strong>how can this be solved efficiently</strong>? I'd prefer a small constant amount of passes over the data (one or two).</p>\n"},{"tags":["security","browser","mdx","olap","xmla"],"answer_count":2,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":307,"score":2,"question_id":8598998,"title":"Is client-side OLAP (e.g. client-side MDX construction plus xmla4js) bad for security?","body":"<p>I'm working on a public-facing web project that will be powered in part by an OLAP server. I wanted to compare a couple ways of doing this from a security perspective:</p>\n\n<ol>\n<li><p>My initial idea was to pass some representation of the user's intent to the web server via AJAX, have the web server do lots of input validation and construct an appropriate MDX expression to pass to the OLAP server, and finally proxy the OLAP results back to the browser. (Tangentially, this seems to be the approach taken by <a href=\"http://jpivot.sourceforge.net/\" rel=\"nofollow\">jpivot</a>; e.g. I just clicked to drill down into a table in a jpivot example, and what got sent to the server wasn't MDX but simply the x-www-form-urlencoded string \"wcf65768426.x=3&amp;wcf65768426.y=3\".)</p></li>\n<li><p>In contrast, the <a href=\"http://code.google.com/p/xmla4js/\" rel=\"nofollow\">xmla4js</a> project seems premised on opening up a firewall port and exposing your OLAP server to the world (or at least to your particular customers) via XML/A, writing MDX queries in client-side javascript, and having the browser directly hit the OLAP server.</p></li>\n</ol>\n\n<p>My gut reaction is to be quite suspicious of the second approach. It seems to presume that nothing bad can happen if someone were to execute arbitrary MDX statements against my OLAP server. I'm not yet a student of particularly advanced MDX, but it's not immediately obvious to me that this is a risk-free proposition. At very least someone could kick off some very expensive queries, or download a larger chunk of your dataset than you were hoping to easily make available to people. This isn't the sort of thing people generally do with SQL servers, and I'm initially inclined to think the same reasons suggest you shouldn't do it with OLAP servers either.</p>\n\n<p>But I'd also like to assume that the folks behind xmla4js had some use cases in mind that were not crazy security risks. And I guess potentially I could be thinking about this too cautiously.</p>\n\n<p>Any more experienced OLAP folks want to comment on the wisdom of letting people directly bang on your OLAP server, e.g. via XML/A?</p>\n"},{"tags":["c#","ado.net","mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":131,"score":1,"question_id":9984624,"title":"Querying OLAP server","body":"<p>I use the following code to execute a query in C#:</p>\n\n<pre><code> AdomdConnection con = new AdomdConnection(\"Datasource=local;...\");\n\n            con.Open();\n            AdomdCommand command = con.CreateCommand();\n            command.CommandText = input;\n\n            AdomdDataReader reader = command.ExecuteReader();\n  while (reader.Read())\n            {\nfor(i =0; i&lt;reader.fieldCount; i++){\n      a[i]=reader.GetString(i);\n}\nreturn a;\n</code></pre>\n\n<p>Howeever, this code returns the full path in the hierarchy for each cell. I.e., each row of data is like [AllGeography, Canada, Vancouver, Allproduct, bikes, accessories, 297483].\nI want to retrieve only the leaves and the measure value that is :[vancouver, accessories, 297483]. What should I do? How I can specify the leaves?</p>\n"},{"tags":["join","olap","mondrian","cross-join"],"answer_count":4,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":771,"score":2,"question_id":8190943,"title":"Are Mondrian / OLAP the wrong tool for joining large dimensions/sets?","body":"<p>Summary: Most of the examples I've seen of MDX joins have involved joining relatively small sets, say with tens or hundreds of items each. But I find myself also wanting to try joining (in particular \"non-empty joining\") sets that have thousands or tens of thousands of items each, and it's not working well so far. I'm wondering if this could be made to work, or if I perhaps need to consider using something other than Mondrian/OLAP.</p>\n\n<p>To be concrete, I have a cube that records interactions between Firms (n=7000) and Clients (n=27000). Currently both Firm and Client are completely flat hierarchies; there's the All level and the individual-company level, with no other levels in between. There is a central fact table, and separate dimension tables for Firms and for Clients.</p>\n\n<p>My users at least appear to want to get summary reports along these lines, aggregating all the non-empty interactions between Firms and Clients:</p>\n\n<pre><code>select\n  [Measures].[Amount] on columns,\n  NonEmptyCrossJoin([Firm].Children,\n                      [Client].Children) on rows\nfrom MyCube\n</code></pre>\n\n<p>But this query and variations on it don't work in my test Mondrian setup. Either I get an OutOfMemoryException (on a 2GB Java heap), or Java seems to spend impossibly long time in mondrian.rolap.RolapResult$AxisMember.mergeTuple(TupleCursor). (I can provide a more complete stack trace if it would help.) By \"impossibly long\" I mean Java will stay slaving away at the query for hours and hours before I give up.</p>\n\n<p>I initially expected the above query to perform ok, because conceptually it could be done <em>somewhat</em> efficiently by just doing a SQL query along these lines:</p>\n\n<pre><code>select Firm, Client, Sum(Amount) as n\nfrom fact, firm, client\nwhere fact.firmid = firm.firmid and fact.clientid = client.clientid\ngroup by Firm, Client\n</code></pre>\n\n<p>(In fact, if I execute something like this directly in MySql it doesn't take more than 15sec to execute.)</p>\n\n<p>But from the debug logs Mondrian doesn't seem to attempt this optimization.  Instead it appears to be doing the join internally, and in a way that ends up being particularly slow. I've set mondrian.native.crossjoin.enable=true in my mondrian.properties, but this doesn't seem like one of the join types that Mondrian is able to \"make native\".  (If I turn on mondrian.native.unsupported.alert=ERROR then I get the corresponding exception.)</p>\n\n<p>I'm left wondering whether I need to prevent my users from attempting joins on such large dimensions/sets, or whether Mondrian is maybe not the tool I'm looking for here. But maybe I'm just doing something wrong.</p>\n"},{"tags":["mdx","olap","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":567,"score":0,"question_id":9895611,"title":"How to create a period over period Measurement in MDX?","body":"<p>I'm fairly new to MDX queries, and I'm having trouble understanding how I might compute a period over period measurement.  For example say I have a metric like revenue, and I'm breaking that revenue out over time say on a Month to Month basis.  How would I calculate the change from Month to Month of that revenue as a percent?  Now let's say I want to calculate that generically over any period, quarter to quarter, year to year, month to month, or even compare it with identical periods from prior years.  2011 Q1 vs 2012 Q1, 2011 Q2 vs 2012 Q2, etc.</p>\n\n<p><img src=\"http://i.stack.imgur.com/xNIZg.png\" alt=\"Time Dimension\"></p>\n\n<p>Schema definition:</p>\n\n<pre><code>&lt;Dimension type=\"TimeDimension\" highCardinality=\"false\" name=\"Time\"&gt;\n    &lt;Hierarchy name=\"yearQuarterMonth\" caption=\"Year/Quarter/Month\" hasAll=\"true\" primaryKey=\"id\"&gt;\n        &lt;Table name=\"Time\"/&gt;\n        &lt;Level name=\"Year\" column=\"year\" type=\"Numeric\" uniqueMembers=\"true\" levelType=\"TimeYears\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Quarter\" column=\"quarter\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeQuarters\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Month\" column=\"month\" type=\"Numeric\" ordinalColumn=\"month\" uniqueMembers=\"false\" levelType=\"TimeMonths\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Day\" column=\"day\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeDays\" hideMemberIf=\"Never\"/&gt;\n    &lt;/Hierarchy&gt;\n    &lt;Hierarchy name=\"fiscalYearQuarterMonth\" caption=\"Fiscal Year/Quarter/Month\" hasAll=\"true\" primaryKey=\"id\"&gt;\n        &lt;Table name=\"Time\"/&gt;\n        &lt;Level name=\"Fiscal Year\" column=\"fiscal_year\" type=\"Numeric\" uniqueMembers=\"true\" levelType=\"TimeYears\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Quarter\" column=\"quarter\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeQuarters\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Month\" column=\"month\" type=\"Numeric\" ordinalColumn=\"month\" uniqueMembers=\"false\" levelType=\"TimeMonths\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Day\" column=\"day\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeDays\" hideMemberIf=\"Never\"/&gt;\n    &lt;/Hierarchy&gt;\n    &lt;Hierarchy name=\"yearMonth\" caption=\"Year/Month\" hasAll=\"true\" primaryKey=\"id\"&gt;\n        &lt;Table name=\"Time\"/&gt;\n        &lt;Level name=\"Year\" column=\"year\" type=\"Numeric\" uniqueMembers=\"true\" levelType=\"TimeYears\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Month\" column=\"month\" type=\"Numeric\" ordinalColumn=\"month\" uniqueMembers=\"false\" levelType=\"TimeMonths\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Day\" column=\"day\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeDays\" hideMemberIf=\"Never\"/&gt;\n    &lt;/Hierarchy&gt;\n    &lt;Hierarchy name=\"fiscalYearMonth\" caption=\"Fiscal Year/Month\" hasAll=\"true\" primaryKey=\"id\"&gt;\n        &lt;Table name=\"Time\"/&gt;\n        &lt;Level name=\"Fiscal Year\" column=\"fiscal_year\" type=\"Numeric\" uniqueMembers=\"true\" levelType=\"TimeYears\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Month\" column=\"month\" type=\"Numeric\" ordinalColumn=\"month\" uniqueMembers=\"false\" levelType=\"TimeMonths\" hideMemberIf=\"Never\"/&gt;\n        &lt;Level name=\"Day\" column=\"day\" type=\"Numeric\" uniqueMembers=\"false\" levelType=\"TimeDays\" hideMemberIf=\"Never\"/&gt;\n    &lt;/Hierarchy&gt;\n&lt;/Dimension&gt;\n</code></pre>\n"},{"tags":["java","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":1,"view_count":806,"score":-1,"question_id":2683361,"title":"how create and query a cube olap","body":"<p>how can I create a cube olap with oracle, \nhow load the data from sources tou the dimentions and the fact table in the cube\nand how can I query this cube within a java Application.</p>\n\n<p>thanks for your help</p>\n"},{"tags":["ssas","olap","olap-cube","ssas-2008"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":145,"score":0,"question_id":9875222,"title":"SSAS Role based dimension permission","body":"<p>I use SSAS 2008 and SQL2008R2.</p>\n\n<p>I have 3 Tables:</p>\n\n<ol>\n<li><p>Customers (PK id, FK Manager_Id)</p></li>\n<li><p>Managers (PK id)</p></li>\n<li><p>SalesOrders (PD id, FP Customer_Id, integer Quantity)</p>\n\n<ul>\n<li><p>I've created dimension Customers (Hirerachy parent-child)</p></li>\n<li><p>I've created dimension Managers (Hirerachy parent-child)</p></li>\n<li><p>I've created olap cube with these twho dimensions with Measure Quantity.</p></li>\n</ul></li>\n</ol>\n\n<p>So now I want to restrict the access to my olap data by managers.</p>\n\n<p>I've created a role based on some AD account, selected data source, olap cube. Next I selected the manager correspondig this AD account from the Dimension Data tab (actualy this is Sales manager, so because of manager dimension is a hierrachy it selects also Its manager and Manager's Manager and so on...).</p>\n\n<p>The problem is then I browse the cube as this security person I got filtered Managers dimension field in Excel (that's sweet), BUT my customers are still independent of it! I mean then I select this only one manager from the list it filters the customers, but if I remove dimension from the pivot table I get rhe whole cumsers list. And I need to get only the role based person's list of customers. </p>\n\n<p>Please, help me to solve this problem... How can I restrict the access to the olap data?</p>\n\n<p><a href=\"http://i39.tinypic.com/jb1gxv.png\" rel=\"nofollow\">Here is my olap structure snapshot</a></p>\n"},{"tags":["php","mongodb","analytics","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":661,"score":2,"question_id":9837297,"title":"OLAP cube - PHP and MongoDB","body":"<p>I need to create an analytics system. I already built the system using MognoDB and PHP but without using OLAP. Now my queries are really the best I can get, but the system is really slow because no cube. It can take a minute to load a report for the last 7 days. I really need the options of the cube - slice &amp; dice.</p>\n\n<p>So what would be the solution for me? Is there a good cube system build with MongoDB and that can insert &amp; view data via PHP? Maybe MongoDB won't be good for me? Should I use another database and start all the system from 0? What OLAP solutions there are using PHP?</p>\n\n<p>Edit: More info --\nWell, the system is like google analytics. Need to be able to know how much views in every day, need to be able to report from only a specified traffic source and country. The system needs to handle 1,000,000 unique view each day. \nBut not only count of views, there needs to be able to see how much users are returning, what is the average time for every user, etc.</p>\n\n<p>Thanks.</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":112,"score":0,"question_id":9688752,"title":"Previous Year's End Value","body":"<p>I'm trying to retrieve the previous year's end value of a measure.</p>\n\n<p>I know this code gets the value of the previous year, but at the same point in time during that year (so Mar 2012 looks to Mar 2011).</p>\n\n<pre><code>([Measures].[MeasureName], ParallelPeriod([Time].[Calendar].[Year]))\n</code></pre>\n\n<p>I'd like any date in 2012 to look at the last value in 2011 (Dec 2011). So if we're looking at the Year level of 2012 or any Month level, it all points to Dec 2011.</p>\n"},{"tags":["olap","dimensional-modeling"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":104,"score":2,"question_id":9692467,"title":"designing type 2 dimensions","body":"<p>I have a question about type 2 dimensions.</p>\n\n<p>Within our HR system, it is possible to hire an employee with one date, and then at a later point in time, change the hire date if it had been entered incorrectly in the first place. This gets complicated when using Type 2 dimensions as the change would result in a new record in the dimension table.</p>\n\n<p>So, I basically need a way to say that some updates (such as the one above) shouldn't result in a new record in the dimension table. But, for other instances such as if an employee moves to a new position, then I definitely need to create a record in the dimension table.</p>\n\n<p>What are my options here?</p>\n"},{"tags":["design-patterns","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":166,"score":1,"question_id":7359581,"title":"Disruptor and OLAP","body":"<p>I've just been watching the QCON presentation about Disruptor. It looks like (and it may well be I've not fully grasped it - so SIA) this is good for OLTP, but I am not sure whether it is also useful for OLAP-type applications. It fundamentally seems to be around access to/response from (and in fact re-architecting) your business logic for optimal OLTP performance. </p>\n\n<p>So, would there any benefit for an OLAP application (other than the efficient management of requests/responses) and is so what are the kind of things you'd need to consider and where could it be applied ? Or perhaps it is just wrong to try an apply it in this area?</p>\n\n<p>Thx</p>\n\n<p>S</p>\n"},{"tags":["clojure","olap","aggregation"],"answer_count":2,"favorite_count":0,"up_vote_count":4,"down_vote_count":0,"view_count":140,"score":4,"question_id":9670172,"title":"Pre-aggregated datastructure in clojure","body":"<p>In OLAP-cubes it's possible to do very quick look ups on large amounts of aggregated data. The major reason for this is that one pre-aggregates data in operations which are easy to combine upwards (mainly +, -, mean, std, max, min and some more).</p>\n\n<p>How to get this \"anti-lazy\" behaviour in clojure?</p>\n\n<p>I'm thinking on something like</p>\n\n<pre><code>(def world-population {:africa 4e8            ;;this is an aggregation!\n                       :africa/liberia 3.4e6\n                       :africa/ethiopia 7.4e7\n                       ...})\n</code></pre>\n\n<p>How to update a datastructure like this and make sure the parents of an entity is updated too? Do one have to roll one's own ref-implementation? </p>\n"},{"tags":["olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":189,"score":0,"question_id":9656465,"title":"How could use Multi Fact Table in OLAP Cube?","body":"<p>In my project there is an existing OLAP Cube includes examination information. That has two fact table and multi dimensions . First fact table fields: ExaminationID, Date, Doctor etc. Second fact table include treatment information. An examination has more than one treatments or no treatment. So I have to create 2 fact tables. The cube create two measure gorups: examination count and  treatment count.</p>\n\n<p>I expected to get all examinations even if examination do not have a treatment. But Cube only takes examinations that have a treatment. If I have 10 examination but only 8 of them have a tretament  Examination Count must be 10 Treatment Count must be 8. But I do not get the result as I expect to. How could I do this? </p>\n"},{"tags":["sql-server-2008","devexpress","ssas","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":143,"score":0,"question_id":9606438,"title":"Switching to US English msmdsrv.rll Analysis Services","body":"<p>I'm using Analysis Services for a web application I'm building, I have my Analysis Service running, I included a PivotGrid from DevExpress on a web page, I checked on SQLServer that my cube is displaying information, and it does, but when I run my application the PivotGrid doesn't display the data, I checked the logs on the EventViewer and I get the following error:</p>\n\n<blockquote>\n  <p>The resource file 'msmdsrv.rll' for locale '1034' could not be loaded.\n  Switching to US English (1033) if available.</p>\n</blockquote>\n\n<p>Obviously this is about the language the cube is trying to find, I changed the language to English (United States) in the dropdown list included at the top of SQLServer but I still getting the error, any suggestion?</p>\n\n<p>Thanks in advanced.</p>\n"},{"tags":[".net","ssas","olap","pivot-table","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":322,"score":0,"question_id":9504386,"title":"Find a olap web-interface like Excel (chart and grid)","body":"<p>My company is looking for libraries which can do the same things as Excel with dynamic pivot tables (ODC files for example).</p>\n\n<p>We have Windows 2008 R2 Server, SQL Server 2008 R2, and MS Analysis Services.</p>\n\n<p>We want to make a website where people from the company can manipulate datas from a cube. So this library need to work in IIS on server side.</p>\n\n<p>I found this : <a href=\"http://www.radar-soft.com/\" rel=\"nofollow\">http://www.radar-soft.com/</a></p>\n\n<p>It was perfect because it's a VS control. So I had just to create a new website and put the good control on it.</p>\n\n<p>But the demo software is bugged and when I try to use the example with our cube, Silverlight is freezing and splashed...</p>\n\n<p>Anybody use a control like this ? Maybe have you any other ideas ?</p>\n\n<p>Thanks in advance,</p>\n"},{"tags":["sql-server","database","olap","cubes"],"answer_count":3,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":418,"score":3,"question_id":2065031,"title":"book suggestions to learn about olap","body":"<p>I want to learn about olap and 'cubes', I have a very limited understanding and looking for recommendations on good beginner books on these sort of topics.</p>\n\n<p>I use sql server primarily so if the book is geared towards sql server it would be ideal.</p>\n"},{"tags":["ssas","olap","cube","dimension","fact"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":131,"score":0,"question_id":9405674,"title":"Dimension design - two facts relate to same dimension and different grains","body":"<p>I have an Employee Dimension that contains attributes for the company the person works for. Employees can have membership (a fact that has a start and end date) but so can companies. How do I handle this? Should I split off the company information into a separate dimension and remove it from the Employee dimension altogether or do something else?</p>\n\n<pre><code>User hierarchy in Employee dimension:\nCompany Name &lt;-- I currently don't have a separate Company dimension\n  Employee Name\n\nFact Company Membership\n  CompanyKey &lt;-- Here is where the problem is\n  StartDateKey\n  EndDateKey\n\nFact Employee Membership\n  EmployeeKey &lt;-- No problem here because I have an Employee Dimension\n  StartDateKey\n  EndDateKey\n</code></pre>\n"},{"tags":["jasper-reports","ireport","mdx","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":183,"score":0,"question_id":9392019,"title":"Results from 2 mdx queries on same jaspersoft report","body":"<p>I have 2 mdx queries. Each of them return 1 record with 1 column.<br><br> I am interested in showing single tuple value from each mdx query result side by side on same report (using jaspersoft ireport). </p>\n\n<p>Note: The 2 mdx queries are fetching data from different cubes and there is no connection between the data.</p>\n"},{"tags":["database","database-design","olap"],"answer_count":5,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":60,"score":1,"question_id":9382646,"title":"How to model an optional breakdown of a column","body":"<p>I'm coming up with a design for a database that will allow queries over historic transactions, and I'm stumped with this particular issue.</p>\n\n<p>One of the columns to be stored is, let's say, number of sales per day (to be broken down by a variety of attributes).  With recent data, we can break this down into online and in-store sales; however, before a certain cut-off the only information available to populate this database is the total sales figure, without the breakdown.</p>\n\n<p>I can't think of a particularly elegant way to present this, such that newer data can populate the logical \"Online Sales\" and \"In-store sales\" columns, with \"Total Sales\" being computed as their sum (in a view/sproc/computed column) - and yet old data can just report the total sales figure.</p>\n\n<p>FWIW clients of this data will be aware that the sales breakdown may or may not be there - so the output of a query would always have a valid \"Total sales\" figure, and might have missing values for online or in-store sales.  (I specifically say \"missing\" instead of \"null\" as there's no strong requirement to have it represented as such, if an alternative makes more sense.)</p>\n\n<p>Is there a canonical way to handle this situation?</p>\n\n<hr>\n\n<p>Given a lack of strong responses so far, I'll post a few answers of my own that I see as candidates (I may end up needing to accept one of them anyway if no superior answers materialise).  Comments, criticism and or votes on these are graciously accepted - and especially improvements to them.</p>\n"},{"tags":["tfs","process","ssas","analysis","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":191,"score":1,"question_id":9359690,"title":"TFS Analysis Rebuild Error: column does not contain valid bindings to data and cannot be processed","body":"<p>I am having an issue on my TFS 2010 instance. After a rebuild in the Reporting Tab of TFS I am not getting an error when the Cube full sync happenings. So it looks like the warehouse build happens successfully, but the analysis services build does not. Here is the error.</p>\n\n<blockquote>\n  <p>[Full Analysis Database Sync]:  AnalysisDatabaseProcessingType=Full,\n  needCubeSchemaUpdate=True. \n  Microsoft.TeamFoundation.Server.WarehouseException: TF221122: An error\n  occurred running job Full Analysis Database Sync for team project\n  collection or Team Foundation server TEAM FOUNDATION. \n  Microsoft.TeamFoundation.Server.WarehouseException: Failed to Process\n  Analysis Database 'Tfs_Analysis'. \n  Microsoft.TeamFoundation.Server.WarehouseException: Error (Data\n  mining): In the <strong>'Tfs_AnalysisDataSource Structure' structure, the\n  'BuildSK' column does not contain valid bindings to data and cannot be\n  processed.</strong></p>\n  \n  <p>at\n  Microsoft.TeamFoundation.Warehouse.TFSOlapProcessComponent.ExecuteXmla(String\n  finalXmla) at\n  Microsoft.TeamFoundation.Warehouse.TFSOlapProcessComponent.ProcessOlap(AnalysisDatabaseProcessingType\n  processingType, WarehouseChanges warehouseChanges, Boolean\n  lastProcessingFailed, Boolean cubeSchemaUpdateNeeded)\n  --- End of inner exception stack trace --- at Microsoft.TeamFoundation.Warehouse.TFSOlapProcessComponent.ProcessOlap(AnalysisDatabaseProcessingType\n  processingType, WarehouseChanges warehouseChanges, Boolean\n  lastProcessingFailed, Boolean cubeSchemaUpdateNeeded) at\n  Microsoft.TeamFoundation.Warehouse.AnalysisDatabaseSyncJobExtension.RunInternal(TeamFoundationRequestContext\n  requestContext, TeamFoundationJobDefinition jobDefinition, DateTime\n  queueTime, String&amp; resultMessage) at\n  Microsoft.TeamFoundation.Warehouse.WarehouseJobExtension.Run(TeamFoundationRequestContext\n  requestContext, TeamFoundationJobDefinition jobDefinition, DateTime\n  queueTime, String&amp; resultMessage)\n  --- End of inner exception stack trace ---</p>\n</blockquote>\n\n<p>Any help would be really appreciated, </p>\n\n<p>I have tried rebuilding and looking to see what structure that might be causing this. I have actually changed anything in any of the mining cubes etc so don't know why this has started happening.</p>\n\n<hr>\n\n<p><strong>UPDATE !!!!</strong>\nI have gotten the incremental sync to work by</p>\n\n<ol>\n<li>Switching off the Analysis</li>\n<li>Disabling all of the Warehouse sync jobs.</li>\n<li>1 by 1 enabling all of the Warehouse jobs and running them Starting</li>\n<li>the analysis jobs again 5 Running the incremental sync.</li>\n</ol>\n\n<p>So it seems to me like it may be to do with a lock of some kind. I havent tried the full sync yet as I am a little gun shy and have a presentation on the reports in the morning.</p>\n\n<hr>\n\n<p><strong>UPDATE !!!!</strong>\nThe full analysis database sync has happened over night without any issues.</p>\n\n<p>So the steps above should work where locks are not allowing schema changes.\nDave</p>\n"},{"tags":["hadoop","benchmarking","olap"],"answer_count":0,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":334,"score":0,"question_id":9371699,"title":"OLAP with Hadoop","body":"<p>Can anybody share a story about building an OLAP system using Hadoop/Hive or similar stack?\nSo far I've found <a href=\"http://people.cs.kuleuven.be/~bettina.berendt/teaching/2010-11-2ndsemester/ctdb/petabyte_facebook.pdf\" rel=\"nofollow\">this paper</a> I'd love to hear about smaller, medium size implementations.</p>\n\n<p>References to good benchmarks would also be very useful.  So far I found <a href=\"https://issues.apache.org/jira/secure/attachment/12411185/hive_benchmark_2009-06-18.pdf\" rel=\"nofollow\">one benchmark</a> but I'd love to see some graphs on how performance changes with the size of tables/number of nodes.  I'm sure there are pure Hadoop benchmarks around but I'm more interested in specifically Hive benchmarks because they make it easier to get a feel on how OLAP would behave.</p>\n"},{"tags":["sql-server-2008","ssis","nservicebus","olap","cqrs"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":226,"score":0,"question_id":9359052,"title":"OLTP to OLAP with CQRS or SSIS","body":"<h1><em>Background Information</em></h1>\n\n<p>Our application reads/writes from 3 components:</p>\n\n<ol>\n<li>ASP.NET MVC 3 customer front end website (write actions)</li>\n<li>Winform verification tool at stores (write actions)</li>\n<li>Silverlight Dashboard for tenant (95% aggregate reads 5% write actions)</li>\n</ol>\n\n<p>(3) is the only piece that can use some performance improvements.</p>\n\n<p>Our storage is Sql Server Standard OLTP database that has stored procedures that aggregate data consumed by the silverlight app.</p>\n\n<p>When using database tuning advisor or execution plan we don't see any critical indexes missing and we rebuild indexes with sql agent job.</p>\n\n<p>Most of the widgets are sparklines</p>\n\n<ul>\n<li>x = time selected by interval (day, week, month, year)</li>\n<li>y = aggregate (sum,avg,ect)</li>\n</ul>\n\n<p>currently we return about 14 - 20 points per widget. Our dashboard opens with 10 widgets initially.</p>\n\n<p>Our dimensions would be: tenant, store, (day,week,month,year)</p>\n\n<p>Our facts: completed, incomplete, redeemed, score ...</p>\n\n<p>I know a denormalized table will remove needing sql server from recalculating for\nstore managers, franchise owners, corporate viewing the data ~50 (simultaneous users)\neach time</p>\n\n<p>I'll be honest if we go with OLAP it will be my first hands on experience with it.</p>\n\n<h1><em>Questions</em></h1>\n\n<p>What is the long term solution for a rich reporting dashboard?</p>\n\n<p>I would assume OLAP.  If so, how would you keep it up to date to be near realtime dashboard that we have today?\nPutting a maintenance page while OLAP rebuilds itself is not an option.\nIdeally, we would want to do this incrementally and see Nservicebus (which we use today already) as a great bridge to update these \ndenormalized views.   Do we put these denormalized views in oltp as just another table or is there a way to incrementally update OLAP datasource?</p>\n\n<h1><em>References</em></h1>\n\n<p><a href=\"http://www.udidahan.com/2009/12/09/clarified-cqrs/\" rel=\"nofollow\">http://www.udidahan.com/2009/12/09/clarified-cqrs/</a></p>\n\n<p><a href=\"http://www.udidahan.com/2011/10/02/why-you-should-be-using-cqrs-almost-everywhere%E2%80%A6/\" rel=\"nofollow\">http://www.udidahan.com/2011/10/02/why-you-should-be-using-cqrs-almost-everywhere%E2%80%A6/</a></p>\n"},{"tags":["translation","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":330,"score":0,"question_id":9269773,"title":"SSAS 2008, Translate Hierarchy members in parent-child hierarchy","body":"<p>I'm creating my dimensions and parent-child hierarchies using AMO objects. One of the requirements is to translate the hierarchy members into another language.</p>\n\n<p>While accessing the newly created cube in the BIDS, I am able to provide translation for the attributes in Dimension Editor, but I'm not sure how do I do the same for the  hierarchy. \nMy DimCompany table has a few fields, including CompanyKey, CompanyParent, CompanyName, CompanyRusName. The last one is to be used to translate attributes and hierarchy members.</p>\n\n<p>I have provided a couple of screenshots explaining the existing situation. </p>\n\n<p>Unfortunately, I can't post images, so just a couple of links here: </p>\n\n<ul>\n<li>\"English language - all fine\" <a href=\"http://db.tt/PjshtUKt\" rel=\"nofollow\">http://db.tt/PjshtUKt</a></li>\n<li>\"Russian language - problems with hierarchy members\"\n<a href=\"http://db.tt/4Rf3yM2j\" rel=\"nofollow\">http://db.tt/4Rf3yM2j</a></li>\n</ul>\n\n<p>I'd very grateful for any hints and suggestions!</p>\n\n<p>Regards,\nGaliya</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":176,"score":1,"question_id":9196512,"title":"Mdx Sum returns non integer value","body":"<p>When have a issue at work where the value returned by the SUM() function isn't treated like a \"normal\" number when using the value returned together with the Round() function.</p>\n\n<p>Try this MDX for example</p>\n\n<pre><code>WITH \nMEMBER SomeNumber AS 0.595 \nSET SomeNumberSet AS \n           {[SomeNumber], [SomeNumber], [SomeNumber], [SomeNumber], [SomeNumber], [SomeNumber], [SomeNumber], [SomeNumber] }\n\nMEMBER SomeNumberSum AS\nRound(SUM([SomeNumberSet], [Measures].[SomeNumber]) / 8, 2)\n\n\nSELECT [SomeNumberSum] ON 0\n\nFROM [SomeCube]\n</code></pre>\n\n<p>This code returns 0.59, the sum of sets are 4,76, which are then divided by 8 = 0,595. Since MDX is using Bankers rounding this SHOULD be rounded to 0.60.</p>\n\n<p>Just using Round(0,595) gives us the correct result.</p>\n\n<p>Whats even more strange is that if we in the set only uses the SomeNumber 6 times or less and in the Round Function divide with the same multiplier we get 0.6 (which is correct)</p>\n\n<p>Also, if I wrap the Sum() with the StrToValue() function, it works, even if I use more than 5 SomeNumbers in the set</p>\n\n<p>Whats going on?!</p>\n"},{"tags":["aggregate-functions","olap","analysis-services","olap-cube","measure"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":595,"score":0,"question_id":4103111,"title":"Non-aggregated measure in OLAP cube","body":"<p>Is possible to add a non-aggregated measure to an OLAP cube? for example I have a 'Datetime' field in my relational DB, and I would like to not use any kind of aggregation function when querying this measure of the cube. is there any scenario where this could be possible?</p>\n"},{"tags":["java","sql","oracle","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":330,"score":1,"question_id":9207073,"title":"column names for an ad-hoc sql","body":"<p>My programm will get an input of a valid sql, and should return column names for the sql.\nAnd I want to do this with out executing the sql statement at all. I am looking for a java solution.</p>\n\n<p>My dbms is oracle optimized for olap, and the tables are so big that result set restriction does not working. Actually execution time is not acceptable for my case. it takes longer than a minute</p>\n"},{"tags":["mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":161,"score":0,"question_id":9154485,"title":"MDX custom rollup formula","body":"<p>Hi to all people that use this very useful site.</p>\n\n<p>I explain my problem with MDX CUSTOM ROLLUP FORMULA.<br>\nI discover that recently, and I try to solve my problem with that, but I was not able to.</p>\n\n<p>I have a dimension called <code>'FILIALI'</code>  (That is Italian language in English STORES..)<br>\nThis dimension has an attribute key and a hierarchy that contains 2 levels.<br>\nThese 2 levels are <code>'Region'</code> and <code>'NameofStore'</code><br>\nFirst level <code>'Region'</code> and if I click over <code>'Region'</code> I can see level <code>'NameofStore'</code></p>\n\n<p>I need for a department obtain a very strange report with excel connected to my OLAP CUBE.</p>\n\n<p>That is:</p>\n\n<pre><code>REGION         NAMEOFSTORE     EURO\n\nAAA            PIPPO           10\n               PLUTO           20\n               CLARA           30\n               EZIO            40\nTotal                          70 !!!!!!!!!!!!!!!\n</code></pre>\n\n<p>So they want to see all second level members BUT they want total is only calculated from 2 members of all members.</p>\n\n<p>So I tried used UNARY OPERATORS but I could not to solve it.</p>\n\n<p>I tried using CUSTOM ROLLUP FORMULA but I could only to do this :</p>\n\n<pre><code>AAA            PIPPO           0\n               PLUTO           0\n               CLARA           30\n               EZIO            40\nTotal                          70 \n</code></pre>\n\n<p>I was able to obtain <code>TOTAL</code> correct but only because I inserted in property CUSTOM ROLLUP FORMULA  a formula like this:</p>\n\n<pre><code>'[Measures].[Euro] * 0  \n</code></pre>\n\n<p>In a field of the dimension table <code>'FILIALI'</code> only on the rows containing the members of what I do not want to calculate <code>TOTAL</code>.</p>\n\n<p>BUT HOW CAN I instead to view real value of all members BUT CALCULATE a CUSTOM TOTAL , excluding some of that members?</p>\n"},{"tags":["visual-studio","visual-studio-2010","visual-studio-2008","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":213,"score":0,"question_id":8073696,"title":"VS 2010 Connection to Cube","body":"<p>I want to have possibility to connect to Olap Cube, but cant figure a way to do it. The problem is that in VS 2010 Microsoft havent implemented Buisness inteligence logic/projects where a part of it is Analysis Services. In VS 2008 analysis services is implemented but silverlight 4 is not compatible with VS2008, and i need Silverlight 4 to complete my funktionality. </p>\n\n<p>i have already tryed : </p>\n\n<p>dataset\nOLeDBConnection\nADO.NET model\nLinq to SQL connection</p>\n\n<p>So, is there a way to connect to Olap Cube in VS 2010?  </p>\n"},{"tags":["set","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":132,"score":0,"question_id":9028451,"title":"Can OLAP measures be sets that aggregate via set-union, rather than numbers that aggregate via addition?","body":"<p>Typically measures in an OLAP cube are a numbers, and these numbers get aggregated via addition (or via some not-very-exotic function like times or MAX or MIN). I'm wondering if any of the major OLAP servers let you make measures that are <em>sets</em> of numbers, or <em>sets</em> of strings. (\"Set\" here is in the mathematical sense, not the OLAP jargon sense of \"a list of tuples\".) Whereas OLAP typically aggregates measures via numeric functions, my hypothetical \"set measures\" would be aggregated via set operations, e.g. set union or set intersection.</p>\n\n<p>I'm interested both theoretically and practically. Theoretically/abstractly/mathematically, there's a nice parallel between addition-over-integers and union-over-sets, and it seems like someone could have considered this parallel in writing an OLAP server. (One potential implementation, if all the possible set members were known in advance, is to represent each set as a (potentially large) integer, and then to aggregate/union by performing bitwise OR.)</p>\n\n<p>As for practice, I'll attempt to provide a concrete case where this might seem at least marginally useful: Suppose you had a dataset where each fact was the metadata associated with an academic paper. Each paper might have a date, a topic, and a set of one or more authors, like so:</p>\n\n<ul>\n<li>fact1: {\"Year\": 1997, \"Topic\" : \"AI\", \"AuthorSet\": [\"Bill Jones\", \"Martha X\"]}</li>\n<li>fact2: {\"Year\": 1997, \"Topic\" : \"Linguistics\", \"AuthorSet\": [\"John Q\", \"Sam S\"]}</li>\n<li>fact3: {\"Year\": 1997, \"Topic\" : \"Linguistics\", \"AuthorSet\": [\"John Q\", \"Jack X\"]}</li>\n<li>etc.</li>\n</ul>\n\n<p>(I'm using quasi-JSON here only because it helps make it obvious what's multi-valued.)</p>\n\n<p>If you created an OLAP cube around this data, it would seem very natural to be able to make a report showing how the set of authors writing on a given topic changed from year to year. In MDX, it might look like this:</p>\n\n<pre><code>select\n[Measures].[AuthorSet] on columns,\n[Year].[Year].All on rows\nwhere ([Topic].[Topic].[AI])\n</code></pre>\n\n<p>For each year, this query would roll up the list of authors via set union.</p>\n\n<p>To get the very most out of this feature you'd probably need custom OLAP client tools that knew about set measures in particular. But for existing clients you could probably just fall back to some string representation of a set. (e.g. the above query could return cells containing, e.g., the string \"Bill Jones; Martha X; John Q; Sam S; Jack X\")</p>\n\n<p>I'm most familiar with SSAS, and SSAS doesn't seem to support anything like this out of the box. It seems like there might be a way to hack it together using measures of string type, maybe plus custom CLR functions, but I haven't figured it out yet.</p>\n\n<p>This particular case you might also be able to solve in MDX only, maybe using custom members, Generate and SetToStr? (Solutions welcome!) But my intuition is that as things get more complicated it'd be more natural to have the set aggregation happen more naturally behind the scenes, with this \"set member\" functionality.</p>\n"},{"tags":["ssas","olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":84,"score":0,"question_id":9076362,"title":"How to limit number of dimension combinations?","body":"<p>Lets say I have got a cube with 3 dimensions. As far as I know OLAP(MOLAP) calculates and stores data in the most granular way so that I will have data for</p>\n\n<p>dim1</p>\n\n<p>dim2</p>\n\n<p>dim3</p>\n\n<p>dim1*dim2</p>\n\n<p>dim2*dim3</p>\n\n<p>dim1*dim3</p>\n\n<p>dim1*dim2*dim3</p>\n\n<p>However I am not interested breaking-down more than 2 levels. So the below data would be enough for me.(I do not need dim1*dim2*dim3)</p>\n\n<p>dim1</p>\n\n<p>dim2</p>\n\n<p>dim3</p>\n\n<p>dim1*dim2</p>\n\n<p>dim2*dim3</p>\n\n<p>dim1*dim3</p>\n\n<p>My questions is: Is there a way to tell MS Analysis Services to process only certain number of combinations?</p>\n\n<p>I would like to do this because I think this will have a huge performance impact. BTW I have 18 dimensions in real.</p>\n\n<p>One options may be to prepare a cube for each combination however this will lead to 153 combinations(=COMBI(18,2)) which is practically impossible.</p>\n\n<p>Thank You</p>\n"},{"tags":["sql-server-2008","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":20,"score":0,"question_id":9097456,"title":"OLAP Attribute Number Rounding?","body":"<p>Is there a way to format things in the cube?</p>\n\n<p>Some attributes are showing little errors for floats (1.00000000001) when I want to do something like \"%.2f\".</p>\n"},{"tags":["excel","olap","pivot-table"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":58,"score":0,"question_id":9030812,"title":"Excel Olap pivot slow using distant servers","body":"<p>I built a pivot table in Excel 2003 around a 15kb *.cub file hosted on my home network share and it refreshes instantly.</p>\n\n<p>If I copy the 15kb file to a server in another region e.g. UK or US then refreshing the pivot table takes ~5 seconds.  Is there anything I can do to eliminate some of this lag?</p>\n"},{"tags":["algorithm","data-structures","theory","olap","cubes"],"answer_count":2,"favorite_count":5,"up_vote_count":10,"down_vote_count":1,"view_count":717,"score":9,"question_id":736731,"title":"Anyone know anything about OLAP Internals?","body":"<p>I know a bit about database internals. I've actually implemented a small, simple relational database engine before, using ISAM structures on disk and BTree indexes and all that sort of thing. It was fun, and very educational. I know that I'm much more cognizant about carefully designing database schemas and writing queries now that I know a little bit more about how RDBMSs work under the hood.</p>\n\n<p>But I don't know anything about multidimensional OLAP data models, and I've had a hard time finding any useful information on the internet.</p>\n\n<p>How is the information stored on disk? What data structures comprise the cube? If a MOLAP model doesn't use tables, with columns and records, then... what? Especially in highly dimensional data, what kinds of data structures make the MOLAP model so efficient? Do MOLAP implementations use something analogous to RDBMS indexes?</p>\n\n<p>Why are OLAP servers so much better at processing ad hoc queries? The same sorts of aggregations that might take <em>hours</em> to process in an ordinary relational database can be processed in milliseconds in an OLTP cube. What are the underlying mechanics of the model that make that possible?</p>\n"},{"tags":["sql-server-2008","ssas","olap","cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":192,"score":0,"question_id":9017483,"title":"SQL Server Analysis Services 2008 - Help designing a multidimensional cube","body":"<p>I've a basic understanding of cubes, measures and dimensions. But this is the first time I am trying to design a multidimensional cube in SSAS. I could hardly find any easy-to-follow tutorial on web that'll help me in my task.</p>\n\n<p><strong>Requirement 1:</strong> I've a flat table: TableA. Some of the columns in the table are the Properties and I would like to treat these properties as the dimensions for the cube (E.g Category, Status, etc). The aggregation (count) will serve as the measure. I could add the Data Sources &amp; Data Source Views in the Analysis Server, but I am struggling with designing the cube. How do you specify what columns are dimensions, what calculation is the measure, etc </p>\n\n<p><strong>Requirement 2:</strong> There's another table: TableB. It contains the same rows as TableA but different columns (Properties) . I would like to use one of this Property as yet another dimension. There's no Foreign key relation between these tables, but their Primary keys can be correlated. How would you design this?</p>\n\n<p>All tips/links are welcome :)</p>\n"},{"tags":["sql","filter","multiple","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":357,"score":0,"question_id":8934252,"title":"MDX - Multiple Where and/or Filter Conditions","body":"<p>I apologize beforehand for a seemingly basic MDX question.  I am trying to filter an MDX resultset based on multiple combinations of dimension attributes.</p>\n\n<p>This is my dimension/measures layout:</p>\n\n<p>Dimensions:</p>\n\n<pre><code>[AccidentDate]\nYear\nQuarter\nMonth\nDay\nDate\n\n[ItemInformation] \nItemState\n\n[CoverageInformation] \nCoverageHiearchy\n----UserLine\n--- Coverage Code\n</code></pre>\n\n<p>Measures:</p>\n\n<pre><code>CTDPaid\n</code></pre>\n\n<p>Now, I wish to select the total amount from the <code>[CTDPaid]</code> measure, grouped by the <code>[ItemInformation].ItemState</code> attribute.  However, I would like to filter the resultset of this query based on multiple filter conditions.</p>\n\n<p>These conditions would be the following, and would be evaluated <strong>separately</strong>:</p>\n\n<pre><code>1. [CoverageInformation].[CoverageHiearchy].&amp;[98]&amp;[002] and [ItemInformation].ItemState.&amp;[MI]\n2. [CoverageInformation].[CoverageHiearchy].&amp;[98]&amp;[004] and [ItemInformation].ItemState.&amp;[MI]\n3. [CoverageInformation].[CoverageHiearchy].&amp;[98]&amp;[004] and [ItemInformation].ItemState.&amp;[IL]\n4. [CoverageInformation].[CoverageHiearchy].&amp;[98]&amp;[002] and [ItemInformation].ItemState.&amp;[IL]\n</code></pre>\n\n<p>Essentially, if I were to port this over to a T-SQL where condition, it would constitute the following:</p>\n\n<p>where</p>\n\n<pre><code>  (ItemState = 'MI' and CoverageCode = '002' and UserLine = '98')\n</code></pre>\n\n<p>and</p>\n\n<pre><code>  (ItemState = 'MI' and CoverageCode = '004' and UserLine = '98')\n</code></pre>\n\n<p>and</p>\n\n<pre><code>  (ItemState = 'IL' and CoverageCode = '002' and UserLine = '98')\n</code></pre>\n\n<p>and</p>\n\n<pre><code>  (ItemState = 'IL' and CoverageCode = '004' and UserLine = '98')\n</code></pre>\n\n<p>Putting this into an MDX slicer would not function as I believe cross joins across the same hierarchy are not supported.</p>\n\n<p>Using the filter() MDX function is not working for me either.</p>\n\n<p>I would greatly appreciate assistance with formulating the correct MDX query to correctly filter my resultset as outlined above.</p>\n\n<p>Thank you kindly for your time</p>\n"},{"tags":["mdx","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":92,"score":0,"question_id":8911547,"title":"NULL value treatment of day over day growth % calculation","body":"<p>I need to calculate day over day growth % for one of the measures.\nI used Time intelligence wizard, but the generated script does not treat null values properly.\nHere's the script:</p>\n\n<pre><code>Create Member \n CurrentCube.[Dim Time TB].[Calendar Dim Time TB Calculations].[Day Over Day Growth %] \n As \"NA\"; \n\n\nScope(\n      {\n        [Measures].[Fact Cointegration Stats VW Count]\n      }\n  ); \n\n  // Day Over Day Growth %  \n    ( \n    [Dim Time TB].[Calendar Dim Time TB Calculations].[Day Over Day Growth %],\n      [Dim Time TB].[DT KEY].[DT KEY].Members ( 1 ) : Null\n    ) \n\n =      \n\n (\n   ( \n     [Dim Time TB].[Calendar Dim Time TB Calculations].[Current Dim Time TB],\n     [Dim Time TB].[Calendar].CurrentMember\n   ) \n\n   -\n\n   ( \n     [Dim Time TB].[Calendar Dim Time TB Calculations].[Current Dim Time TB],\n     ParallelPeriod(\n                     [Dim Time TB].[Calendar].[DT KEY],\n                     1,\n                     [Dim Time TB].[Calendar].CurrentMember\n     )\n   )\n )\n\n /\n\n ( \n   [Dim Time TB].[Calendar Dim Time TB Calculations].[Current Dim Time TB],\n   ParallelPeriod(\n                   [Dim Time TB].[Calendar].[DT KEY],\n                   1,\n                   [Dim Time TB].[Calendar].CurrentMember\n   )\n ); \n\n ( \n   [Dim Time TB].[Calendar Dim Time TB Calculations].[Day Over Day Growth %],\n   [Dim Time TB].[DT KEY].[DT KEY].Members ( 0 ) \n ) = Null; \n\n Format_String( \n                ( \n               [Dim Time TB].[Calendar Dim Time TB Calculations].[Day       Over Day Growth %],\n               [Dim Time TB].[DT KEY].Members\n             )\n ) = \"Percent\";\n\n  End Scope;\n</code></pre>\n\n<p>Here's how the result looks like (The last Column is the \"Day over Day Growth %\" value):</p>\n\n<p>2009 January 20090101 180       1.#INF</p>\n\n<p>2009 January 20090102           -100.00%</p>\n\n<p>2009 January 20090103 180       1.#INF</p>\n\n<p>2009 January 20090104 180       0.00%</p>\n\n<p>As you can see, missing value for 20090102 leads to -100.00% and 1.#INF</p>\n\n<p>I realize that this is a completely newb question, but the work has to be done nevertheless, so any help will be greatly appreciated.</p>\n"},{"tags":["olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":78,"score":0,"question_id":8893203,"title":"How can i use two fact table of same dimensions for cube creating?","body":"<p>I will explain the problem with example.</p>\n\n<p>I have two sets of data</p>\n\n<ol>\n<li>actual</li>\n<li>budget  </li>\n</ol>\n\n<p>(both have same dimension here ex :<code>Date, product, type, etc)</code>.</p>\n\n<p>Both have same star schema.</p>\n\n<p>The facts are <code>margin, volume, revenue.....</code></p>\n\n<p>Pls explain me ... is it model is correct?\nbecause i need to find the variance for each level?</p>\n\n<p>ex : Feb2010 volume -  Feb2011 volume\n     2011 revenue - 2010 revenue</p>\n"},{"tags":["excel","ssas","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":456,"score":1,"question_id":4674308,"title":"Sorting numeric cube dimensions in Excel","body":"<p>I have a pretty simple analysis services cube with a numeric dimension. It works fine in the cube browser, the attribute is set to order by key and it's defined as an integer in the database table. When users connect to it using excel, the dimension initially displays in numeric order. However when the users try to reverse the sort, it now treats the numbers as strings and I'm getting an incorrect sort order, 92, 900, 87, 803, 79, 783, etc. Can excel not sort a numeric dimension from a cube?</p>\n\n<p>Thanks in advance.</p>\n"},{"tags":["ssas","olap","dimensions","cube","fact"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":91,"score":0,"question_id":8702422,"title":"I am not able to get dimensions and fact values while browsing cube in SSAS 2005","body":"<p>I am new to SSAS. I have two tables, FactAnswers and DimDebit. one dimension and one fact. After creating cube when I try to browse dimensions and fact, I got nothing. I want to get AnswerValue from fact table and Debit values from Dim table. Everything you can see in this figure.<img src=\"http://i.stack.imgur.com/VxWmi.png\" alt=\"My Cube\"></p>\n\n<p>Please guide me, Where I am wrong.</p>\n\n<p>Thanks</p>\n"},{"tags":["ssas","olap","dimensional-modeling"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":193,"score":0,"question_id":8246120,"title":"Correctly aggregate values from a one to many relationship in SSAS","body":"<p>So I have a dimensional database for shipments:</p>\n\n<p>A shipment contains many packages.\nA package contains many charges.</p>\n\n<p>Because this is dimensional and the charges are the data I'm most interested in, I've flattened the 3 tables and their many to one relationships into a single charges fact table. Here's a quick snapshot of a single shipment that contains two packages each weighing 1 lb.</p>\n\n<p><img src=\"http://i.stack.imgur.com/NwiNo.png\" alt=\"enter image description here\"></p>\n\n<p>In order to make package weight queryable I've needed to push it down to the charge grain. This causes problems with aggregation. A package weight of 1 lb applies to each package, and should result in 2 lbs for the shipment. I can't find a way to aggregate the weight as a measure in this fashion. I'm very new to SSAS and OLAP and don't really know what next to try. Any suggestions would be greatly appreciated.</p>\n"},{"tags":["ssas","olap","drillthrough"],"answer_count":4,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":392,"score":0,"question_id":8620314,"title":"Is it sensible to store long, unique text strings in OLAP cubes for drillthrough retrieval (especially in SSAS)?","body":"<p>I'm motivated to store some long text strings in an OLAP cube, long on the order of 1,000s or 10,000s of characters -- but I'm wondering if this will lead me astray. (I'm also curious to learn a little more about how OLAP engines handle strings.) The particular use case I have in mind is that I have a unique, pre-existing \"record description\" for each of my OLAP facts, and I want to put those descriptions in the cube so that I have the option to get them back when I do a DRILLTHROUGH operation. In contrast, I don't need the record descriptions to appear when doing normal pivot table / aggregate type operations. (The descriptions are too long to display sensibly in a pivot table, plus each fact has a unique description, meaning it doesn't make sense to aggregate over descriptions.) My current dataset has around 700,000 facts, though I'm also curious if the answer would change for larger datasets.</p>\n\n<p>My hope was that an OLAP server could do something sensible if I put these long strings in a cube. In the Sql Server / SSAS case in particular, I thought perhaps I'd put them in a dimension marked as ROLAP, to save memory usage, and use a degenerate dimension (aka a \"fact dimension\", in SSAS terminology), to avoid needless ETL complexities. But I'm curious if this would be regarded as a horrible practice for some reason, or if there are any hidden gotchas.</p>\n\n<p><strong>Update</strong>: My example use case is where you have a string associated with each OLAP fact. But it might also be instructive to consider the case where the strings are instead associated with each particular value of a particular dimension. (e.g. Suppose you had a Company dimension and each company had a somewhat lengthy Company Description string.)</p>\n"},{"tags":["sql-server-2008","olap","redistributable","adomd.net"],"answer_count":2,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":4876,"score":1,"question_id":442664,"title":"ADOMD.NET 9.0 Redistributable?","body":"<p>Got a problem with ADOMD.NET 8.0, SQL2008 and our app. It isn't giving us the right metadata.</p>\n\n<p>I can't find anywhere to download the ADOMD.NET 9.0 redistributable. Only way I can get it is by installing 2008 and grabbing the DLL.</p>\n\n<p>Any clues?</p>\n"},{"tags":["database","data","ssis","olap","rolap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":36,"score":0,"question_id":8791290,"title":"Storing large amounts of demographic data so it can be easily analysed - OLAP, ORM, custom solution?","body":"<p>We're building a database of demographics data for analysis; this data is all over the place, from crime data to census data to other stuff. We want to be able to dig in via geography, metric, or time period, and while we've done a lot of normalization so we can find out a lot of stuff about City A, it's obviously difficult to pull population data from one table and assault cases from another or data by year from three or four different data tables without lots of JOINing and UNIONing due to it's relational nature.  </p>\n\n<p>I know OLAP is meant for some of this, but when we're going to be adding data all the time, are we going to be overwhelmed with updating data cubes all the time?  And when users might often want very granular information, will all the aggregation calculations just be little-used overhead?</p>\n\n<p>Is there another alternative, data structure or ORM type that would make this easier? I hate to invest the time in a particular tool like SSAS if there is a better-fitting tool out there. Thanks for any input!</p>\n\n<p>[EDIT - I do intend to warehouse the data, and apply something like SSRS to it; I'm more asking if there are any factors in my situation where OLAP might not be the best choice or if there is a more suitable storage mechanism of any time.]</p>\n"},{"tags":["performance","devexpress","olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":134,"score":0,"question_id":8721167,"title":"Is it faster to bind to a dataset or a olap cube with a devexpress pivot grid?","body":"<p>I know you can do both but I'm looking for speed in the devexpress pivot grid.  Has anyone had any experience with the two?  I know you can do both.  We are pulling around 500,000 rows datatable to possibly 1 million rows.  Thanks in advanced to any of your suggestions or stories.</p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":127,"score":0,"question_id":8648575,"title":"OLAP dimension for Age","body":"<p>We have a client table with a field DateOfBirth. </p>\n\n<p>I'm new to MS Analysis Services, OLAP and data cubes. I'm trying to report on client metrics by age categories (18-25,26-35,35-50,50-65,66+)</p>\n\n<p>I don't see a way to accomplish this. (Note: I'm not concerned with age at the time of a sale. I'm interested in knowing the age distribution of my current active customers).</p>\n"},{"tags":["performance","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":568,"score":0,"question_id":8321014,"title":"Performance Tips For \"top 5 Bs for each A\" MDX Queries? (Especially SSAS)","body":"<p>Typical MDX examples for \"give me the top 5 Bs for each A\" look like this:</p>\n\n<pre><code>-- return top 5 clients for each firm\nselect\n  [Measures].[Amount] on columns,\n  NON EMPTY generate(\n    [Firms].[Firm Name].Children,\n    crossjoin(\n      [Firms].[Firm Name].CurrentMember,\n      TopCount([Clients].[Client Name].Children, 5, [Measures].[Amount])\n    )\n  )\n  on rows\nfrom [FirmsAndClients]\n</code></pre>\n\n<p>I'm prototyping a UI that does a lot of these \"top 5\" type queries, so I'm looking for any tips to speed them up in particular, especially when crossjoin(A, B) has mostly null measure values.</p>\n\n<p>In this particular case Firms x Clients was big (n=5000 x n=20,000, more or less) and sparse, and I was able to speed things up by a factor of about 100 by replacing the NON EMPTY with a filter(NOT ISEmpty) inside the crossjoin:</p>\n\n<pre><code>-- return top 5 clients for each firm\nselect\n  [Measures].[Amount] on columns,\n  generate(\n    [Firms].[Firm Name].Children,\n    crossjoin(\n      [Firms].[Firm Name].CurrentMember,\n      TopCount(\n        filter([Clients].[Client Name].Children, NOT IsEmpty([Measures].[Amount]))\n               5,\n               [Measures].[Amount])\n    )\n  )\n  on rows\nfrom [FirmsAndClients]\n</code></pre>\n\n<p>I was hoping to get a further performance benefit from pre-warming the SSAS caches by running similar queries, but I've discovered the above query (i.e. the one with \"filter\") is equally slow when run against warm and cold caches. Playing with Sql Profiler, I've discovered part of why this might be: While SSAS is caching portions of the underlying cube data, it doesn't seem to cache the results from the query-as-a-whole, nor does it seem to cache the intermediate sets created by generate or by crossjoin. Thus it has to redo the generate and crossjoin and topcount each time I repeat the query. And even even though each topcount appears to take 1ms or less, those milliseconds add up when iterating across thousands of Firms.</p>\n\n<p>Any tips on what I can do, at the MDX level or the cube level or the Sql Server tuning level? In the SQL world I could get some mileage out of creating an index on the columns I wanted to sort by. As far as I know there's nothing like that for OLAP, though.</p>\n\n<p>Conceivably this is a more general question of what to do when you want to speed up an MDX query that involves complicated sorting and filtering (which apparently doesn't sit 100% well with the SSAS caching system).</p>\n"},{"tags":["sql","sql-server-2008","sql-server-2005","tsql","olap"],"answer_count":4,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":101,"score":0,"question_id":8664813,"title":"Update in child table, only one value got updated","body":"<p>Below I am trying to update value of a parent table from child table and counting matching values. Tables in my db:</p>\n\n<ol>\n<li><p><code>issue_dimension</code> with id = issue_id and have column accno.</p></li>\n<li><p><code>star_schema</code> with id star_id,this Child column have fk issue_id and column book_frequency</p></li>\n</ol>\n\n<p>The book_frequency need to match the count of each accno in parent table , I tried this </p>\n\n<pre><code>update [test1] .[dbo] .star_schema \nset [book_frequency] = (\n    select top 1 COUNT([issue_dimension].ACCNO)as book_frequency \n    from issue_dimension \n    group by ACCNO having (COUNT(*)&gt;1) and \n        issue_dimension.ACCNO = star_schema .ACCNO\n)\n</code></pre>\n\n<p>It only updates only 1st value count issue_dimension. I need to count every accno in issue_dimension and update it to matching accno of star_schema.\nI never did update by joining two or more tables , can anyone help in this with joins </p>\n"},{"tags":["sql","data-warehouse","olap","star-schema"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":100,"score":1,"question_id":8660460,"title":"is it correct about dimension table and star schema?","body":"<p>is it correct dimensions of star schema also has foreign and primary key relationship ?Is it conceptually correct , please help as its confusion I am having in my Dateware implementation.\nIf yes then in what cases , same for No\nThanks</p>\n"},{"tags":["ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":53,"score":0,"question_id":1094567,"title":"Trace back columns in calculated measures","body":"<p>How do I trace back the actual columns used/joined in calculated measure? THe reason I am asking this question is, I am trying to write the equivalent TSQL query to verify the result with that of calculated measure. \nSo far, my approach has been a look up into the measure properties and find the table/view and the column name used. The joining column has been a difficult part (let s say it impossible for me), because the DSV looks very messy and is hard to follow the lines. </p>\n\n<p>Any suggestions appreciated!</p>\n"},{"tags":["sql-server-2008","data-warehouse","olap","star-schema"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":51,"score":0,"question_id":8656692,"title":"features of Dataware housing via SQL server","body":"<p>do sql server provide any tools/functions which help us in making star scheme ,aggregates or similar ?  I am using winform application to give layout for dwh users and sql server 2008 for db</p>\n"},{"tags":["excel","sas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":57,"score":0,"question_id":8618222,"title":"SAS doesn't update OLAP data when dimensions are modified","body":"<p>We are working with SAS OLAP Cube Studio. We have an existing OLAP Cube and we have changed the hierarchy of some dimensions and added new ones. We deleted the old data and rebuilt the cube from scratch.</p>\n\n<p>However, when we view the cube using Microsoft Excel, the new changes are not shown and the old hierarchy stays in place. What could be the problem?</p>\n"},{"tags":["olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":143,"score":1,"question_id":8585227,"title":"OLAP: Why should all foreign keys between fact and dimension tables be surrogate keys?","body":"<p>I'm reading a Wikipedia article about <a href=\"http://en.wikipedia.org/wiki/Online_analytical_processing\" rel=\"nofollow\">OLAP</a> and <a href=\"http://en.wikipedia.org/wiki/Fact_table\" rel=\"nofollow\">OLAP Fact Tables</a> and the article states</p>\n\n<blockquote>\n  <p>All foreign keys between fact and dimension tables should be surrogate\n  keys, not reused keys from operational data.</p>\n</blockquote>\n\n<p>But it doesn't state why.\nSo, why should </p>\n\n<blockquote>\n  <p>All foreign keys between fact and dimension tables should be surrogate\n  keys, not reused keys from operational data.</p>\n</blockquote>\n\n<p>?</p>\n"},{"tags":["sql-server-2008","ssas","mdx","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":221,"score":2,"question_id":8583557,"title":"Non-Additive Fact","body":"<p>I have a Fact Table with 10 measures. out of 10 measures 9 are aggregated at Sum level.But I have Unit Price which is a Non-Additive Fact Measure.When I go to the property of Aggregation and make it none it does not work in SSAS and gives NULL values in the Cube once the cube is processed. So is there any way where I can deal with my Non-additive measure called Unit_Price.SO created a MDX. I don't know if this is the right method to do that or not. Here is my MDX.Please suggest a method to do the above.</p>\n\n<pre><code>with member [Measures].[Non Additive Unit Sales] as\n  case when [Time].Level is [Time].[Month]\n     and [Gender].Level is [Gender].[Gender]\n     and [Customers].Level is [Customers].[Name]\n     and [Product].Level is [Product].[Product Name]\n  then [Measures].[Unit Sales]\n  else null\n  endselect\n   {[Measures].[Unit Sales],\n     [Measures].[Non Additive Unit Sales],\n     [Measures].[Semi Additive Unit Sales]}\n   * [Gender].Members ON COLUMNS,\n  [Time].Members ON ROWS\nfrom [Sales]\n</code></pre>\n"},{"tags":["ssas","mdx","olap"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":4695,"score":1,"question_id":2900090,"title":"MDX query- How do I use a member property?","body":"<p>I'm a complete newb to MDX / OLAP, \"data warehousing\" in general. I have the following MDX query and would like my results to display the month's number (1 = January, 12 = December). Luckily, the cube creator created a member property named \"Month Number Of Year\"</p>\n\n<p>When I try to run the query, I get the following...\n\"Query (4, 8) The function expects a tuple set expression for the 1 argument. A string or numeric expression was used.\"</p>\n\n<p>Any suggestions for fixing this?</p>\n\n<p>Thanks!</p>\n\n<pre><code>WITH\nMEMBER [Measures].[Tmp] as '[Measures].[Budget] / [Measures].[Net Income]'\n\nSELECT {[Date].[Month].Properties(\"Month Number Of Year\")} ON COLUMNS,\n{[Measures].[Budget],[Measures].[Net Income],[Measures].[Tmp]} ON ROWS\n\nFROM [AnalyticsCube]\n</code></pre>\n"},{"tags":["oracle","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":1,"view_count":107,"score":0,"question_id":8531442,"title":"Oracle 9i OLAP (creating dimestions,fact table,cubes)","body":"<p>I need to undastand basics of Oracle OLAP. Or Oracle Cubes. Or how to use Analytical Worksapace Manager. </p>\n\n<p>Can anyone brief me about it. Or any Link related to it. I am using Oracle 9i. And PL/SQL developer tool. </p>\n"},{"tags":["hierarchy","olap","business-intelligence","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":208,"score":0,"question_id":7859332,"title":"How to set up dynamic hierarchies in OLAP","body":"<p>I'm currently setting up a bi-solution, and having difficulties by defining the cube and its hierarchies. </p>\n\n<p>A part of the schema definition looks like this:</p>\n\n<pre><code>&lt;Dimension foreignKey=\"user\" highCardinality=\"false\" name=\"user\"&gt;\n  &lt;Hierarchy name=\"user\" hasAll=\"true\" allMemberName=\"all\" primaryKey=\"ID\"&gt;\n    &lt;Table name=\"user\" /&gt;\n    &lt;Level name=\"timezone\" column=\"timezone\"/&gt;\n    &lt;Level name=\"locale\" column=\"locale\"/&gt;\n    &lt;Level name=\"gender\" column=\"gender\"/&gt;\n    &lt;/Level&gt;\n  &lt;/Hierarchy&gt;\n&lt;/Dimension&gt;\n</code></pre>\n\n<p>Now I want to access the gender level directly.</p>\n\n<pre><code>SELECT\n{[user].[gender].Members} ON COLUMNS,\n{[Measures].[Fact Count]} ON ROWS\nFROM [cube]\n</code></pre>\n\n<p>Results in something like <code>[user].[zone3].[de_DE].[male] = 10, [user].[zone1].[en_US].[male] = 30</code> and so on. I want a total for each sex: <code>[user].[male] = 20</code> and <code>[user].[female] = 30</code>. </p>\n\n<p>In summary, I need a flexible ordering of the levels. Is this possible? I know there are parallel hierarchies but i cannot create one for every possible order...</p>\n\n<p>I also tried to put all attributes in properties instead of levels but I could not figure out to get a simple total amount of male/female users.</p>\n\n<p>And it has to be quite simple because the whole thing will be part of a dynamic bi-tool...</p>\n"},{"tags":["olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":73,"score":0,"question_id":8173179,"title":"OLAP Hierarchy Creation","body":"<p>I have a dimension name is 'Material' that have attributes:</p>\n\n<pre><code>Material Type\nLetter1\nLetter2\nMaterial Name\nMaterial ObjectId\n</code></pre>\n\n<p>I want to create an hierarchy like </p>\n\n<pre><code>Material Type\n  Letter 1\n     Letter 2\n        Material \n</code></pre>\n\n<p>Example like : <code>Inventory of Material -&gt; M -&gt;MI -&gt; MIRROR</code>\nI set the Material Type Key Value: Material Type, and Name Value: Material Name.\nBut when I browse the dimension I do not see material type names on the first level. I see different material names for different times. </p>\n\n<p>Secondly when I browse my cubes that use the material dimension, I do not see my material hierarchy. Only First level (Material Type) have seen on the secreen.</p>\n\n<p>What I do for these problems. I searched but not found anything...</p>\n"},{"tags":["ssas","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":115,"score":0,"question_id":8490657,"title":"OLAP Dimension structure","body":"<p>I have Dimension \"Customer\". Each Customer can have some buisness units and some departmens. \nI should bild 2 hierarchies: Customer->Department and Customer->Buisness Unit.\nSo, I also need to set key attribute. This is my question: What should be use as key attribute?\nMay be I do this wrong?\nCould you help?</p>\n"},{"tags":["java","olap","mondrian","drilldown"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":408,"score":2,"question_id":7219464,"title":"Mondrian Olap drilldown algorithm","body":"<p>I didn't found but may be someone could me explain - OLAP cube is a combination of all possible aggregation, so related to Mondrian - leaf level is data in fact table or it is a minimum aggregate (cell) ?\nThanks.</p>\n"},{"tags":["sas","data-warehouse","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":67,"score":1,"question_id":8136860,"title":"OLAP Cubes get incremented folder names in SAS 9.2","body":"<p>When updating/Creating cubes in SAS 9.2 the Cubes in folder c:\\OLAP is not overwritten.\nThe folder names is incremented with numbers :\nC:\\OLAP\\Departments1\nC:\\OLAP\\Departments2 \nand so on..</p>\n\n<p>In 9.1.3 this didnt happen. Anyone know how to turn this feature of, or why it is like this?</p>\n"},{"tags":["mysql","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":1,"view_count":72,"score":-1,"question_id":8424917,"title":"Need output of OLAP query","body":"<pre><code> select itemID, storeID, custID, sum(price) \n from Sales F \n group by storeID, itemID, custID with cube(storeID, custID);\n</code></pre>\n\n<p>So what should be the output of this query? I mean which attributes could be null?\nWill I have:</p>\n\n<pre><code>I, S,    C\nI, S,    null\nI, null, null\n</code></pre>\n\n<p>or</p>\n\n<pre><code>I, S,    C\nI, S,    null\nI, null, null\nI, null, C\n</code></pre>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":307,"score":0,"question_id":8374787,"title":"Cumulative sum (progressive total)","body":"<p>I have a cube with the dimension CreatedOn (Time type) and the measure IssueOpened.  I need to get the cumulative sum for IssueOpened.</p>\n\n<p>For example:</p>\n\n<pre><code>2009  IssueOpened=7   OpenedOnTheEndOfPeriod=7\n2010  IssueOpened=12  OpenedOnTheEndOfPeriod=19\n2011  IssueOpened=2   OpenedOnTheEndOfPeriod=21\n</code></pre>\n\n<p>So, I have created the calculated member:</p>\n\n<pre><code>sum([CreatedOn].[Y-Q-M].currentmember.level.members(0):[CreatedOn].[Y-Q-M].currentmember.prevmember, Measures.[IssueOpened])\n</code></pre>\n\n<p><img src=\"http://i.stack.imgur.com/mgVAS.png\" alt=\"enter image description here\"></p>\n\n<p>But it looks like it doesn't work as I want.  Start of dimension:</p>\n\n<p><img src=\"http://i.stack.imgur.com/P1qnI.png\" alt=\"enter image description here\"></p>\n\n<p>And it looks like a truth at the end of dimension:</p>\n\n<p><img src=\"http://i.stack.imgur.com/TOMZ5.png\" alt=\"enter image description here\"></p>\n\n<p>May be the error on the first member of Time dimension? What do I need to fix to get the desired result?</p>\n"},{"tags":["flex","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":324,"score":1,"question_id":3879190,"title":"Flex OLAPDataGrid Sorting","body":"<p>I'm trying to provide some default sorting within the OLAPDataGrid component in Flex. There appears to be a dataCompareFunction on OLAPAttribute, but nothing I do seems to actually trigger calls to that method. Any suggestions around using this method or any others to provide sorting of the dimensions on OLAPDataGrid?</p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":438,"score":0,"question_id":8295158,"title":"Analysis services 2008 : decimal numbers truncate in cube olap","body":"<p>I'm working on olap cube (with analysis services 2008). In my database  I have a column (datatype =NUMBERS(40,30) ). In this column there's values with 10 numbers after the coma example : 125.256987452122 or 159.2365894123658</p>\n\n<p>In my cube olap,  that column is match to a measure. When I look the values in the cube,\nI don't have the same value with the database. example :  125.256987452122  ==> in cube 125.2569 or  159.2365894123658 ==> in cube 159.2365</p>\n\n<p>Even when I set the measure property FORMATSTRING = ''### ### ### ### ##0.0000000000;-### ### ### ### ##0.0000000000''  I get this result 25.256987452122  ==> in cube 125.2569000000\nor  159.2365894123658 ==> in cube 159.2365000000.</p>\n\n<p>The mesure datatype is Double . I change it to currency but I have the same problem.</p>\n\n<p>Did someone know how to get the same  result as  in the data base , in my cube olap  : \n 159.2365894123658 ==> in cube 159.2365894123658   ???</p>\n\n<p>Thanks for your answers  </p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":109,"score":2,"question_id":8280786,"title":"One measure on the two different dimensions","body":"<p>I have the facts table with two date columns: StartDate and FinishDate:</p>\n\n<p><img src=\"http://i.stack.imgur.com/9blks.png\" alt=\"enter image description here\"></p>\n\n<p>And I have Time table which have been linked with the facts table with two different relations.</p>\n\n<p>I have created Time dimension based on the Time table and included this dimension to my cube:</p>\n\n<p><img src=\"http://i.stack.imgur.com/QcWm9.png\" alt=\"enter image description here\"></p>\n\n<p>So in the result I have two different dimensions (Created_On and Updated_On) based on the Time table.</p>\n\n<p>Now I am trying to browse my cube and I want to get the two counts: count of facts which have been created in some period of time and count of facts which have been updated in the same period of time.</p>\n\n<p>I can get each of them separately, but cannot in the same time:</p>\n\n<p><img src=\"http://i.stack.imgur.com/gzVM1.png\" alt=\"enter image description here\"></p>\n\n<p>How can I get it? Do I need to change the warehouse structure? Do I need to change my cube? Or do I need to use MDX in this case?</p>\n"},{"tags":["mdx","olap","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":577,"score":0,"question_id":8223280,"title":"Date Ranges in Mondrian","body":"<p>I want to fetch data for TimeStamp t1 to t2. But t1 and t2 might not necessarily in my database table. So, what i want is: it should find next available timestamp greater than or equal to t1 ( > t1 in case t1 is not there in db table or t1 if it is there) and last available timestamp less than or equals to t2  ( &lt; t2 if t2 is not there or t2 if it is there in db) in MDX query itself.</p>\n\n<p>.FirstSibling, .LastSibling, .FirstChild, .LastChild, .NextMember, .LastMember, HEAD, TAIL won't work for me as i want timestamp be to >= t1 and &lt;= t2 (with both available in db).\nHow should i do it?</p>\n"},{"tags":["count","distinct","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":427,"score":0,"question_id":8242309,"title":"Count distinct in MDX (convert from SQL query)","body":"<pre><code>SELECT COUNT (DISTINCT S.PK_Submission)\nFROM Fact_Submission FS, Submission S\nWHERE \nFS.FK_Submission = S.PK_Submission\nAND FS.FK_Submission_Date &gt;= 20100101\nAND FS.FK_Submission_Date &lt;= 20101231\n</code></pre>\n\n<p>I've tried this:</p>\n\n<pre><code>SELECT \n{[Measures].[Fact Submission Count]} ON AXIS(0), \nDistinct({[Submission].[PK Submission] }) ON AXIS(1)\nFROM [Submission]\nWHERE \n([Date].[Calendar Year].[2010])\n</code></pre>\n\n<p>but the result is the same</p>\n\n<p>any idea how to write this in MDX? I'm pretty new at this so still haven't figured it out.</p>\n"},{"tags":["mysql","olap","mondrian","rolap","olap4j"],"answer_count":2,"favorite_count":1,"up_vote_count":5,"down_vote_count":0,"view_count":741,"score":5,"question_id":8078280,"title":"Why use ROLAP instead of plain MySQL?","body":"<p>Are there any performance advantages in using a ROLAP server such as Mondrian on top of a MySQL database, as opposed to simply querying the MySQL database?</p>\n\n<p>I am asking this in the context in which most of my queries will be relatively simple (such as finding all the sales in a certain period), but the size of the database is rather large (hundreds of thousands of entries). </p>\n\n<p>My idea was to use OLAP to speed up queries, but now I'm confused as to whether or not this is actually the purpose of this technology, especially in its ROLAP form. While trying the olap4j API, I realized that I can use it to make MDX queries without even having an actual OLAP server (just having a relational database and an OLAP schema for it). How could that be of any use in terms of performance?</p>\n\n<p>Thanks</p>\n"},{"tags":["flex","actionscript","flex3","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":75,"score":0,"question_id":8213953,"title":"Pivot/OLAP implementation using flexSpreadSheet in Flex3","body":"<p>I am using <a href=\"http://code.google.com/p/flexspreadsheet/\" rel=\"nofollow\">flexSpreadSheet</a> for Pivot functionality in a Flex 3 application.It accepts 'flatData'(raw data in an  ArrayCollection of objects with attributes mapping exactly to the columns in the table in DB).I ran it for dummy data of approx 10.000 rows in DB with approx 20 columns.It worked fine.</p>\n\n<p>Now the real data is of the size of around 90,000 rows.Now when the user drags and drops rows/columns to create a pivot,it hangs even for a single dimension and error#1502-'a script executed for more than 15s(sic)' occurs..I try resolving by setting <code>scriptTimeLimit</code> but it still hangs.</p>\n\n<p>For a pivot like application and for such large amounts of data is there anyway i can fetch and display data within practical time limits.Are there other APIs or open source libraries for OLAP implementation in flex?</p>\n"},{"tags":["python","sql","optimization","aggregate","olap"],"answer_count":10,"favorite_count":4,"up_vote_count":9,"down_vote_count":0,"view_count":2695,"score":9,"question_id":51553,"title":"Why are SQL aggregate functions so much slower than Python and Java (or Poor Man's OLAP)","body":"<p>I need a real DBA's opinion. Postgres 8.3 takes 200 ms to execute this query on my Macbook Pro while Java and Python perform the same calculation in under 20 ms (350,000 rows):</p>\n\n<pre><code>SELECT count(id), avg(a), avg(b), avg(c), avg(d) FROM tuples;\n</code></pre>\n\n<p>Is this normal behaviour when using a SQL database?</p>\n\n<p>The schema (the table holds responses to a survey):</p>\n\n<pre><code>CREATE TABLE tuples (id integer primary key, a integer, b integer, c integer, d integer);\n\n\\copy tuples from '350,000 responses.csv' delimiter as ','\n</code></pre>\n\n<p>I wrote some tests in Java and Python for context and they crush SQL (except for pure python):</p>\n\n<pre><code>java   1.5 threads ~ 7 ms    \njava   1.5         ~ 10 ms    \npython 2.5 numpy   ~ 18 ms  \npython 2.5         ~ 370 ms\n</code></pre>\n\n<p>Even sqlite3 is competitive with Postgres despite it assumping all columns are strings (for contrast: even using just switching to numeric columns instead of integers in Postgres results in 10x slowdown)</p>\n\n<p>Tunings i've tried without success include (blindly following some web advice):</p>\n\n<pre><code>increased the shared memory available to Postgres to 256MB    \nincreased the working memory to 2MB\ndisabled connection and statement logging\nused a stored procedure via CREATE FUNCTION ... LANGUAGE SQL\n</code></pre>\n\n<p>So my question is, is my experience here normal, and this is what I can expect when using a SQL database?  I can understand that ACID must come with costs, but this is kind of crazy in my opinion.  I'm not asking for realtime game speed, but since Java can process millions of doubles in under 20 ms, I feel a bit jealous. </p>\n\n<p>Is there a better way to do simple OLAP on the cheap (both in terms of money and server complexity)?  I've looked into Mondrian and Pig + Hadoop but not super excited about maintaining yet another server application and not sure if they would even help.</p>\n\n<hr>\n\n<p>No the Python code and Java code do all the work in house so to speak.  I just generate 4 arrays with 350,000 random values each, then take the average.  I don't include the generation in the timings, only the averaging step.  The java threads timing uses 4 threads (one per array average), overkill but it's definitely the fastest.</p>\n\n<p>The sqlite3 timing is driven by the Python program and is running from disk (not :memory:)</p>\n\n<p>I realize Postgres is doing much more behind the scenes, but most of that work doesn't matter to me since this is read only data.</p>\n\n<p>The Postgres query doesn't change timing on subsequent runs.</p>\n\n<p>I've rerun the Python tests to include spooling it off the disk.  The timing slows down considerably to nearly 4 secs.  But I'm guessing that Python's file handling code is pretty much in C (though maybe not the csv lib?) so this indicates to me that Postgres isn't streaming from the disk either (or that you are correct and I should bow down before whoever wrote their storage layer!)</p>\n"},{"tags":["asp.net","mdx","analysis","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":264,"score":0,"question_id":6494228,"title":"Making a dropdown using Analysis Cube Data","body":"<p>So I am working on a project that requires me to make a dropdown using the data from analysis service cube. This is what i have come up with by googling.</p>\n\n<pre><code>protected void Page_Load(object sender, EventArgs e)\n    {   DataTable dt = new DataTable();\n        AdomdConnection conn = new AdomdConnection();\n        conn.ConnectionString = \"Data Source=RRLR87G4XE-1;Provider=MSOLAP\";\n        conn.Open();\n\n        AdomdCommand cmd = new AdomdCommand();\n        cmd = conn.CreateCommand();\n        cmd.Parameters.Add(\"DimProductRegion\", \"Bike\");\n        cmd.CommandText = \"SELECT {[Dim Product].[Region].children} ON ROWS, {} ON COLUMNS FROM [Adventure Works]\";\n\n        AdomdDataAdapter da = new AdomdDataAdapter(cmd);\n        da.Fill(dt);\n\n\n        ddlRegionFilter.DataSource = dt;\n        ddlRegionFilter.DataTextField = \"ParameterCaption\";\n        ddlRegionFilter.DataValueField = \"ParameterValue\";\n        ddlRegionFilter.DataBind();}\n</code></pre>\n\n<p>but the problem is that it wouldn't display the results on the drop down. the drop down is just empty.</p>\n\n<pre><code>&lt;asp:DropDownList ID=\"ddlRegionFilter\" runat=\"server\" AutoPostBack=true &gt;\n&lt;/asp:DropDownList&gt;\n</code></pre>\n"},{"tags":["olap","neo4j"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":352,"score":0,"question_id":8179468,"title":"Neo4J as OLAP performance benchmark","body":"<p>I would like to know if Neo4J can be used as OLAP. The search says it is great tool as OLTP. However there are no proven case studies as OLAP. </p>\n\n<p>Also only Jasper 1st version of connector with Neo4J. I have not seen any connectors from other BI providers. If there are any BI providers that have auto connector with Neo4J please share.</p>\n"},{"tags":["flex","olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":77,"score":0,"question_id":8182406,"title":"Add a totals row to a Flex OLAPDatagrid","body":"<p>Anyone know if it's possible to add a 'Totals' row to a Flex OLAPDataGrid please (at the top or bottom, I don't mind). </p>\n\n<p>Tks,\nAlex</p>\n"},{"tags":["algorithm","data-structures","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":144,"score":1,"question_id":8158389,"title":"best data structure for multidimensional data?","body":"<p>I would like to implement a simple, in-memory OLAP cube storage engine for read and write (writeback) - functionally similar to SSAS cube with multiple dimensions but one measure and only with 1 type of aggregation (sum). As in OLAP cube each axis in the multidimensional space can be a multi-level hierarchy.</p>\n\n<p>Can the community provide me with some hints at which data-structures and related algorithms should I be looking at? I understand that I need something capable of indexing data in many dimensions at once, and storing intermediate precomputed aggregation values. </p>\n\n<p>I'd rather not be gluing multiple nested maps together but implement something from scratch - the goal of the excercise is not just to implement this beast but also to better understand multidimensional data structures and algorithms.</p>\n\n<p>Just to clarify - I am focused on the core data structure of storing multidimensional hierarchical data for reads and writes. I do not seek to implement MDX parser, make the cube persistent, etc.</p>\n"},{"tags":["sql-server-2005","ssas","mdx","olap","bids"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":45,"score":0,"question_id":8133448,"title":"I want to open SSAS 2000 cab file","body":"<p>I have SSAS cube zip file schm.zip <a href=\"http://support.microsoft.com/kb/312399\" rel=\"nofollow\">for how to create</a></p>\n\n<p>I have only this cab file no database nothing.</p>\n\n<p>this file has multiple files having extension dim_, dimcr_ , dimprop_ , dimtree_</p>\n\n<p>I want to open this file using sql server 2005. which tools i may required to open this? i have ANALYSIS SERVICES (DEVELOPMENT WIZARD) installed only with sql server , Management studio.</p>\n\n<p>any help will appreciated.</p>\n\n<p>Aamir Khan\n   JSE</p>\n"},{"tags":["sql-server-2005","olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":58,"score":0,"question_id":8140883,"title":"OLAP Cubes Does Not Process With Agent Job?","body":"<p>In my project,I use MS SQL Analysis Server. Briefly, I created a job, that runs every night to process cubes. Job is running successfully that shown in history. But OLAP Cubes were not prossed. I designed and installed this system a lot of server. This problem occurs only two server. Others works successfully. I controlled every thing that is different the others. (Partitions,IIS Settings...)  What Can I do? Any suggestion...</p>\n"},{"tags":["sql-server-express","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":104,"score":1,"question_id":8082291,"title":"Third Party Analysis Service Equivalent Component for SQL Server Express","body":"<p>As far as I know, the SQL Server Analysis Service (SSAS) is NOT supported by SQL Server Express Edition (2005/2008/2008R2). Does anyone know if there is any third party SSAS equivalent component / service / system (free or commercial) that does the same job?</p>\n\n<p>Many thanks.</p>\n"},{"tags":["sql","oracle","query","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":159,"score":0,"question_id":8072104,"title":"oracle data from multiple tables","body":"<p>*<strong><em>UPDATE</em></strong></p>\n\n<p>i will try to explain the situation again:\ni have one datamart which contains all the clients and the original payments along with status and fiscal period in yyyymmdd format. the status needs to be matched with the status in another table so that i get only those client names and fiscal periods where status_datamart=status_table and status_table in ('inactive', 'active'). this data is now inserted into a table called 'inv' which contains: \nPORTFOLIO_INV, CLIENT_INV,ACCT_TYPE_INV,PERIOD,DESK,STATUS,PRIOR_OCA_CALC,PRINCIPAL,CUR_BAL</p>\n\n<p>the second datamart again contains client, fiscal_period, payments(gross and net), transaction_type.\none query is used to fetch only those records from this datamart where the txn type is matched with another table and txn category is 'gross'.\nsecond query has same filters as above, only txn category is now changed to 'net'.</p>\n\n<p>The reason for 2 queries to get gross and net is that the data is in following format:</p>\n\n<p>client1 | fiscal period| status | gross\nclient2 | fiscal period| status | gross\nclient1 | fiscal period| status | net\nclient3 | fiscal period| status | gross</p>\n\n<p>so i use query one to store gross into one table 'pmt' :\nPORTFOLIO_PMT,CLIENT_PMT,ACCT_TYPE_PMT,PERIOD_PMT,DETAIL_TRANSACTION_TYPE,DETAIL_DESK_AT_PMT,DETAIL_STATUS_AT_PMT,PRIOR_OCA_CALC_PMT,DETAIL_AMOUNT_PMT</p>\n\n<p>and second query to store into another table 'net':\nPORTFOLIO_NET,CLIENT_NET,ACCT_TYPE_NET,PERIOD_NET,DETAIL_TRANSACTION_TYPE_NET,DETAIL_DESK_AT_PMT_NET,DETAIL_STATUS_AT_NET,PRIOR_OCA_CALC_NET,DETAIL_AMOUNT_NET</p>\n\n<p>constraints:\nclient_inv=client_pmt=client_net\nperiod= period_pmt=period=net</p>\n\n<p>hope it helps...</p>\n\n<hr>\n\n<p>i am writing a query that will retrieve the name of client, fiscal year and principal amount from table T1, sum(current payments) from another table T2 (for same client and same fiscal period) and the sum(net) from third table(for same client as in T1 and T2) . the query took 2132.78 seconds to complete for around 3400 records in T1, 939 in T2 and 103 in T3.</p>\n\n<p>is there a way in which i can NOT use joins and just fetch the data I want quickly?\nThe total number of records will vary in each table depending what was the principal amount and how many payments have been received.</p>\n"},{"tags":["reporting-services","ssas","olap","business-intelligence","olap-cube"],"answer_count":4,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":656,"score":2,"question_id":2561397,"title":"In SQL Server Business Intelligence, why would I create a report model from an OLAP cube?","body":"<p>In Business Intelligence Developer Studio, I'm wondering why one would want to create a report model from an OLAP cube.  </p>\n\n<p>As far as I understand it, OLAP cubes and report models are both business-oriented views of underlying structures (usually relational databases) that may not mean much to a business user.  The cube is a multidimensional view in terms of dimensions and measures, and the report model is... well I'm not sure entirely -- is it a more business-oriented, but still essentially relational view?</p>\n\n<p>Anyway, in Report Builder I can connect directly to both an OLAP cube or a report model.  So I don't see why, if I have an OLAP cube which already provides a business-oriented view of the data suitable for end-users, why I would then convert that to a report model and use that in Report Builder instead.</p>\n\n<p>I think I'm obviously missing some fundamental difference between report models and cubes -- any help appreciated!</p>\n"},{"tags":["olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":32,"score":0,"question_id":8078953,"title":"OLAP componante for Oracle and Analysis","body":"<p>My team is having trouble creating reports based on OLAP cubes. This is because the various aplicaitvos that are developed in ASP.NET, Java, PHP, etc. .. have separate databases, or in a MySQL, SQL Server or Oracle.</p>\n\n<p>For Oracle and SQL Server have their own components to use.</p>\n\n<p>I wonder if there is any component that can be used both in Oracle and SQL SERVER preferably without requiring the use of SQL Server Reporting Services. Someone could tell me?</p>\n\n<p>Taking the question, there is a line of study guides me to build this component? There is a way to browse the information of the cubes as / similar information by navigating a common database using SQL QUERY?</p>\n"},{"tags":["many-to-many","ssas","olap","mondrian"],"answer_count":0,"favorite_count":2,"up_vote_count":0,"down_vote_count":0,"view_count":503,"score":0,"question_id":8074641,"title":"Can Pentaho Mondrian aggregate many-to-many/multi-valued dimensions with Sql Server/SSAS's level of cleverness?","body":"<p>Short version: I like how Sql Server can apparently handle multi-valued dimensions with a bit of cleverness. I'm wondering if Mondrian can do the same.</p>\n\n<h1>Background: Bridge Table Pattern</h1>\n\n<p>I've been learning about modeling multi-valued dimensions in OLAP, and in particular have been exploring the Bridge Pattern approach. (See, e.g., Kimball Group's <a href=\"http://www.kimballgroup.com/html/10dt/DT124AlternativesMulti-valuedDimensions.pdf\" rel=\"nofollow\">Design Tip #124 Alternatives for Multi-valued Dimensions</a>.)</p>\n\n<p>To review, the basic idea with bridge tables is rather than have</p>\n\n<p>fact_table -> dimension table</p>\n\n<p>you have</p>\n\n<p>fact_table -> bridge table -> dimension table</p>\n\n<p>Bridge table is n:m, which means that each fact is ultimately associated with multiple values of a given dimension (say, multiple customers), rather than just a single value.</p>\n\n<p>This approach has some nice properties, but it raises the possibility of messing up your aggregates if you're not careful. For example, if you had a transaction fact table row with SalesAmount=$3.30, then once your OLAP stack joins the fact_table and the bridge_table, there will now be <em>k</em> rows with SalesAmount=$3.30. If things get summed naively, you risk effectively proceeding as if that one transaction brought in k * $3.30, rather than just $3.30.</p>\n\n<h1>Background: What Sql Server / SSAS can apparently do</h1>\n\n<p>As I gathered <a href=\"http://sqlcat.com/sqlcat/b/technicalnotes/archive/2008/02/11/analysis-services-should-you-use-many-to-many-dimensions.aspx\" rel=\"nofollow\">here</a>, some OLAP tools can use some cleverness to avoid this sort of \"double counting\". For instance, apparently if you tell SQL Server/SSAS that you're dealing with a many-to-many relationship (e.g. where each Sale can be associated with n \"Sales Reasons\"), then a straightforward MDX query like this</p>\n\n<pre><code>select\n  [Measures].[Internet Sales Amount]\non columns,\n  [Sales Reason].[Sales Reason].members\non rows\nfrom [Adventure Works]\n</code></pre>\n\n<p>treats things as sanely as possible as both at the individual sales reason level (e.g. \"On Promotion\") and at the aggregate \"All Sales Reasons\" level. In particular, the resulting row for \"On Promotion\" will sum across all the sales facts for which \"On Promotion\" was one of the reasons recorded. And the row for \"All Sales Reasons\" will include the sum of all sales, period, regardless of reason. In particular, the \"All\" aggregate will not double-count sales facts in cases where multiple sales reasons -- e.g. \"On Promotion\" and \"Price\" -- were both recorded.</p>\n\n<h1>Can Mondrian do this too?</h1>\n\n<p>So far Mondrian, unlike SSAS, doesn't seem to provide a way to indicate that a relationship is \"multi-valued\" or \"many-to-many\". Am I right about this?</p>\n\n<p>If Mondrian won't give me any extra help, then if I want to use the Bridge Table pattern I seem to need to jump through some hoops to get aggregates to work right both at the particular-value level and at the \"All\" level of a multi-valued dimension.. The Design Tip #124 document (above), for example, recommends making use of a \"weighting factor\" in the bridge table. That can help to make sure the \"All\" values come out right, but I suspect it has the side-effect of making measures come out wrong/arbitrarily if I drill down to the particular-value level. There might be a way around it by crafting more clever MDX expressions, but I'm not sure yet.</p>\n"},{"tags":["ssas","relationship","olap","dimension","fact-table"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":353,"score":0,"question_id":8054293,"title":"Analysis Services OLAP - Dimension Usage Relationship Type","body":"<p>I was hoping someone could explain the appropriate use of the 'FACT Relationship Type' under the  Dimension Usage tab. Is it simply to create a dimension out of your fact table to access attribute on the fact table itself?</p>\n\n<p>Thanks in advance!</p>\n\n<p>Mike at BI Metrics</p>\n"},{"tags":["excel","olap","pivot-table"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":799,"score":0,"question_id":1668798,"title":"Pivot Table does not refresh automatically after refreshing the OLAP cube. Excel 2007","body":"<p>I have a workbook connected to an external OLAP cube.  Previously, when I connected to the external data source and then refreshed all, every pivot table would refresh and show the new data.  Now, if I connect to the data source and refresh the pivots, the pivots do not update with new data.  The only way I can get it to update is if I manually click in one of my filters then click ok.  For some reason, this triggers a connection to the cube and the pivot refreshes with the new data.  Any idea why this might be happening?  I'm at a loss and it's extremely time consuming to have to manually click in each pivot.  Thanks.</p>\n"},{"tags":["oracle","olap","olap-cube","oracle-olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":182,"score":0,"question_id":7957008,"title":"How to deploy Oracle Dimension table for OLAP Cubes","body":"<p>I followed <a href=\"http://www.adp-gmbh.ch/ora/olap/example_1.html\" rel=\"nofollow\">First Example</a> as well as <a href=\"http://www.dba-oracle.com/t_olap_dimensions_cubes.htm\" rel=\"nofollow\">Second Example</a> to create Cubes in Oracle 10g.</p>\n\n<p>I tried to create cube using query rewrite mechanism in Oracle 10g. </p>\n\n<p>(Intailly tried to create using Analystic workspace manager we got error in that too so only we went for query rewrite mechansism)</p>\n\n<p>We succeded in creating table \"PRODUCTS\"\nAlso we succedded in creating Dimension for that table \"PRODUCTS\"</p>\n\n<p>But when we try to create Attribute for the above \"PRODUCTS\" table like below </p>\n\n<pre><code>BEGIN \ncwm_classify.remove_entity_descriptor_use(28, cwm_utility.DIMENSION_TYPE, 'SH', 'PRODUCTS');\nCOMMIT; \nEND\n</code></pre>\n\n<p>we are getting following error.<br>\nNote : We have data inside table too</p>\n\n<pre><code>Error starting at line 1 in command:\nbegin \ncwm_classify.remove_entity_descriptor_use(28, cwm_utility.DIMENSION_TYPE, 'SH', 'PRODUCTS'); \ncommit; \nend; \nError report:\nORA-06510: PL/SQL: unhandled user-defined exception\nORA-06512: at \"OLAPSYS.CWM$OLAP$DIMENSION\", line 242\nORA-06510: PL/SQL: unhandled user-defined exception\nORA-06512: at \"OLAPSYS.CWM$UTIL\", line 368\nORA-01403: no data found\nORA-06512: at \"OLAPSYS.CWM$CLASSIFY\", line 322\nORA-06512: at \"OLAPSYS.CWM$CLASSIFY\", line 1198\nORA-06512: at line 2\n06510. 00000 -  \"PL/SQL: unhandled user-defined exception\"\n*Cause:    A user-defined exception was raised by PL/SQL code, but\n           not handled.\n*Action:   Fix the problem causing the exception or write an exception\n           handler for this condition. Or you may need to contact your\n           application administrator or DBA.\n</code></pre>\n\n<p>When i googled i got suggestion like we have to deploy Dimension also before deploying Cubes.</p>\n\n<p>So i'm trying to create OLAP Cubes for this i need to to deploy Dimension Tables in Oracle.\nIs there any way to deploy Dimension is that possible actually?</p>\n\n<p>Suggest me how to do this?</p>\n"},{"tags":["php","mdx","olap","jasperserver"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":566,"score":0,"question_id":7931616,"title":"MDX query from PHP","body":"<p>Is it possible to create an MDX query for JasperServer using PHP as a host language, given that my underlying relational database is MySQL?</p>\n\n<p>What I would like to do is send the query to JasperServer in order to create an OLAP View and receive the view as a result (preferably in some text-based format, as oposed to an image or PDF).</p>\n\n<p>I'm using JasperServer CE 4.2.1.</p>\n\n<p>As a side note, is it even correct to think about making MDX queries from you application, just like you would make SQL queries? If yes, is there any way to make MDX queries to any OLAP server using PHP?</p>\n\n<p><strong>Edit:</strong> Added missing information: I'm using MySQL as a relational database server.</p>\n"},{"tags":["reporting","olap","oltp"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":59,"score":0,"question_id":7766910,"title":"OLAP or ALTP at reporting Tools","body":"<p>should I use OLAP or OLTP for reporting tools like BIRT, Jasper Report... ?\nI want to build ad - hoc many documents (e.g. 1000000).</p>\n"},{"tags":["olap","mdx","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":587,"score":1,"question_id":2312561,"title":"Mondrian MDX Query, Avoid Fatal Error when Member not Found in cube","body":"<p>i want to know if is it possible to avoid mondrianÂ´s fatal error when it doesn't have any member in defined cube. for instance i have this MDX Query </p>\n\n<p>select {[Measures].[Unit_Sales], [Measures].[Quantity], [Measures].[Total]} ON COLUMNS,\nHierarchize({([Country.CountryHeirarchy].[All Countries].[USA], [Products.ProductHeirarchy].[All Products])}) ON ROWS\nfrom [SALES]</p>\n\n<p>and lets say, the DataBase doesn't have the USA member, i want to get a zero(0) or null value. is it possible to do that on mondrian.</p>\n\n<p>i have been trying with this property in <strong>mondrian.property</strong> file </p>\n\n<p><strong>mondrian.rolap.ignoreInvalidMembersDuringQuery=true</strong></p>\n\n<p>but not lucky still now.</p>\n\n<p>Thanks in advance.</p>\n"},{"tags":["tfs","olap","item"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":372,"score":0,"question_id":7923082,"title":"TFS 2010 Custom Work Item fields not showing in OLAP","body":"<p>I've created a custom \"Bug\" work item template, but when I pull the OLAP cube in Excel, none of my new fields are in the PivotTable field list.  I've manually refreshed the cube, but they're still not showing up.  Thoughts?</p>\n\n<p>Thanks in advance...</p>\n"},{"tags":["sql","visual-studio","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":34,"score":0,"question_id":7916613,"title":"Is it necessary to create FactX and DimX tables manually for MS BI Analysis Services?","body":"<p>I have an OLTP database. For this database, I want to use SQL 2008 R2 Analysis Services. So I created a new project in Visual Studio using the BI template 'Analysis Services Project'. </p>\n\n<p>Do I need to create FactXXX and DimXXX tables manually on the server, or is it somehow possible to do this in Visual Studio?</p>\n\n<p>For instance, can Dimension Wizard (Right click on \"Dimensions\" folder in solution explorer -> New Dimension -> Use Existing table) be used for the dimensions, or is it for some other purpose?</p>\n"},{"tags":["ssas","mdx","olap","dimensions","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":237,"score":0,"question_id":7893989,"title":"SSAS Cube Memory Explodes with MDX query with 10 Dimensions","body":"<p>We are querying an SSAS Cube with an mdx query that executes very quickly and efficiently with up to 9 dimensions. Once we hit 10 dimensions, cube's memory usage goes wildly out of control and uses all the available memory on the machine until it basically crashes the machine. Can anyone answer why 10 would be so radically different than 9?</p>\n\n<pre><code>with member measures.CatKey\n    as\n    [Question Answer Primary].[Q-A].currentmember.properties('key')\nselect {\n        measures.CatKey,\n        [Measures].[AverageValue],\n        KPIValue('KPI Question Average Delta Wave Over Wave'),\n        KPITrend('KPI Question Average Delta Wave Over Wave'),\n        [Measures].[TopBoxPercent],\n        KPIValue('KPI Top Box Delta Wave Over Wave'),\n        KPITrend('KPI Top Box Delta Wave Over Wave'),\n        [Measures].[MiddleBoxPercent],\n        KPIValue('KPI Middle Box Delta Wave Over Wave'),\n        KPITrend('KPI Middle Box Delta Wave Over Wave'),\n        [Measures].[BottomBoxPercent],\n        KPIValue('KPI Bottom Box Delta Wave Over Wave'),\n        KPITrend('KPI Bottom Box Delta Wave Over Wave'),\n        [Measures].[Primary Response Count]\n    } on columns,\n\n    [Question Answer Primary].[Q-A].[QUESTIONCATEGORY] * [Question Answer Primary].[QUESTIONKEY].[QUESTIONKEY]\n    DIMENSION PROPERTIES MEMBER_VALUE on rows\n\nfrom [SATPlus_Cube]\n\nwhere CrossJoin({[Response Wave].[Wave].&amp;[20110101]}, \n{\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[AfricaSpecific], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[ChinaSpecific], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[Training], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[SalesSupport], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[Relationship], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[ProductsAndPartsQuality], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[ProductSupport], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[PricingAndDiscounts],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[Overall],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[KeyMetrics],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[ITSystemsSupport],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[GovernmentNationalSales],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[FinancingAndCredit],\n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[FieldSupport], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[DistributionSupport], \n    [Question Answer Primary].[QUESTIONCATEGORY].&amp;[AdvertisingSupport]\n}, \nNonEmpty (\n        {[Sample].[SAMPLE KEY].[SAMPLE KEY]},\n        ( \n            {[Hierarchy].[Node Value].&amp;[1]}\n            , [Measures].[Primary Response Count]\n        )\n    ))\n</code></pre>\n"},{"tags":["sas","olap","mdx"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":15673,"score":1,"question_id":197407,"title":"Defining a calculated member in MDX - filtering a measure's value","body":"<p>I need to define a calculated member in MDX (this is SAS OLAP, but I'd appreciate answers from people who work with different OLAP implementations anyway).</p>\n\n<p>The new measure's value should be calculated from an existing measure by applying an additional filter condition. I suppose it will be clearer with an example:</p>\n\n<ul>\n<li>Existing measure: \"Total traffic\"</li>\n<li>Existing dimension: \"Direction\" (\"In\" or \"Out\")</li>\n<li>I need to create a calculated member \"Incoming traffic\", which equals \"Total traffic\" with an additional filter (Direction = \"In\")</li>\n</ul>\n\n<p>The problem is that I don't know MDX and I'm on a very tight schedule (so sorry for a newbie question). The best I could come up with is:</p>\n\n<pre><code>([Measures].[Total traffic], [Direction].[(All)].[In])\n</code></pre>\n\n<p>Which almost works, except for cells with specific direction:</p>\n\n<p><img src=\"http://img152.imageshack.us/img152/4460/exbm5.png\" alt=\"example\" /></p>\n\n<p>So it looks like the \"intrinsic\" filter on Direction is overridden with my own filter). I need an intersection of the \"intrinsic\" filter and my own. My gut feeling was that it has to do with Intersecting <code>[Direction].[(All)].[In]</code> with the intrinsic coords of the cell being evaluated, but it's hard to know what I need without first reading up on the subject :)</p>\n\n<p>[edit] I ended up with </p>\n\n<pre><code>IIF([Direction].currentMember = [Direction].[(All)].[Out],\n    0,\n    ([Measures].[Total traffic], [Direction].[(All)].[In])\n)\n</code></pre>\n\n<p>..but at least in SAS OLAP this causes extra queries to be performed (to calculate the value for [in]) to the underlying data set, so I didn't use it in the end.</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1121,"score":0,"question_id":7859146,"title":"Date dimension has stopped processing in OLAP cube","body":"<p>Little bit of background, we have an OLAP system that has been happily processing it's cube for a customer for a long time. Then recently it started to fail. This has coincided with the main developer accidentally getting married and making himself unavailable. So obviously I can't go pestering him. </p>\n\n<p>We have a date dimension that works at Year, Month, Day level. We have thow hierarchies  for calendar and fiscal years.</p>\n\n<p>It's currently throwing a message that I find pretty indecipherable (not being an OLAP dev) and the examples I've read online refer to it being caused by weeks splitting across months, which is not a problem I have.\nThe message is:</p>\n\n<pre><code>Rigid relationships between attributes cannot be changed during incremental processing of a dimension.\n</code></pre>\n\n<p>When I reprocess the cube I now get problems related to dates.  When I reprocess the Date dimension I get the following:</p>\n\n<pre><code>Internal error: The operation terminated unsuccessfully.\nErrors in the OLAP storage engine: Rigid relationships between attributes cannot be changed during incremental processing of a dimension.\nErrors in the OLAP storage engine: An error occurred while the 'Date ID' attribute of the 'Date' dimension from the 'TMC_CUBE_TESCO' database was being processed.\nErrors in the OLAP storage engine: The process operation ended because the number of errors encountered during processing reached the defined limit of allowable errors for the operation.\nServer: The operation has been cancelled.\n</code></pre>\n\n<p>When I view the entire detail for the Date Dimension I see that it has processed a heap of SELECT statements but falls down here:</p>\n\n<pre><code>SELECT DISTINCT [dbo_dw_DIMdate].[DateTime] AS [dbo_dw_DIMdateDateTime0_0],[dbo_dw_DIMdate].[DayOfMonth] AS [dbo_dw_DIMdateDayOfMonth0_1],[dbo_dw_DIMdate].[MonthNumberCalendar] AS [dbo_dw_DIMdateMonthNumberCalendar0_2],[dbo_dw_DIMdate].[YearCalendar] AS [dbo_dw_DIMdateYearCalendar0_3]\nFROM [dbo].[dw_DIMdate] AS [dbo_dw_DIMdate]\nProcessing Dimension Attribute 'Date ID' failed. 1 rows have been read.\nStart time: 10/21/2011 10:30:35 PM; End time: 10/21/2011 10:30:35 PM; Duration: 0:00:00\nSQL queries 1\n\nSELECT DISTINCT [dbo_dw_DIMdate].[DateID] AS [dbo_dw_DIMdateDateID0_0],[dbo_dw_DIMdate].[DayOfCalendarYear] AS [dbo_dw_DIMdateDayOfCalendarYear0_1],[dbo_dw_DIMdate].[DayOfFiscalYear] AS [dbo_dw_DIMdateDayOfFiscalYear0_2],[dbo_dw_DIMdate].[DayOfWeek] AS [dbo_dw_DIMdateDayOfWeek0_3],[dbo_dw_DIMdate].[IsCalendarYearToDate] AS [dbo_dw_DIMdateIsCalendarYearToDate0_4],[dbo_dw_DIMdate].[IsFiscalYearToDate] AS [dbo_dw_DIMdateIsFiscalYearToDate0_5],[dbo_dw_DIMdate].[IsLastCalendarMonth] AS [dbo_dw_DIMdateIsLastCalendarMonth0_6],[dbo_dw_DIMdate].[IsLastWeek] AS [dbo_dw_DIMdateIsLastWeek0_7],[dbo_dw_DIMdate].[IsWeekDay] AS [dbo_dw_DIMdateIsWeekDay0_8],[dbo_dw_DIMdate].[IsYesterday] AS [dbo_dw_DIMdateIsYesterday0_9],[dbo_dw_DIMdate].[DateTime] AS [dbo_dw_DIMdateDateTime0_10],[dbo_dw_DIMdate].[DayOfWeekName_engb] AS [dbo_dw_DIMdateDayOfWeekName_engb0_11],[dbo_dw_DIMdate].[ShortDayOfWeekName_engb] AS [dbo_dw_DIMdateShortDayOfWeekName_engb0_12],[dbo_dw_DIMdate].[WeekNumberCalendar] AS [dbo_dw_DIMdateWeekNumberCalendar0_13],[dbo_dw_DIMdate].[WeekNumberFiscal] AS [dbo_dw_DIMdateWeekNumberFiscal0_14],[dbo_dw_DIMdate].[WeekCommencing] AS [dbo_dw_DIMdateWeekCommencing0_15],[dbo_dw_DIMdate].[YearFiscal] AS [dbo_dw_DIMdateYearFiscal0_16],[dbo_dw_DIMdate].[YearCalendar] AS [dbo_dw_DIMdateYearCalendar0_17],[dbo_dw_DIMdate].[IsLastCalendarWeek] AS [dbo_dw_DIMdateIsLastCalendarWeek0_18]\nFROM [dbo].[dw_DIMdate] AS [dbo_dw_DIMdate]\nError Messages 1\n</code></pre>\n\n<p>I'm not after \"sent me teh codez\", but any help understanding the error message and problem would be very much appreciated.</p>\n"},{"tags":["sql-server","olap","data-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":85,"score":0,"question_id":7821706,"title":"Best way to transform data to intermediate DB for OLAP","body":"<p>I am doing research to see what is the best way to take data from a live database, and transform it to be able to put the data into data cubes. Currently as a prototype, we used normal queries, to copy data from the live database as a sequence of SQL Statements, and put into the intermediate DB that is used for OLAP, but for the real thing we are considering to use MDX.</p>\n\n<p>Any tips, if this is the best and most efficient way?</p>\n"},{"tags":["olap","business-intelligence","mondrian","olap4j"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":110,"score":0,"question_id":7528473,"title":"Please suggest ways to start building Business Analytics solutions using existing mysql databases","body":"<p>I believe there are three layers to build up- \n1) Presentation Layer/Data Visualization Layer\n2) Constucting olap server(like mondrian) to access mysql database and produce results.\n3)Using Olap Client API(olap4j) to build OLAP cubes that store intermediate data.</p>\n\n<p>Is this approach correct or is there any thing wrong with it?</p>\n\n<p>Please suggest.\nThanks in Advance</p>\n"},{"tags":["sql","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":46,"score":0,"question_id":7710775,"title":"Advice for hand-written olap-like extractions from relational database","body":"<p>We've implemented over the course of the years a series of web based reports summarizing historical business data (product sales, traffic, etc). The thing relies heavily on complex SQL queries, and the boss expects the results to be real time, but they need up to a minute to execute. The reports are customizable on a several dimensions. </p>\n\n<p>I've done some basic research, and it looks like what we need is some kind of OLAP (?), ETL(?), whatever. </p>\n\n<p>Is that true? Are we supposed to convert to a whole package and trash our beloved developments, or is there a possibility to keep it relational, SQL-based, and get close to a dedicated solution by simply pre-calculating some optimized views with a batch process running at night? Have you got pointers to good documentation on the subject?</p>\n\n<p>Thank you.</p>\n"},{"tags":["excel","odata","olap","cube","powerpivot"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":141,"score":1,"question_id":7712029,"title":"Any sample on how to expose a olap cube as oData so it can be used using powerpivot?","body":"<p>I'm looking for a sample on how to expose an olap cube as an odata feed so it can be consumed by powerpivot. I do not want to provide direct access to the cube.</p>\n"},{"tags":["mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":51,"score":0,"question_id":7515201,"title":"OLAP - levels have  the same name","body":"<p>I have the following Hierarchy:</p>\n\n<pre><code> &lt;Dimension name=\"Locations\"&gt;\n&lt;Hierarchy hasAll=\"true\" allMemberName=\"All Locations\" primaryKey=\"loc1Id\"  uniqueKeyLevelName=\"loc1Id\"&gt;\n  &lt;Table name=\"OLAP_Budget\"/&gt;\n  &lt;Level name=\"location1\" column=\"location1\" uniqueMembers=\"true\"/&gt;\n  &lt;Level name=\"location2\" column=\"location2\" uniqueMembers=\"true\"  hideMemberIf=\"IfBlankName\"/&gt;\n  &lt;Level name=\"location3\" column=\"location3\" uniqueMembers=\"true\"  hideMemberIf=\"IfBlankName\"/&gt;\n&lt;/Hierarchy&gt;\n</code></pre>\n\n<p>   </p>\n\n<p>The problem:</p>\n\n<p>\"location1\" is exit through  different fiscal Year and has different children in each fiscal year.\nI displayed \"fiscalYear\" dimension in column but when i choose to display values of a specific fiscalYear it display all children overall the fiscalYears.</p>\n\n<p>How can i solve this problem ?</p>\n\n<p>Thanks in Advance</p>\n"},{"tags":["sql-server","sql-server-2005","ssas","olap","cube"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":71,"score":1,"question_id":7559394,"title":"Setting up a relative dimension?","body":"<p>I have a pretty simple scenario but a very large data set (using even simpler example below to illustrate my issue). </p>\n\n<p>Let's say i have a cube comprised of Country table(fact) that has one dimension called Continent. </p>\n\n<p><img src=\"http://i.stack.imgur.com/EjOUT.png\" alt=\"enter image description here\"></p>\n\n<p>With this, i can aggregate country data by continent. </p>\n\n<p>But let's say each country has a city:</p>\n\n<p><img src=\"http://i.stack.imgur.com/sMcKs.png\" alt=\"enter image description here\"></p>\n\n<p>Here i can't assign Continent dimension directly to city, because city does not have a continent property. This is a simplified example, and it would be trivial to join Country information in while populating the city fact table. However, my application is using a very large dataset that requires a long time to query, and i am trying to avoid having to make a join on Country to get the continent id. I need to be able to write simple MDX query to get population count by country or by city.</p>\n\n<p>How can i set up my cube, so that dimension relationship in above scenario can be set up between city and continent, without adding continentID to city? </p>\n\n<p><strong>Update</strong></p>\n\n<p>As Brian suggested, i could make country a dimension. This is how i did it initially, and perhaps i didn't do it correctly but it was a performance hit because: Above example is simple, but in my case, i have 15 properties (such as continent above) that i need to aggregate my data on. If i create a country dimension, and specify those 15 properties as dimensional attributes, every time i process my cube, it will do a \"select distinct continent from country\" x15 (once per each attribute) in order to get that distinct list of continents. if Country table is huge (which in my case it is a view comprised of many big tables), it will take a very long time just to get that list of distinct values per dimension. </p>\n\n<p>my attempt above is just a way to work around this problem, and have separate table per dimension that i could easily manage. my only problem is that i have sub views which need to be aggregated on those properties, while the properties do not exist on sub tables and need to be looked up from \"country\" view etc.. </p>\n"},{"tags":["oracle","olap","xmla"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":371,"score":0,"question_id":6125830,"title":"Opensource or free online Oracle OLAP Server or Offline Oracle Cube file","body":"<p>Is there any free online Oracle OLAP servers available for testing? or Is there any offline cube available for Oracle like (.cub) in SSAS.</p>\n"},{"tags":["sql-server","synchronization","ssas","olap","data-synchronization"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":237,"score":0,"question_id":7410207,"title":"SQL Server 2005 Analysis Service (SSAS) Partial Synchronization","body":"<p>I'm new to SSAS (this is my first project that involves ssas).</p>\n\n<p>I have a regular a SQL Server 2005 server (say Blah) that run database instance and sql server analysis service. I want to synchronize some of the data in Blah (based on some condition) to another server, Blah2. Partial data sync is quite straightforward with the help of replication server. However, I'm not sure how to do a partial data synchronization for the analysis service.</p>\n\n<p>I have a table in Blah database that list all of the cubes in its analysis service. I then need to filter this table to list all the necessary cube and this is ok. But I'm sure how to continue from there. </p>\n\n<p>I've looked into the SSAS Database Sync Wizard but I couldnt find any command line tools for this or a way to run this as procedure in SQL Script (I will need to do this as a regular sql server job, so it's necessary not to rely on gui). Even if I want to use the gui, there doesnt seems to be a way to filter the cube/measurement from the gui.</p>\n\n<p>I'm thinking of getting the cube, measurement, data source view, etc dynamically but I cant find a way to get these definitions dynamically from sql script. I'm trying to do simple openquery to get list of cube in sql server screen with this (olap_server is a linked server to the ssas):</p>\n\n<pre><code>select *\nfrom openquery(olap_server, 'select [CATALOG_NAME]\nfrom $system.dbschema_catalogs')\n</code></pre>\n\n<p>with no luck. I got the \"An error occurred while preparing the query \"select [CATALOG_NAME]\nfrom $system.dbschema_catalogs\" for execution against OLE DB provider \"MSOLAP\" for linked server \"olap_server\".\" error instead.</p>\n\n<p>Is there any straightforward way to do this task? </p>\n"},{"tags":["sap","mdx","olap","xmla"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":172,"score":0,"question_id":7391559,"title":"Updating cube (writeback) via MDX on SAP","body":"<p>does anybody know if SAP BW supports UPDATE CUBE statement in MDX query (connection to server established via XMLA) ?? It returns some generic error and I cannot find any documentation... </p>\n\n<p>Same syntax works well for other providers.</p>\n\n<p>Or is there any other way for writing data to SAP BW cube via MDX?</p>\n\n<p>Thanks for any advice,\nVrata</p>\n"},{"tags":["sql-server","wpf","oracle","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":102,"score":0,"question_id":7368027,"title":"Olap/multi dimensional reporting, WPF client, agnostic data?","body":"<p>Can anyone give me general guidelines on how to approach multi dimensional reporting where I'd like to support at the very least cube generated from Oracle and SQL Server databases. I can imagine GemFire or Coherence being in the mix too. </p>\n\n<p>I'm a little unsure where to start. If I work entirely in the Microsoft ecosystem I'm fine with SQL Server Analysis services, reporting services, MDX. Introduce the other data sources and I'm lost. </p>\n\n<p>Thanks</p>\n"},{"tags":["mdx","hierarchical-data","olap","missing-data"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":142,"score":0,"question_id":7355519,"title":"Is OLAP/MDX a good way to process data w/ unknown values at various aggregation levels","body":"<p>I'm new to OLAP, so perhaps I don't know the right terminology to use for this question, but bear with me here.</p>\n\n<p>I work with lots of hierarchical, multidimensional data where parent/aggregated cells mostly have data, but child/leaf cells are often missing data (attribute values are unknown but non-zero). I currently use a combination of scripting and SQL to work with it, but that's getting unwieldy. It seems like OLAP cubes and MDX are better suited to the <em>structure</em> of the data, but not necessarily to <em>tasks</em> I need to do with it. For example:</p>\n\n<ul>\n<li>OLAP seems mainly designed for read-only reporting; I do a lot of modifications to the data in batch processes</li>\n<li>OLAP seems to like having complete leaf-level data to calculate aggregates; my data has missing values at various levels</li>\n</ul>\n\n<p>Examples of what I want to do:  </p>\n\n<ul>\n<li>Load original multi-level data into cube and preserve known parents; don't overwrite or display their values as calculated aggregates of children (which may be incomplete).</li>\n<li>Create/update/delete cells in a cube based on results from complicated queries/joins of other cubes. Sometimes a cube needs to be transformed to use a slightly different dimension definition.</li>\n<li>Users require estimates for unknown values. I can create decent estimates, but need to adjust them so they conform to known parents/children across all dimensions and levels (this is much harder than it sounds). I am already doing this, but it involves pulling the data out of the RDBMS into a custom executable.</li>\n<li>Queries and calculations need to be able to handle the unknowns properly. Ideally be able to easily query how much of an aggregated cell's value is made up of estimated vs. known values, possibly compute confidence/error statistics, or check whether we can derive an exact value for an unknown when it has a known parent and all known siblings, etc.</li>\n<li>Data can be large... up to tens of millions of fact table rows. Performance needs to be decent for batch jobs (minutes are ok, hours not so much).</li>\n</ul>\n\n<p>Could an OLAP server and MDX be a good tool for this type of work? Are there any other tools that would work well for manipulating hierarchical/multidimensional/gap-filled data?</p>\n"},{"tags":["mdx","olap","delimiter"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":67,"score":0,"question_id":7256149,"title":"MDX problem: Source data in columns can contain square brackets ([ ]), how to stop these being interpreted as delimiters?","body":"<p>I am working on a project that is using OLAP cubes, and we have a problem with an MDX statement. </p>\n\n<p>The problem is that our source data has square brackets in. For example:\nCustomer [customer code]</p>\n\n<p>This is an example query on a specific customer, whose name is \"CustomerA [123]\". The measures list is insignificant and has been left out:</p>\n\n<pre><code>SELECT &lt;measures&gt; ON COLUMNS, \n[Customer_Dim].[All Customer_Dim].[CustomerA [123]] ON ROWS\nFROM [cubename]\n</code></pre>\n\n<p>So when we submit this query for one specific customer, the MDX uses those square brackets as delimiters.</p>\n\n<p>This causes an error, because it is reading the [123] and thinks there is a syntax error.</p>\n\n<p>We want to protect the square brackets from the data from being read as delimiters. Is there a way to shield them, or are we forced to change the character to something else?</p>\n\n<p>Thanks</p>\n"},{"tags":["java","analytics","olap","business-intelligence"],"answer_count":4,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":618,"score":1,"question_id":5089898,"title":"In memory and embeddable OLAP implementation compatible with olap4j","body":"<p>I am looking for an OLAP implementation, which could be embedded in a java application. The best -- but not necessarily -- if I could use olap4j to connect to it. I need such a library for testing purposes of my application to evaluate ideas before go for a standalone OLAP server. </p>\n"},{"tags":["sql-server","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":181,"score":0,"question_id":7158229,"title":"SQL Server 2008 Analysis services","body":"<p>I am creating an analysis dashboard using DUNDAS dashboard. For that I have to create an OLAP cube. </p>\n\n<p>Is OLAP servcices already installed with SQL server 2008 or do we have to install it separately? </p>\n"},{"tags":["mysql","query","reporting","aggregate","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":157,"score":0,"question_id":4971312,"title":"MySQL: Use aggregate result in further calculation","body":"<p>I'm currently working on writing report generators.  For one report I need to do a breakdown by a given characteristic (supplier, logging user, language, etc which for each row includes the name of the characteristic I'm interested in, the number of items that match that characterastic, and the percentage of total items this figure represents.  The first two aren't a problem, the third is.  </p>\n\n<p>For example, to get a breakdown by language I'd be using a query like this.  </p>\n\n<pre><code>SELECT lang_id, \nCOUNT(IF(open=TRUE,1,NULL)) AS lang_total\nFROM table\nGROUP BY lang_id;\n</code></pre>\n\n<p>This gives me the number of items per language.  </p>\n\n<p>I can get the total number of items in the table and store it in a variable simply enough with a plain count. </p>\n\n<pre><code>SELECT @totalOpen:=COUNT(*) FROM table WHERE open = TRUE;\n</code></pre>\n\n<p>Now I want to add a third column, which is the figure in lang_total divided by the value in @totalOpen multiplied by 100 (in other words, the percentage of all items that fit the criteria).  Something along the lines of the following:</p>\n\n<p>This is the bit I'm having trouble with, as because as far as I can tell you can't use aggregate columns in calculations.  </p>\n\n<pre><code>SELECT lang_id, \nCOUNT(IF(open=true,1,NULL)) AS lang_total\n(lang_total/@totalOpen)*100 as lang_percent\nFROM table\nGROUP BY lang_id;\n</code></pre>\n\n<p>I'm sure that there must be a way of doing this in MySQL, but I've not been able to track it down.  Can anyone help out with this?</p>\n"},{"tags":["ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":915,"score":0,"question_id":2556417,"title":"How can I obtain a list of a SSAS Cube's dimentions and dimentions' attributes","body":"<p>I have a user asking me to list the dimensions and dimension attributes of our SSAS cube. </p>\n\n<p>I susspect I could generate this via AMO, but I'm wondering if there's an MDX query or SSMS option to show the same info.</p>\n\n<p>Any ideas?</p>\n"},{"tags":["database","filter","mdx","olap","mondrian"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":613,"score":0,"question_id":7078647,"title":"MDX - Filter on measure value?","body":"<p>I want to write an MDX expression that uses a measure value in the WHERE statement. </p>\n\n<p>For example: suppose I want to show the income from sold products in stores in different cities, but I only want to count the income for sold products that have a price over $10.</p>\n\n<p>This is what I tried but it doesn't work:</p>\n\n<pre><code>WHERE ([MEASURES].[Price]&gt;10)\n</code></pre>\n\n<p>How can I do this using MDX?</p>\n"},{"tags":["olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":143,"score":0,"question_id":6869088,"title":"Infor PM Application Studio","body":"<p>Is there anyone here using Infor PM Application studio or has experience with it? I m stuck on afew problems but find virtually no resource to get help and the manual is dull and not helpful. </p>\n\n<p>Please let me know if you can answer afew question. I'm new to the application so most questions are usability, things like how to manipulate global variables.</p>\n\n<p>Specifically, my question is to do with How i can relate a Selection in \"List box\" to a HyperBlock.</p>\n\n<p>for example, if i have a List Box that allows user to select a year (2010,2011...etc). This list box outputs to a global variable Iâ€™ve created, and i can use this global variable to structure the Hyperblock to show the contents based on selected year.</p>\n\n<p>BUT  i also need to structure hyperblock based on previous year and the year before that and not just current. So if user picks 2011, i also need to display 2010 and 2009. I am stuck on how i can do this. </p>\n\n<p>Thanks</p>\n"},{"tags":["hadoop","olap","hive","oltp"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":568,"score":1,"question_id":6978300,"title":"Make OLAP with Hadoop Hive from OLTP Mysql","body":"<p>I bit confuse with Hadoop hive which i read from Wiki used for make OLAP.\nNow i want to make OLAP on Hive from OLTP database which use Mysql.</p>\n\n<p>How i can solve this? can i use Kettle for make OLAP in Hive?\nany guidance how to make OLAP on Hive from OLTP mysql ?</p>\n\n<p>Tks.</p>\n"},{"tags":["python","mdx","olap","psycopg2","xmla"],"answer_count":3,"favorite_count":4,"up_vote_count":5,"down_vote_count":0,"view_count":2260,"score":5,"question_id":3793215,"title":"Query OLAP Mondrian (MDX, XMLA) with a Python interface?","body":"<p>Actually I'm using <a href=\"http://en.wikipedia.org/wiki/R_%28programming_language%29\" rel=\"nofollow\">R</a> + Python with RPY2 to manipulate data and ggplot to create beautiful graphics.. I have some data in a PostgreSQL database, and I'm using psycopg2 to query data.</p>\n\n<p>I'm starting a thesis, and in the future I need an <a href=\"http://en.wikipedia.org/wiki/OLAP_cube\" rel=\"nofollow\">OLAP cube</a> to store my (very big) simulation data: multiple dimension, aggregation query, etc.</p>\n\n<p>Is there any best or standard practice for interfacing between Python (and I want Python + R, no jpivot or some other dashboard in Java) and an OLAP engine like <a href=\"http://en.wikipedia.org/wiki/Mondrian_OLAP_server\" rel=\"nofollow\">Mondrian</a>? I searched on Google for any solution, and didn't I find anything.</p>\n\n<p>I've briefly evaluated <a href=\"http://en.wikipedia.org/wiki/SQLAlchemy\" rel=\"nofollow\">SQLAlchemy</a>, and Django-ORM, but they have no <a href=\"http://en.wikipedia.org/wiki/MultiDimensional_eXpressions\" rel=\"nofollow\">MDX</a> or XML/A interface to query an OLAP server (Mondrian or other) ...</p>\n\n<p>Is it possible to write a query in MDX and, with psycopg + ODBC, query my OLAP server, and the OLAP server giving me an answer from my simulation data (no mapping on Python object, but it's OK for me)?</p>\n\n<p><strong>Update 1 :</strong> </p>\n\n<p><em><strong>Why do I need to search around OLAP + Mondrian technology ?</em></strong></p>\n\n<p>Because <a href=\"http://en.wikipedia.org/wiki/Universit%C3%A9_Laval\" rel=\"nofollow\">University of Laval</a> (GeoSoa departements + Thierry Badard) wrote a spatial extension to OLAP: SOLAP, and implemented this in Mondrian as <a href=\"http://www.spatialytics.org/projects/geomondrian/\" rel=\"nofollow\">GeoMondrian</a>.\nThat interest me because I'm working on spatial multi agent based simulation ( ~= geosimulation).</p>\n\n<p>The GeoSoa departement created an Ajax based component to communicate and visualize spatial data with GeoMondrian: SOLAPLAYERS, which can query a Mondrian server by its Xlma servlet.</p>\n\n<p>Problem : probably slow in big data manipulation, need Internet or Apache 2. Briefly, it's only to visualize data or map ... In my case, I need raw data to make my own data manipulation + graphics with R: spatial analysis, regression analysis, rank-tail, etc. Here, SOLAP help me to prepare data for this later complex R analysis.</p>\n\n<p><em><strong>Why Python?</em></strong></p>\n\n<p>1 - Web access to spatial data -</p>\n\n<p>I'm trying to use a \"cool\" Python framework, like <a href=\"http://geodjango.org/\" rel=\"nofollow\">GeoDjango</a> or <a href=\"http://en.wikipedia.org/wiki/MapFish\" rel=\"nofollow\">MapFish</a>: big community in GIS, open-source, use <a href=\"http://www.geoalchemy.org/intro.html\" rel=\"nofollow\">GeoAlchemy</a> to manipulate spatial query/data, include visualisation with JavaScript extensions and <a href=\"http://en.wikipedia.org/wiki/OpenLayers\" rel=\"nofollow\">OpenLayers</a>, etc.</p>\n\n<p>2 - Local access to spatial data in GIS -</p>\n\n<p>I want to create a plugin in QGIS (open source GIS) to access and visualize data, and QGIS plugin and API = Python.</p>\n\n<p>3 - Automatic analysis of data - </p>\n\n<p>A user or scientist runs a simulation with grid computing and choose automatic analysis (R + ggplot2 + MDX query) they want to run on this data. My goal here is to create a synthetic report of the simulation (graphic, tabular data, etc.).</p>\n\n<p>So, after simulation, data go to OLAP/SOLAP cube, and many Python scripts (created by the user) get data with MDX, manipulate data with R + RPY2, and write and produce cool output for the scientist on doku-wiki or another community-platform.</p>\n\n<p><em><strong>Problem?</em></strong></p>\n\n<p>1 - Olap4j, the API core of Mondrian to communicate with an external component, is Java-made :/</p>\n\n<p>2 - SOLAPLAYERS uses Ajax to access data, too slow for me.</p>\n\n<p>3 - SQLAlchemy and GeoAlchemy have no driver connection to a multidimensional database (OLAP).</p>\n\n<p><strong>* Solution? *</strong></p>\n\n<p>1 - Py4j to access Java object or Java collection in olap4j with Python? Write my own function to access the Java mapped collection? => dangerous and not very easy?... </p>\n\n<p>2 - XLMA with Ajax Mondrian server? It is too slow.</p>\n\n<p>3 - Write my own py-connector to OLAP Mondrian ? => Ouch. It's an hard way, I think.</p>\n\n<p>What should I do?</p>\n"},{"tags":["mdx","olap","business-intelligence","olap-cube","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":447,"score":0,"question_id":6979698,"title":"How to get current row value in a WITH MEMBER calculation MDX?","body":"<p>I would like to calculate a Measure based on the current row.\nProblem is I can't find a way to get the current row in a WITH MEMBER part.</p>\n\n<pre><code>WITH MEMBER [Measures].[Test] AS AVG(\n    NonEmptyCrossJoin(\n                FILTER(DESCENDANTS([Exigences].[ENVGR], [Levier], SELF),\n                       [Exigences].CurrentMember.Name = 'Chemicals'),\n                DESCENDANTS([Organization].[Valeo].[Powertrain Systems], [entity], SELF)),\n    [Measures].[ProgressLevel])\n\nSELECT {[Measures].[ProgressLevel], [Measures].[Test]} ON COLUMNS,\nDESCENDANTS([Exigences].[ENVGR].[ENVGR-01.001], [Levier], SELF) ON\nROWS FROM [Exigences]\n</code></pre>\n\n<p>Chemicals is currently hard coded. That is for the example.\nI would like in place of 'Chemicals' to have the current rows value.</p>\n\n<p>So let's say those are the values rows will return 'Chemicals', 'Pharmacy', 'Test', I would like the [Measures].[Test] calculation to change.</p>\n\n<p>Can MDX do that ? If so how can I get the current value.</p>\n\n<p>I tried [Levier].CurrentMember.Name but I think it's conflicting with the [Exigences].CurrentMember.Name.</p>\n\n<p>Any one has an idea ?</p>\n\n<p>Thank you,</p>\n"},{"tags":["sql-server","ruby","analysis","data-warehouse","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":270,"score":0,"question_id":6608328,"title":"Ruby architecture for OLAP / analytics applications","body":"<p>I'm evaluating Ruby as a platform / language of choice for developing web-based custom OLAP / analytics applications (backed by a data warehouse).</p>\n\n<p>Key requirements:</p>\n\n<ul>\n<li>Ability to create custom charts / views accessible over the web</li>\n<li>Ability to offer \"pivot table\" style analytics functionality on the web</li>\n<li>Ability to interface with an existing data warehouse / cubes (Microsoft SQL Server)</li>\n</ul>\n\n<p>Has anyone had good experiences with using a Ruby-based stack in this kind of context?</p>\n\n<p>What would be the recommended architecture / set of components or libraries to make this work well?</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":840,"score":0,"question_id":7012581,"title":"Percentage Calculation on MDX","body":"<p>Im new to MDX Query and I'm trying to add a percentage on attended percentage in each row.  The following code :</p>\n\n<pre><code>SELECT {[Measures].[Client Interventions Count]* [Dim Intervention Attendance].[Attended].Children} ON COLUMNS,\n[Dim Date].[Calendar].[Month Name] ON ROWS\nFROM [Client Intervention]\n</code></pre>\n\n<p>procude a result of :</p>\n\n<p><img src=\"http://i.stack.imgur.com/TiehM.png\" alt=\"enter image description here\"></p>\n\n<p>How can I perform a calculation on each row? For example, first row November 2007 , total client intervention count = 68 , so the percentage count should be 57/68 %</p>\n\n<p>Any idea?? Thanks</p>\n"},{"tags":["hadoop","analytics","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":321,"score":1,"question_id":6958109,"title":"Select DB, OLAP solutions for fast web analytics (large data array)","body":"<p>I have the following problem: my system collects daily ~300M hits from different sites. \nEvery has time, user id, type (ad or usual), http address, site id. </p>\n\n<p>There is also an array of users ~ 200M, which has gender, age group and country. </p>\n\n<p>Required to design a system that is based on data by hits could give real-time reports on the hits of different user groups. Like OLAP solutions :-)</p>\n\n<p>For example, to plot graph on hits for girls 15-25 age, from UK, from October to September, 2011. </p>\n\n<p>Which database you recommend to choose, and solution to build OLAP cubes? </p>\n\n<p>I'm looking for opensource solution, like HBase (+ zohmg or cascading) Hypertable or something else (free DWH :-)).</p>\n"},{"tags":["sql-server","ssas","mdx","olap","bids"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":928,"score":0,"question_id":6847677,"title":"MDX query to sum a measure for all columns/rows","body":"<p>I have a cube that has:</p>\n\n<pre><code>DimEntity\nEntityID\nEntityName\nEntityLongName\n\nFactReturns\nTotalReturn\n</code></pre>\n\n<p>What I want to do is sum the TotalReturns between all combinations of entities, so the output is like this:</p>\n\n<pre><code>             NameA        NameB\nLongNameA    sum(A, 1)    sum(A, 2)\nLongNameB    sum(B, 1)    sum(B, 2)\n</code></pre>\n\n<p>(sum(A, 1) = sum(A, A), because EntityName \"A\" and EntityID \"1\" refer to the same entity)</p>\n\n<p>What I have now is this:</p>\n\n<pre><code>WITH MEMBER [Measures].[SumReturns] AS\n    SUM([Dim Entity].[EntityID], [Measures].[TotalReturn])\nSELECT \n    [Dim Entity].[EntityName].Children ON COLUMNS,\n    [Dim Entity].[EntityLongName].Children ON ROWS  \nFROM\n    [Returns]\nWHERE\n    [Measures].[SumReturns]\n</code></pre>\n\n<p>But this just gives me a table like this:</p>\n\n<pre><code>             NameA            NameB\nLongNameA    A.TotalReturn    null\nLongNameB    null             B.TotalReturn\netc...\n</code></pre>\n\n<p>I am just learning MDX and having a real hard time understanding how this works. </p>\n"},{"tags":["dataset","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":123,"score":1,"question_id":6825264,"title":"Public dataset for OLAP design","body":"<p>I need a complex (in some degree) public dataset for OLAP kind of analysis and reports. Foodmart, AdventureWorks and Steel-Wheels which comes with BI products are focused primary on a single domain - retail sale, and the datasets I have worked with in my employment\nalso are not much different then those.</p>\n\n<p>I am in search for some interesting and complex dataset (from health sector, etc) having adequate dimension and facts for challenging OLAP design.</p>\n\n<p>There are a lot of public dataset available, in AWS, and in various links provided in this very site (stackoverflow) but I find none of them to be applicable for OLAP design but for data mining.</p>\n\n<p>Can anyone please help me to point out or share some datasets as I have mentioned.</p>\n\n<p>Regards</p>\n"},{"tags":["mdx","olap","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":119,"score":1,"question_id":6791164,"title":"Good MDX default query","body":"<p>I have build an MDX editor and now need a good default query which executes and already has two dimensions. I would like to place the measures on the first dimension (without knowing their names), and any other cube dimension on the second result dimension. Currently I have achived this:</p>\n\n<pre><code>select {[Measures].members} ON COLUMNS\n  from [mycubename]\n</code></pre>\n\n<p>But I don't know how to populate the second column... Any Ideas?</p>\n\n<p>Something like </p>\n\n<pre><code>select {[Measures].members} ON COLUMNS,\n       {[Dimensions].[first].members} ON ROWS  \n  from [mycubename]\n</code></pre>\n\n<p>which would work against any cube if the cube name is given in the from clause.</p>\n"},{"tags":["c#","oracle","olap","cube"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":975,"score":0,"question_id":868629,"title":"Accessing an OLAP data present in Oracle Cubes using C# .NET?","body":"<p>I am a newbie to ORACLE.  I would like to access an OLAP cube in Oracle using C#.  Could you please suggest efficient ways of doing the same?</p>\n"},{"tags":["architecture","ssas","olap","analysis-services","cube"],"answer_count":2,"favorite_count":2,"up_vote_count":0,"down_vote_count":0,"view_count":160,"score":0,"question_id":6713582,"title":"How to Program Business Logic into an OLAP Cube?","body":"<p>We are seeking to build an OLAP cube from a relational DB. But the database contains only raw data. The \"domain logic\" such as calcuations, conditional logic, and custom aggregations (i.e., sum up all of the rows that meet these conditions and no other row exists such that blah blah blah) is all contained in .NET code. I would like values generated by that code to be included in the cube. </p>\n\n<p><strong>Question 1:</strong> What kind of architecture do you recommend to include domain logic in a cube? I would prefer NOT to...</p>\n\n<ul>\n<li>Code this logic into views, stored procs, or UDFs in the source database.</li>\n<li>Include the domain logic into the OLAP cube as calculated members</li>\n</ul>\n\n<p>Keeping my business logic in .NET code keeps in easy to maintain, scale, and test.  </p>\n\n<p><strong>Question 2:</strong> Is this a good architecture?</p>\n\n<ul>\n<li>Create a secondary OLTP database as a data warehouse. </li>\n<li>Then create a custom ETL process to pull data from the source system, do the calculations, and write that information back into the DW database, </li>\n<li>Have the cube process the DW database </li>\n</ul>\n"},{"tags":["mdx","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":110,"score":0,"question_id":6680913,"title":"define measure aggregate at run time","body":"<p>Am using OLAP and i want to make measure functions e.g(count,max,..) to be selected by the user (to be as a filter).</p>\n\n<p>Is there a way to choose measure aggregate function of a cube at run time ?</p>\n\n<p>Thanks in Advance</p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":500,"score":0,"question_id":243985,"title":"SSAS custom group by query","body":"<p>My fact table looks like this</p>\n\n<pre><code>yesterday a\nyesterday a\nyesterday a\nyesterday b\nyesterday b\nyesterday c\ntoday     a\ntoday     a\ntoday     b\ntoday     b\ntommorow  a\ntommorow  a\ntommorow  c\ntommorow  d\n</code></pre>\n\n<p>In the end I need an Excel report like this</p>\n\n<pre><code>               repetition count\n               1     2     3\nyesterday      1     1     1\ntoday          0     2     0\ntomorow        2     1     0\n</code></pre>\n\n<p>How to create a \"repetion count\" dimension in SSAS 2k5 ? Please keep in mind that my fact table is a liitle bit more complicated and I have more other dimension there. </p>\n\n<p>My idea is to create a named query in DSV but I have some doubts if filtering will work correctly.</p>\n"},{"tags":[".net","data","olap","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":336,"score":0,"question_id":6651476,"title":"Open, free, cube data structures for .NET","body":"<p>I'm embarking on a project that allows users to slice and dice data in a fashion much like that provided in OLAP systems. However, the data is not stored in an OLAP system and will be provided to the front-end as flat records from a relational system. </p>\n\n<p>My initial thinking is that I may need to take that flat data and populate a client-side cube data structure with it, which can then be queried via a programmatic interface. Whilst such a data structure sounds interesting and challenging to write myself, I'm wondering whether there is already a free, open implementation that I can leverage. </p>\n\n<p>Ideally, it would:</p>\n\n<ul>\n<li>provide a lot of flexibility around defining dimensions, their levels, members, and attributes</li>\n<li>support calculated measures</li>\n<li>provide a nice interface by which to query the cube</li>\n<li>be free, open source, and untied to any particular interface technology</li>\n</ul>\n\n<p>Does anyone know of such a project I could use?</p>\n"},{"tags":["sql","database","database-design","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":458,"score":3,"question_id":6413773,"title":"How to calculate the likely size of an OLAP cube","body":"<p>Does anyone know a method to use to get a rough size of an OLAP cube based on a star schema data warehouse. Something based on the number of dimensions, the number of records in the dimension tables and the number of fact records and finally the number of aggregations or distinct records etc..</p>\n\n<p>The database I am looking at has a fact table of over 20 billion rows and a few dimension tables of 20 million, 70 million and 1.3 billion rows.</p>\n\n<p>Thanks\nNicholas</p>\n"},{"tags":["mysql","data-warehouse","olap","etl","pentaho"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":178,"score":0,"question_id":6554516,"title":"which is most suitable develop tools kit for data warehouse development in remote enviroment?","body":"<p>We have all Mysql data store in remote server (internal network, only can be accessed by an entrance server). So we can't have a online schema fetch but should always finish it manually.\nSo which do you think fit the request best? (community version or free verseion only)</p>\n\n<p>====ETL====</p>\n\n<p>Pentaho Kettle? (Spoon)</p>\n\n<p>seems always try to connect to database and no response. </p>\n\n<p>Talend (TOS)</p>\n\n<p>good to use. but efficiency seems not as good as kettle.</p>\n\n<p>=====DATABASE=====</p>\n\n<p>HDFS?</p>\n\n<p>Mysql cluster?</p>\n\n<p>Mysql infobriht?</p>\n\n<p>====OLAP====</p>\n\n<p>Pentaho?</p>\n\n<p>Any suggestion is appreciated.</p>\n"},{"tags":["sql-server-2005","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":143,"score":0,"question_id":6462045,"title":"SSAS OLAP MDX and relationships","body":"<p>I new to OLAP, and still not sure how to create a relationship between 2 or more entities. </p>\n\n<p>I am basing my cube on views. For simplicity sake let's call them like this:</p>\n\n<blockquote>\n  <p>viewParent (ParentID PK)</p>\n  \n  <p>viewChild (ChildID PK, ParentID FK)</p>\n</blockquote>\n\n<p>these views have more fields, but they're not important for this question. </p>\n\n<p>in my data source, i defined a relationship between viewParent and viewChild using ParentID for the link. </p>\n\n<p>As for measures, i was forced to create separate measures for Parent and Child. </p>\n\n<p>in my MDX query however, the relationship does not seem to be enforced. If i select record count for parent, child, and add some filters for the parent, the child count is not reflecting it.. </p>\n\n<pre><code>SELECT {\n    [Measures].[ParentCount],[Measures].[ChildCount]\n} ON COLUMNS\nFROM [Cube]\nWHERE {\n    (\n    {[Time].[Month].&amp;[2011-06-01T00:00:00]}\n    ,{[SomeDimension].&amp;[Foo]}\n    )\n}\n</code></pre>\n\n<p>the selected ParentCount is correct, but ChildCount is not affected by any of the filters (because they are parent filters). However, since i defined a relationship, how can i take advantage of that to filter children by parent using a WHERE clause? </p>\n\n<p>Facts:</p>\n\n<p>viewParent, viewChild</p>\n\n<p>Dimensions: </p>\n\n<p>ParentDimension (contains attributes from parent view that i'd aggregate on)\nChildDimension (contains attributes from child view that i'd aggregate on)</p>\n\n<p>This is just an idea i came up with, but maybe my design/relationship is off.</p>\n"},{"tags":["ms-access","olap"],"answer_count":6,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":360,"score":3,"question_id":1584551,"title":"MS Access + OLAP","body":"<p>I have lot of data in MS Access, and for analysis I need tools. Might you suggest any tools for data mining and analysis (OLAP)?</p>\n"},{"tags":["data-warehouse","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":455,"score":0,"question_id":6265446,"title":"Implementing data cube in c#","body":"<p>I am trying to implement a multi dimensional data cube in c#. Could somebody point in the direction of resources that would serve as a starting point. I am primarily interested in data structures needed to implement the cube.</p>\n"},{"tags":["mdx","olap","business-intelligence"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":1,"view_count":168,"score":0,"question_id":6395178,"title":"Business Intelligence and OLAP/MDX","body":"<p>What are good (no vendor related) blogs about Business Intelligence and OLAP/MDX ?</p>\n\n<p>Edited: To widen a bit the scope and after the answer of Boyan: blogs/forums related to information visualization and Business Intelligence ?</p>\n"},{"tags":["mysql","database","apache","analytics","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":186,"score":2,"question_id":6393439,"title":"How to store metrics for my web app?","body":"<p>I need to store more metrics for my web app. User behavior and other conditions needs to be tracked over time and compared.</p>\n\n<p>Some records have a timestamp associated with it, some don't. So an on-demand query for metrics might not be suitable all the time. I think what is needed is a snapshot (daily?) of certain analytics queries (via a cronjob?) that I write and then stored somewhere (DB? file?). </p>\n\n<p>Right now I'm worried about the size of these snapshots if I were to save them in the DB. How will it affect my app's performance? </p>\n\n<p>Admins should be able to view these analytics on a web dashboard. Imagine storing the state of 100,000+ rows of data every day....and then querying them pretty often to do analysis.</p>\n\n<p>Are there other good approaches to storing and viewing metrics? I'm using the LAMP stack for my app. Also using Google Analytics and other 3rd party metric tracking tools but it's not good enough to track specialized statistics for my app.</p>\n"},{"tags":["sql-server-express","olap"],"answer_count":4,"favorite_count":1,"up_vote_count":3,"down_vote_count":0,"view_count":1352,"score":3,"question_id":3724548,"title":"OLAP on SQL Express","body":"<p>I'm wondering if there is any desktop OLAP solution that can use SQL Express (and therefore does not require Analysis Services)</p>\n\n<p>I've been tasked with finding a way to allow our customers to do 'Ad-Hoc' reports, but the vast majority of them are on Sql Express, In previous jobs, customers have had Analysis Services and typically Cognos or Crystal Reports, so all that was required was to design the cube.</p>\n"},{"tags":["ssas","mdx","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":597,"score":0,"question_id":6308165,"title":"Merging two tuples in the same hierarchy into one (in MDX WITH SET command)","body":"<p>The following MDX query returns measure X on 3 tuples: 2001, 2002-1 and 2002-2. What I am trying to do is merging 2002-1 and 2002-2 into one tuple and have the measure X for 2001 and 2002-1&amp;2. Using SUM function is not possible. Because measure X is used on other axis.</p>\n\n<pre><code>with \nmember v as [Measures].[X]\nset w as {[Dim Date].[Calendar Date].[Year].&amp;[2001],\n[Dim Date].[Calendar Date].[Month].&amp;[1]&amp;[2002],\n[Dim Date].[Calendar Date].[Month].&amp;[2]&amp;[2002]}\nselect w on 0, v on 1\nfrom [DS];\n</code></pre>\n"},{"tags":["sharepoint","translation","multilingual","olap","performancepoint"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":96,"score":0,"question_id":6227066,"title":"Associating user selection of a language for an application with the corresponding translation in an OLAP database","body":"<p>Here is my problem: I have a multilingual SharePoint application and I have PerformancePoint reports in that application. In my OLAP database I have set up 3 translations for the dimension's and cube members for the corresponding languages that the application uses. \nMy question is - how do I retrieve (select) the content from the OLAP cube for the selected language in the application. I don't know how to associate  the selected language in the application with the available translations in my OLAP database.\nYour help will be very appreciated.</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":765,"score":0,"question_id":6278462,"title":"Filtering hierchies in MDX WITH clause","body":"<p>By using the answer of <a href=\"http://stackoverflow.com/questions/6268451/mdx-on-multiple-hierarchical-dimensions/6274438\">MDX on multiple hierarchical dimensions</a> I have the following MDX query:</p>\n\n<pre><code>with\nmember L1Y1 as ([Dim Location].[Hierarchy].[Center].&amp;[1],\n        [Dim Date].[Calendar Date].[Year].&amp;[2010],\n        [Measures].[x])                 \nselect ([Dim Attribute].[Parent Code].&amp;[10000]) on 0, \n       ({L1Y1}) on 1\nfrom DS\n</code></pre>\n\n<p>Now the problem is how to filter the L1Y1 based on its children. For example suppose we want to filter it so that only season 2 and month 7 included in the query. The following query output is the same as above and the <code>where</code> clause has no effect:</p>\n\n<pre><code>with\nmember L1Y1 as ([Dim Location].[Hierarchy].[Center].&amp;[1],\n        [Dim Date].[Calendar Date].[Year].&amp;[2010],\n        [Measures].[x])                 \nselect ([Dim Attribute].[Parent Code].&amp;[10000]) on 0, \n       ({L1Y1}) on 1\nfrom DS\nwhere [Dim Date].[Calendar Date].[Season].&amp;[2] and \n      [Dim Date].[Calendar Date].[Month].&amp;[7]\n</code></pre>\n"},{"tags":["ssas","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":212,"score":0,"question_id":6281431,"title":"Dimension members listed multiple times in cube","body":"<p>I have a dimension with two attributes where one can be listed as a child of the other in a hierarchy. In the table there is a column for each attribute value so for attribute B it can be listed in the table multiple times (for every different attribute A, ex: A1:B1, A2:B1, A1:B2, A3:B1, etc).</p>\n\n<p>When listing members for attribute B in the cube browser, SSAS lists each value for attribute B multiple times (per every row that was in the table). How do I get it to only list a unique value of attribute B once. It also lists it multiple times in the grid if A is not part of the MDX query.\n(Ex: Row headers: B1, B2, B3, B1, B2, B1, B2, etc).</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":671,"score":0,"question_id":6268451,"title":"MDX on multiple hierarchical dimensions","body":"<p>2 hierarchical dimensions (for location and time) are defined on a cube. My question is about possibility of writing a single MDX query for retrieving following structure. I mean writing a single query for obtaining values V1, V2, V3 and V4:</p>\n\n<p><img src=\"http://i.stack.imgur.com/wRIbs.jpg\" alt=\"enter image description here\"></p>\n\n<p>The obvious way is to use multiple MDX queries. Just wondering if there is some magic syntax in MDX.</p>\n"},{"tags":["sql-server","sql-server-2008","ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":150,"score":0,"question_id":6268203,"title":"OLAP Error while Processing","body":"<p>I am new to OLAP, and figured out how to make a cube and process it. However, when i play with it too much, i eventually come up against this error: </p>\n\n<blockquote>\n  <p>Errors in the OLAP storage engine: The\n  attribute key cannot be found: Table:\n  dbo_v_MYEntities, Column: uniqueId,\n  Value: 2548. Errors in the OLAP\n  storage engine: The record was skipped\n  because the attribute key was not\n  found. Attribute: Unique Id of\n  Dimension: v MY Entities from\n  Database: Test Cube New, Cube: MYdm\n  MyApp - Views, Measure Group: v MY\n  Entities, Partition: v MY Entities,\n  Record: 2526.</p>\n</blockquote>\n\n<p>It seems that some values get stuck, and the cube expect the value to be there, I know i can edit error properties and stop it from throwing exceptions, but i would like to be able to fix it. </p>\n\n<p>I wouldn't mind clearing the cube, so that it re-generates itself from scratch, but i can't seem to be able to do that. </p>\n\n<p>Once i get this error, even if i delete the cube, and create it again from scratch, the error is still there. </p>\n\n<p>The only solution so far (in my test environment) was to change database name in project deployment target properties. Obviously this will not do the trick in production. </p>\n"},{"tags":["sas","mdx","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":217,"score":1,"question_id":5181600,"title":"Marketing penetration in OLAP cube - Help with specific MDX measure definition","body":"<p>I am pretty new to MDX but I know what I want accomplish but its proving very hard.  Basically, I have a dataset where each row is a sale for a customer.  I also have postcode data and the UK population at each ward.  </p>\n\n<p>The total population in each ward is then divided by the count of the wardcode within the data set - e.g. ward A had a population of 1,000.  I have ten customers who live in ward A and so the population value is therefore 1,000/10.</p>\n\n<p>So as long as there are no other dimensions selected, only the region hierarchy, I can then drill up and down and the population penetration as count of customers / calculated population value is correct.  However, as soon as I introduce more dimension the total population will not sum to its true value.</p>\n\n<p>So I therefore need to do the calculation above within the cube and I am trying to find the MDX function(s) to do this.</p>\n\n<p>Esentially something like - </p>\n\n<p>step 1) sum the number of ward codes (the lowest level of the Geographic hierarchy) and group this by the distinct ward code, eg wardcodeA = 5, wardcodeB=10 etc.  </p>\n\n<p>Step 2) Then take the population in each ward (which could be stored as the total at ward level and taking the average) and then divide this by the result of the previous step</p>\n\n<p>step 3) sum the results from each ward at the currently select Geographical level</p>\n"},{"tags":["sql","data-warehouse","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":431,"score":0,"question_id":6199760,"title":"Calculate date and time key in fact table using existing date time field","body":"<p>I have date time field in a fact table in the format MM/DD/YY HH:MM:SS (e.g 2/24/2009 11:18:47 AM) and I have seperate date and time dimension \ntables. What I would like ask is that how I can create date key and time key in the fact table using the date time field so that I can join the\ndate and time dimension.</p>\n\n<p>There are alot of reference for creating seperate date and time dimension and their benefit but I could not find how to create date and time keys\nin the fact table using existing date time field.</p>\n\n<p>I have also heard that having date time field in fact table has certain benefit. If so, what would you recommend, should I have all three (date key, time key\nand date time field) in the fact table. Date key and time key are must to have for me and I am concerned about fact table size if I have date time field\nalso in the fact table.</p>\n\n<p>Thank you all for any help you can give.</p>\n"},{"tags":["mysql","analytics","olap","star-schema"],"answer_count":2,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":1021,"score":2,"question_id":4076915,"title":"star schema for implementing near real time analytics with changing data","body":"<p>I implementing analytics for a medical software. The data to be processed is mainly appointment related. I'm planing to implement star schema for generating reports. I have a few doubts</p>\n\n<ol>\n\n<li>My data can change like a appointment can be marked as cancelled later, i read that  changing data in star schema is not a good idea. If not what is a better approach.</li>\n<li>The data to my fact tables will inserted by a background task when the data is added to my main database. Is constant insertion of data to fact table a issue as reposts are viwed in the application almost anytime.</li>\n<li>I am planning to implement it in mysql, and if someone can point me to some post releated to performance of mysql with this kind of structure it would be great. Also which is a better engine to implement this schema Innodb or Myisam</li>\n</ol>\n\n<p>Thanks.</p>\n"},{"tags":["mysql","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":3,"down_vote_count":3,"view_count":838,"score":0,"question_id":6176229,"title":"Non-in-memory olap for MySql","body":"<p>I'm familiar with Mondrian. But I am looking for something like SSAS for MySql. Any suggestion?</p>\n"},{"tags":["mysql","database","indexing","olap","indices"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":590,"score":0,"question_id":6178125,"title":"Bitmap Indices on MySQL DB","body":"<p>I'm trying to design an OLAP DB in MySQL with the use of <strong>Bitmap Indices</strong>, however MySQL doesn't support Bitmap indices (as far as I know), so I have to build and maintain my own bitmap index.</p>\n\n<p>Could someone tell me if this will still bring any benefit to my application, like speeding up multidimensional range queries ? If so, which would be the best way to implement it ? </p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":285,"score":0,"question_id":5741204,"title":"OLAP dimension for boolean, time, selective count","body":"<p>I have just started tinkering with MS SQL Analysis Services. For a start, I'm creating one cube from sales detail table. For the dimensions I have created ProductDim from product master table, LocationDim from location tables, and a CalendarDim.</p>\n\n<p>However I'm stuck when trying to provide these data:</p>\n\n<ul>\n<li>boolean: how do I let user filter active/inactive transactions? Should I create a dimension containing 2 values, TRUE and FALSE?</li>\n<li>time: should I create a dimension containing 00:00:00 to 23:59:59 or should I merge time into my calendar dimension?</li>\n<li>transaction count: one transaction can have many line items, there's line item id, and there's transaction id, how do I set the dimension so user can see transaction count? Because the count of the measure is line item count.</li>\n</ul>\n"},{"tags":["ssas","mdx","olap","cube"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":842,"score":0,"question_id":5994780,"title":"SSAS Cube - Calculated Member from a Dimension","body":"<p>I have a very simple cube.</p>\n\n<p>This is the schema of the data source:</p>\n\n<pre><code>FactSales:\n  - DimRateCardID int (FK to DimRateCard)\n  - SalesDate int (FK to DimDateID)\n  - Sales int\n\nDimRateCard\n  - DimRateCardID int\n  - Product Name string\n  - Customer Name string\n  - Rate money\n\nDimDate:\n  - DimDateID int\n  - Year int\n  - Month int\n  - Day int\n  - IsHoliday bit\n</code></pre>\n\n<p>The cube structure is</p>\n\n<pre><code>Measure Groups:\n - FactSales.Sales \n - DimRateCard.Rate\n\nDimensions:\n    1) DimRateCard:\n      - Attribute - DimRateCardID, Product Name, Customer Name,\n      - Hierarchy - (Customer Name, Product Name)\n\n    2) DimDate:\n      - Attribute - DimDateID, Year, Month, Day, IsHoliday\n      - Hierarchy - (Year, Month, Day)\n</code></pre>\n\n<p>I am trying to create a calculated member to calculate the total cost as follows</p>\n\n<pre><code>WITH \nMEMBER Measures.[Total Cost]\n    AS [DimRateCard].[Rate].membervalue * [FactSales].[Sales]\nFORMAT_STRING = \"Currency\",\nSELECT {\nMeasures.Cost,\n[DimRateCard.Rate]\n} ON COLUMNS,\n[DimRateCard].[Customer].Members\nON ROWS\nFROM [DW Snow Flake]\n</code></pre>\n\n<p>The Cost column returns #error, but seems to work fine if I select [DimRateCard].[RateCardID] on COLUMNS. I come from a background of relationship database. This is something that I am trying to achieve in SQL.</p>\n\n<pre><code>SELECT drc.CustomerName, drc.ProductName, SUM(f.Sales * drc.Rate)\nFROM FactSales f\nINNER JOIN DimRateCard drc ON drc.DimRateCardID = f.DimRateCardID\nGROUP BY drc.CustomerName, drc.ProductName\n</code></pre>\n\n<p>Can someone shed some light on this issue?</p>\n\n<p>Just to clarify why I put the rate in a dimension rather in FactSales. The way the rate is determined is by the number of sales made over a date range (as determined by marketing). For example, say we charge $5 per unit for purchase of 5 units or less, $4 units for purchase between 6 to 15 units, $3 for purchase between 16 to 25 units. If you buy 3 units today, 5 tomorrow, and 10 the week after (18 in total), you get charged $3 per unit.</p>\n\n<p>Thanks</p>\n"},{"tags":["ssas","olap","business-intelligence"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":327,"score":0,"question_id":6006335,"title":"Operational database schema to data mart schema, table reduction?","body":"<p>I'm starting to study SQL Server Analysis Services and I'm working my way through the <a href=\"http://www.microsoft.com/learning/en/us/Book.aspx?ID=13112&amp;locale=en-us\" rel=\"nofollow\">training book</a>, as well as the <a href=\"http://www.microsoft.com/downloads/en/details.aspx?FamilyID=fffaad6a-0153-4d41-b289-a3ed1d637c0d\" rel=\"nofollow\">Developer Training Kit</a>. In both, I find suggestions that the number of tables used in an OLAP database (ideally, star schema) is greatly reduced from the production OLTP database.</p>\n\n<p>From the training kit:</p>\n\n<blockquote>\n  <p>We followed the data dimensional methodology to architect the data mart schema. From some 200 tables in the operational database, the data mart schema contained about 10 dimension tables and 2 fact tables.</p>\n</blockquote>\n\n<p>From what I understand, the operational databases are usually (somewhat) normalised and the data mart schemas are heavily denormalised. I also believe that denormalising data usually involves adding more tables, not less.</p>\n\n<p>I can't see how you can go from 200 tables to 12, unless you only need to report on a subset of data. And if you do only need to report on a subset of data, why can't you just use the appropriate tables in the operational database (unless there are significant performance gains to be made by using a denormalised star schema)?</p>\n"},{"tags":["java","oracle11g","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":377,"score":1,"question_id":5981602,"title":"java.sql.SqlRecoverableException while querying oracle cube","body":"<p>I get the following error when I try to query a cube (based on Oracle Olap 11gr2) from a Java program\njava.sql.SqlRecoverableException: no more data to read from the socket.</p>\n\n<p>This error occurs sometimes and sometimes it does not occur.</p>\n\n<p>We observed that if many people simultaneously try to query the cube the error crops up.</p>\n\n<p>Is this a bug or is there a solution or a method to deal with this sort of situation</p>\n"},{"tags":["delphi","components","olap","cube","crosstab"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":948,"score":2,"question_id":4572674,"title":"Crosstab/Cube/Pivot Components for Delphi","body":"<p>I'm looking for a Delphi VCL crosstab/cube/pivotcube/olap grid component for Delphi 2009, 2010, or XE.  I'm willing to sacrifice advanced features to get something open/free (or very cheap if I must) to make it easier to collaborate with any future developers without anyone having to purchase more components than I already use, since this will just be used in one screen.  If there isn't anything appropriate out there, I may try to implement something simple on my own.  I can live with some fairly basic features: drag and drop to configure dimensions, sort by a column, allow totals/min/max for a column, and (optionally) expand/collapse or drill down to sub-categories.  Blazing performance and enterprise scalability are not required, since there should be less than 2000 source rows.</p>\n\n<p>There appear to be several decent options in the commercial space (ExpressPivotCube, FastCube, HierCube), but they are all a few hundred dollars.  This project already uses existing installations of Excel 2007 and SQL Server 2005/2008, so I might consider leveraging those, though I'd prefer a native Delphi component, if possible.  There are also the very old Decision Cube components included in Delphi's Source\\xtab directory, but they apparently no longer support unicode compilers (Delphi 2009+), since I got dozens of unicode-related compilation errors while test compiling that source in Delphi XE.  Those components also still link to the long-deprecated BDE!  Has anyone modified Decision Cube to support unicode/pure-TDataSet?  The online tutorials I found were incomplete and silent on the dozens of BDE/unicode compilation errors I see, so I might have to tackle that on my own.</p>\n\n<p>Does anyone have suggestions where to start for a free/cheap basic crosstab/pivot grid component?</p>\n"},{"tags":[".net","sqlite","olap","olap-cube"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":304,"score":1,"question_id":4700498,"title":"Is there any OLAP Library for SQLite in .Net?","body":"<p>I would like to know is there any OLAP libray for SQLite? which will allow me to create CUBES dynamically.</p>\n\n<p>Thanks,\nOmky</p>\n"},{"tags":["ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":99,"score":1,"question_id":5869162,"title":"Automatic MOLAP Error Notification","body":"<p>We are just setting up a number of SSAS Cubes using pro-active caching and one thing that concerns me is how we will know if cube processing fails. </p>\n\n<p>Is there a way to get SQL Server to notify via email if something has fallen over?</p>\n"},{"tags":["web-applications","oracle10g","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":152,"score":0,"question_id":5806857,"title":"how to access oracle 10g OLAP programmatically in a web application","body":"<p>Oracle provided BI Beans libraries which allows a web application to access Oracle OLAP. It seems that there are no new version of BI beans and that it is no more supported by Oracle. </p>\n\n<p>Given above, how can we access Oracle 10g/11g OLAP in java/jsp programs?</p>\n"},{"tags":["java","jdbc","olap","infobright"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":405,"score":1,"question_id":3970149,"title":"Accessing infobright from Java","body":"<p>Would someone advise me technology for accessing Infobright from java, or some technics... things of that nature.. as far as I understand I should use plain jdbc connection and execute queries... not making use of high level thing like hibernate... Am I right? </p>\n\n<p>Thanks in advance!</p>\n"},{"tags":["excel","olap","data-warehouse","pivot-table"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":303,"score":1,"question_id":5785689,"title":"View OLAP cube details in Excel","body":"<p>Is there a way to view the details (the grain) in an OLAP cube in excel? I know excel can already show the measures that are aggregrated, but the users want to see the details... ie the individual grain. So, in my case, the fact table contains order information (order number, the dollar amount, etc). The measures are all aggregrated, but once the user sees an aggregration, they want to be able to see the details of that aggregration. Anyway to do this?</p>\n"},{"tags":["sql","mdx","olap","pivot-table","xmla"],"answer_count":2,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":177,"score":1,"question_id":5723164,"title":"Schema-agnostic OLAP-like tool?","body":"<p>Do there exist any (ideally free or open-source) tools for performing OLAP analyses on <em>arbitrary</em> tables in a relational database, without requiring any advance specification of dimensional hierarchies, cardinalities, or any other meta-information about the table beyond what can be extracted automatically from the table itself?</p>\n\n<p>My inability to Google for anything like what I'm describing makes me suspect I'm using incorrect terminology and what I'm searching for isn't properly considered to be OLAP. If this is the case, what I specifically want is anything that would let technically unsophisticated users create cross-tab or contingency table aggregations using tables in a relational DB without needing to write elaborate SQL queries.</p>\n\n<p>Or, in other words, I'd like something that mimics Excel's PivotTables on a larger scale. I appreciate that Excel does indeed generate extensive caches behind the scenes when you make a PivotTable, but it does this without the user having to explain to it which caches need creating. This is the functionality I'm trying to find elsewhere, if it exists.</p>\n"},{"tags":["reporting","solr","olap","business-intelligence","oltp"],"answer_count":3,"favorite_count":3,"up_vote_count":2,"down_vote_count":0,"view_count":626,"score":2,"question_id":4317180,"title":"Choosing a strategy for BI module","body":"<p>The company I work for produces a content management system (CMS) with different various add-ons for publishing, e-commerce, online printing, etc. We are now in process of adding \"reporting module\" and I need to investigate which strategy should be followed. The \"reporting module\" is otherwise known as <em>Business Intelligence</em>, or BI.</p>\n\n<p>The module is supposed to be able to track item downloads, executed searches and produce various reports out of it. Actually, it is not that important what kind of data is being churned as in the long term we might want to be able to push whatever we think is needed and get a report out of it.</p>\n\n<p>Roughly speaking, we have two options. </p>\n\n<p><strong>Option 1</strong> is to write a solution based on Apache Solr (specifically, using <a href=\"https://issues.apache.org/jira/browse/SOLR-236\" rel=\"nofollow\">https://issues.apache.org/jira/browse/SOLR-236</a>). Pros of this approach:</p>\n\n<ul>\n<li>free / open source / good quality</li>\n<li>we use Solr/Lucene elsewhere so we know the domain quite well</li>\n<li>total flexibility over what is being indexed as we could take incoming data (in XML format), push it through XSLT and feed it to Solr</li>\n<li>total flexibility of how to show search results. Similar to step above, we could have custom XSLT search template and show results back in any format we think is necessary</li>\n<li>our frontend developers are proficient in XSLT so fitting this mechanism for a different customer should be relatively easy</li>\n<li>Solr offers realtime / full text / faceted search which are absolutely necessary for us. A quick prototype (based on Solr, 1M records) was able to deliver search results in 55ms. Our estimated maximum of records is about 1bn of rows (this isn't a lot for typical BI app) and if worse comes to worse, we can always look at SolrCloud, etc.</li>\n<li>there are companies doing very similar things using Solr (Honeycomb Lexicon, for example)</li>\n</ul>\n\n<p>Cons of this approach:</p>\n\n<ul>\n<li>SOLR-236 might or might not be stable, moreover, it's not yet clear when/if it will be released as a part of official release</li>\n<li>there would possibly be some stuff we'd have to write to get some BI-specific features working. This sounds a bit like reinventing the wheel</li>\n<li>the biggest problem is that we don't know what we might need in the future (such as integration with some piece of BI software, export to Excel, etc.)</li>\n</ul>\n\n<p><strong>Option 2</strong> is to do an integration with some free or commercial piece of BI software. So far I have looked at <em>Wabit</em> and will have a look at <em>QlikView</em>, possibly others.  Pros of this approach:</p>\n\n<ul>\n<li>no need to reinvent the wheel, software is (hopefully) tried and tested</li>\n<li>would save us time we could spend solving problems we specialize in</li>\n</ul>\n\n<p>Cons: </p>\n\n<ul>\n<li>as we are a Java shop and our solution is cross-platform, we'd have to eliminate a lot of options which are in the market</li>\n<li>I am not sure how flexible BI software can be. It would take time to go through some BI offerings to see if they can do flexible indexing, real time / full text search, fully customizable results, etc.</li>\n<li>I was told that open source BI offers are not mature enough whereas commercial BIs (SAP, others) cost fortunes, their licenses start from tens of thousands of pounds/dollars. While I am not against commercial choice per se, it will add up to the overall price which can easily become just too big</li>\n<li>not sure how well BI is made to work with schema-less data</li>\n</ul>\n\n<p>I am definitely not be the best candidate to find the most approprate integration option in the market (mainly because of absence of knowledge in BI area), however a decision needs to be done fast.</p>\n\n<p>Has anybody been in a similar situation and could advise on which route to take, or even better - advise on possible pros/cons of the option #2? The biggest problem here is that I don't know what I don't know ;)</p>\n"},{"tags":["sql","ssis","olap","data-warehouse"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":204,"score":0,"question_id":5658706,"title":"should dimension table key lookups be processed before data goes into a staging table?","body":"<p>I have read that a staging table should be an exact column by column match of its target table in the dw. If that is the case, after populating the staging table is it best practice to not do subsequent lookups to match up keys to those in dimension tables?</p>\n\n<p>My question I guess is this, should dimension table key lookups be processed before data goes into a staging table? </p>\n"},{"tags":["c#","wcf","json","serialization","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":831,"score":0,"question_id":5642360,"title":"Return a jagged array with dynamic number of dimensions from C# WCF Service","body":"<p>I'm currently trying create a service that will return results of a OLAP cube query in a C#/ WCF data service.  I am doing this to gain complete programmatic control over how the OLAP results are serialized, how clients are authenticated/authorized and to be able to query cubes from javascript in a website directly.</p>\n\n<p>The results from the OLAP queries may have any number of dimensions (realistically somewhere between 1 and 5 max).  The problem I'm having is that I cannot figure out how to first create a jagged array of a dynamic number of dimensions without hard codding the handling of every number of dimensions I'll possibly use.  So the first quest is: is there an elegant way to create a jagged array of a dynamic number of dimensions in C#? </p>\n\n<p>Once I have this array of dynamic number of dimensions, is it possible to then serialize this into json using DataContractJsonSerializer (or any other json serializer freely available).  The goal is to serialize this into an object that looks something like this for 2-dimensional results:</p>\n\n<pre><code>{\n  \"DimensionMemberCaptions\" = [[\"Dim1 member1\", \"Dim2 member2\"], [\"Dim2 member1\"], [\"Dim2 member2\"]],\n  \"Data\" = [[1, 2],\n            [3, 4]],\n  \"FormatedData = [[\"1$\", \"2$\"],\n                   [\"3$\", \"4$\"]]\n}\n</code></pre>\n\n<p>Where DimensionMemberCaptions contain the headers for each dimension (OLAP member names) and data/formateddata is a table of the results.</p>\n\n<p>I would like to avoid writing my own serialization functions but its seeming more appealing as time goes on -- using an Array (multi-dimensional array instead of jagged) and writing my own json serializer specifically for the purpose of serializing OLAP output to a Stream returned by a WCF REST method.</p>\n"},{"tags":["olap"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":29,"score":1,"question_id":1537965,"title":"How to create a growth column or a share column in an SQL Server 2008 Cube Development?","body":"<p>I have a huge amount of sales data starting from 2000 till 2009. I want to calculate growth on 2009 sales versus 2008 sales.</p>\n\n<p>I also want to calculate share of each product in any particular year or month.</p>\n\n<p>Best Regards </p>\n\n<p>Wajih</p>\n"},{"tags":["ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1382,"score":0,"question_id":5494234,"title":"MDX Calculated member Sum of selected members rollup","body":"<p>I'm trying to write a calculated member that will roll up along a dimension based on the selected values provided on the axes.</p>\n\n<p>Product -> subcategory -> category\nlexus -> sedan -> car\nlexus-coupe -> coupe -> car\nbmw -> sedan -> car\nbmw-coupe -> couple -> car\nford -> pickup -> truck\nchev -> pickup -> truck\nford-suv -> suv -> truck\nlincoln-nav -> suv -> truck</p>\n\n<p>[Calculated measure] = [measures].[a]+[measures].[b]</p>\n\n<p>suppose the user wants to see [Calculated measure] at the car level for just lexus-coupe and bmw.  How do you create a calculated measure that will roll up at the car level based on what has been selected in the dimension?</p>\n\n<p>Thank you in advance!</p>\n"},{"tags":["sql-server","ssis","training","olap","etl"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":348,"score":0,"question_id":5524635,"title":"Recommendations for an online beginners guide to OLAP databases in Microsoft SQL 2008","body":"<p>As our products gather more and more data, and more and more demands are made of reporting against that data we really need to stop trying to report against the primary OLTP databases and get that primary data into a corresponding OLAP database and report against that.  However thatâ€™s about where my OLAP knowledge stops.</p>\n\n<p>So my question boils down to this:  Can any of you StackOverflow people recommend a good set of (preferably online) learning resources to educate proficient SQL using software developers in the ways of OLAP?  Specifically the mechanics of how one should go about the ETL (with SSIS I presume) of source data in your OLTP databases into their corresponding OLAP one(s)?</p>\n\n<p>As you can see I know just enough about this to know that I know nearly nothing about it.  Whilst this conscious incompetence is a recent improvement from my earlier unconscious incompetence I would like to elevate this to at least conscious competence!</p>\n\n<p><em>update</em></p>\n\n<p>The answer to <a href=\"http://stackoverflow.com/questions/798445/a-developers-guide-to-sql-server-analysis-services-and-olap\">A Developers guide to SQL Server Analysis Services and OLAP</a> by <a href=\"http://stackoverflow.com/users/95589/eric\">Eric</a> lists a couple of decent sounding books (duly added to my Amazon wish list), but being a cheapskate (and impatient) I really would like online resources I can access now and for free rather than books.</p>\n"},{"tags":["ssas","mdx","olap","olap-cube"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":707,"score":1,"question_id":5518583,"title":"MDX equivalent to SQL's GROUP BY for excluding duplicate rows","body":"<p>My cube has a fact table that contains a row for every modification made to any entity. What I need is a measure that will return a count of the entities based on the selected dimensions.\nSo if the user selects a month from the date dimension then the measure should return the number of entities that were modified that month (rather than the number of modifications).</p>\n\n<p>In SQL this would be something like:</p>\n\n<pre><code>SELECT EntityID, COUNT(*) FROM FactTable WHERE Date BETWEEN X AND Y GROUP BY EntityID\n</code></pre>\n\n<p>How can you do this in MDX? Surely this would be an extremely common scenario with cubes.</p>\n"},{"tags":["olap","mdx","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":445,"score":0,"question_id":5347586,"title":"Defining a SUM calculated member on a dimension property in a cube","body":"<p>I am an OLAP/MDX newbie so pardon me if this is too obvious of a question.</p>\n\n<p>I am trying to define a MDX calculated member which will SUM the values from a dimension property but unable to do so. I am not even sure if this is possible or not.</p>\n\n<p>This is an example scenario.</p>\n\n<p>In the DataWarehouse</p>\n\n<p>Imagine a DiskDim dimension which stores instances of disks and which has a column Size which stores the Size in MBâ€™s of the each Disk. </p>\n\n<p>There is a ComputerDim dimension which stores instances of computers.</p>\n\n<p>There is a fact table ComputerHasDisk which stores the relationship between an instance of a computer and disk. Note the fact table only has the relationship and no columns which can be used as measures.</p>\n\n<p>In AS</p>\n\n<p>We have a DiskDim dimension, a Computer dimension and a count of rows measure for ComputerHasDisk, a count of rows measure for DiskDim and a count of rows measure for ComputerDim.</p>\n\n<p>I want to define a calculated member as part of  Measures for Total Disk Size such that using the calculated member I should be able to slice on Computer and get the sum of all the disk sizes for each Computer.</p>\n\n<p>This is the query I am expecting to write:</p>\n\n<p>SELECT [Measures].[TotalDiskSize] ON COLUMNS,\n[ComputerDim].[ComputerDim].Members ON ROWS\nFROM [Cube]</p>\n\n<p>How do we define the calculated member [Measures].[TotalDiskSize] to be able to write the query above. Is it even possible ?</p>\n\n<p>Thanks,\nAnirudh</p>\n"},{"tags":["ssas","olap","business-intelligence","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":175,"score":0,"question_id":5251433,"title":"SSAS - Creating a measure the only counts the newest events","body":"<p>I'm new to SSAS and I'm not sure how to heavily customize a measure.\nMy fact table stores every change (events like created new page or deleted page).\nThe default measure will return a count of all changes but I also need a measure that\nwill display the number of pages (to which the events refer) in the system. It should only count one event for every distinct page but using the latest status of the system as of the date being used as a filter.\nFor example: Somebody creates 5 pages on Monday and then deletes 2 pages on Tuesday and adds 1 page on Friday.\nThat's 8 events but only 6 unique pages so the measure should display 5 pages if filtered for Tuesday and 6 pages if filtered for Friday. It should only count the events that are the last one for that page (As opposed to using the first event for that page as this could affect other dimensions).\nHow would I go about doing this?</p>\n"},{"tags":["mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":313,"score":0,"question_id":5439007,"title":"Displaying multiple hierchy levels in an MDX query","body":"<p>I'm trying to get the following data from a TFS OLAP cube in a single query</p>\n\n<pre><code>[Work Item].[System_ID] | [Work Item].[System_Title] | [Measures].[BaselineWork]\n13426                   | Do some work               | 5\n</code></pre>\n\n<p>Sounds pretty simple huh? That's what I thought too, but having 0 knowledge of OLAP, TFS and MDX has made this pretty daunting.</p>\n\n<p><img src=\"http://i.stack.imgur.com/DPphG.jpg\" alt=\"SSMS Hierchy\"></p>\n\n<p>So, I can get this...</p>\n\n<pre><code>SELECT\n[Measures].[Microsoft_VSTS_Scheduling_BaselineWork] ON COLUMNS,\n[Work Item].[System_Id].MEMBERS ON ROWS\nFROM [Team System]\nWHERE [Work Item].[System_WorkItemType].&amp;[WPS Task]\n</code></pre>\n\n<p>and this...</p>\n\n<pre><code>SELECT\n[Measures].[Microsoft_VSTS_Scheduling_BaselineWork] ON COLUMNS,\n[Work Item].[System_Title].MEMBERS ON ROWS\nFROM [Team System]\nWHERE [Work Item].[System_WorkItemType].&amp;[WPS Task]\n</code></pre>\n\n<p>but combining the two has got me stumped. Any suggestions?</p>\n"},{"tags":["sql-server","database","ssas","olap","cube"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":357,"score":0,"question_id":5287172,"title":"Calculated Measure aggregating on certain cells only","body":"<p>I'm trying to figure out how I can create a calculated measure that produces a count of only unique facts in my fact table. My fact table basically stores events from a historical perspective. But I need the measure to filter out redundant events.\n<br/>Using sales as an example(Since all material around OLAP always uses sales in examples):\n<br/><br/>\nThe fact table stores sales EVENTS. When a sale is first made it has a unique sales reference which is a column in the fact table. A unique sale however can be amended(Items added or returned) or completely canceled. The fact table stores these changes to a sale as different rows.<br/><br/>\nIf I create a count measure using SSAS I get a count of all sales events which means an unique sale will be counted multiple times for every change made to it (Which in some reports is desirable). However I also want a measure that produces a count of unique sales rather than events but not just based on counting unique sales references. If the user filters by date then they should see unique sales that still exist on that date (If a sale was canceled by that date if should not be represented in the count at all).<br/><br/></p>\n\n<p>How would I do this in MDX/SSAS? It seems like I need have a count query work from a subset from a query that finds the latest change to a sale based on the time dimension.\nIn SQL it would be something like:<br/><br/>\n<code>SELECT COUNT(*) FROM SalesFacts FACT1 WHERE Event &lt;&gt; 'Cancelled' AND</code><br/>\n<code>Timestamp = (SELECT MAX(Timestamp) FROM SalesFact FACT2 WHERE FACT1.SalesRef=FACT2.SalesRef)</code><br/><br/>\nIs it possible or event performant to have subqueries in MDX?</p>\n"},{"tags":["database","database-design","data-modeling","olap","data-warehouse"],"answer_count":10,"favorite_count":8,"up_vote_count":13,"down_vote_count":2,"view_count":2461,"score":11,"question_id":4394183,"title":"Should not OLAP database be denormalized for reading performance?","body":"<p>I always thought that databases should be denormalized for reading, as it is done for OLAP database design, and not exaggerated much further 3NF for OLTP design.  </p>\n\n<p>PerformanceDBA in various posts, for ex.,  in <a href=\"http://stackoverflow.com/questions/4375192/performance-of-different-aproaches-to-time-based-data/4390401#4390401\">Performance of different aproaches to time-based data</a> defends the paradigm that database should be always well-designed by normalization to 5NF and 6NF (Normal Form).<br>\nHave I understood it correctly (and what had I understood correctly?)?<br>\nWhat's wrong with traditional denormalization approach/paradigm design of OLAP databases (below 3NF) and advices that 3NF is enough for most practical cases of OLTP databases?  </p>\n\n<p>Please either downvote or upvote, do not mix both.   </p>\n\n<p><strong>Update:</strong><br>\nI have multiple posts showing 0 votes having 3-7 upvotes + 3-7 downvotes. I prefer having 6-14 downvotes than 0 total score.  For ex., this question in a few minutes after posting had 0 with 4 votes (-2+2). I prefer having -4 instead.<br>\nI do not care about personal rep but about underepresentation of interest to topics.  </p>\n\n<p>Update3:  for example:   </p>\n\n<ul>\n<li><a href=\"http://stackoverflow.com/questions/4264947/what-is-best-practice-for-representing-time-intervals-in-a-data-warehouse/4290190#4290190\">\"The simple truth (not complex enough for people who justify datawarehouses with (1) (2) (3) ), is that 6NF, executed properly, is the data warehouse (PerformanceDBA)\"</a>    </li>\n</ul>\n\n<p>Update4:<br>\nOK, I should confess that I could never grasp the theories that denormalization facilitates data reading performance. Can anybody give me references with good logical explanations of this and of the contrary beliefs?<br>\nWhat are sources to which I can refer to support (to convince my stakeholders) that OLAP/DataWareHousing databases should be normalized?   </p>\n\n<p>Update5:<br>\nTo improve visibility I copied here from comments:  </p>\n\n<blockquote>\n  <p>\"It would be nice if participants would\n  add (disclose) how many real-life (no\n  science projects included)\n  data-warehouse implementations in 6NF\n  they have seen or participated in.\n  Kind of a quick-pool. Me = 0. â€“ Damir\n  Sudarevic\"  </p>\n</blockquote>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Data_Warehouse\">http://en.wikipedia.org/wiki/Data_Warehouse</a> tells:  </p>\n\n<blockquote>\n  <p>\"The normalized approach [vs. dimensional one by Ralph Kimball], also called\n  the <strong>3NF model</strong>, whose supporters\n  are referred to as â€œInmonitesâ€,\n  believe in Bill Inmon's approach in\n  which it is stated that the data\n  warehouse should be modeled using an\n  E-R model/normalized model\"</p>\n</blockquote>\n\n<p>It looks like normalized datawarehousing approach (by Bill Inmon) is perceived as not exceeding 3NF (?)<br>\nI just want to understand what is the origin of the myth (or ubiquitous axiomatic belief)  that datawarehousing/OLAP is synonym of denormalization?  </p>\n\n<p>Update6:<br>\nDamir Sudarevic answered that they are well-paved approach. Let me return to question why is denormalization believed to facilitate reading?   </p>\n"},{"tags":["sql-server","olap","cube","dimension"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":2062,"score":2,"question_id":5305351,"title":"SQL Analysis Services OLAP TIME dimension","body":"<p>Hi\ni'm struggling with adding time dimension to OLAP cube.\nI can get everything in cube to work except date.</p>\n\n<p>In my source data view I have datetime column.</p>\n\n<p>I go by using Dimensions->New Dimension-><strong>Generate time dimension on the server</strong>.\nI end up with a nice hierachical time dimension (Date-Month-Quarter-Year).</p>\n\n<p>Later I add this dimension to cube and define regular relationship with datetime column from source data view (same table which has fact data).</p>\n\n<p>When I try to deploy the cube, I get error:</p>\n\n<p>Errors in the OLAP storage engine: The attribute key cannot be found when processing:Table: 'table_name', Column: 'registration_date', Value: '3/29/2007 3:00:00 PM'. The attribute is 'Date'</p>\n\n<p>Maybe I don't get something? Every manual I can find talks about calendar table already created in the source database. There are plenty of script which will create calendar table for you. But why should I ? Isn't <strong>Generate time dimension on the server</strong> meant for it?</p>\n"},{"tags":["ssas","olap","cubes"],"answer_count":5,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":3882,"score":1,"question_id":320405,"title":"Analysis Services 2005 OLAP Cubes : Can I create a distinct count measure on a nvarchar column?","body":"<p>I'm trying to create a cube with a single measure. This measure is a distinct count of a \"name\" column. The cube works perfectly if the measure is set to \"count\" type. However when I set distinct count I get this error:</p>\n\n<p>\"Errors in the OLAP storage engine: The sort order specified for distinct count records is incorrect\"</p>\n\n<p>I have read in some blogs that you can only have  a distinct count on a numeric column. I can't see a good reason for this, and I can't find that info on official documentation. However, it may be true. Anyways, I'm really stuck with this issue. What are my options? </p>\n"},{"tags":["ssas","olap","mdx","cube","dimensions"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":866,"score":1,"question_id":3975919,"title":"Adding an extra row to an MDX result set","body":"<p>I have a very simple MDX query that retuns the contents of a dimension.</p>\n\n<p>I would like to inject one more row to the result set as part of the MDX.</p>\n\n<p>Is this possible?</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":140,"score":0,"question_id":5265152,"title":"In SSAS, can you ignore table relationships at the cube level?","body":"<p>We have a situation where, because OLAP is using a single DataSource view for all cubes, some of our aggregations are getting confused.</p>\n\n<p>The problem is the following:\n  - Multiple fact tables join to another table to make a dimension\n  - Another fact table joins to those fact tables to make dimensions\n  - OLAP doesn't know which join to follow and picks the wrong one</p>\n\n<p>Here is how our cubes are defined</p>\n\n<pre><code>Cube A:\n[FactTable A]-&gt;[Dim A]\n\nCube B:\n[FactTable B]-&gt;[Dim A]\n\nCube C:\n[FactTable C]\n    |---------&gt;[FactTable A]-&gt;[Dim A]\n    |---------&gt;[FactTable B]        \n</code></pre>\n\n<p>Because of this the datasource view looks like this:</p>\n\n<pre><code>[FactTable C]\n    |---------&gt;[FactTable A]-&gt;[Dim A]\n    |---------&gt;[FactTable B]-&gt;[Dim A]\n</code></pre>\n\n<p>OLAP doesn't know how to aggregate Dim A. Is there a way to ignore that join for Cube C? Can you define the relations at the cube level alone?</p>\n"},{"tags":["time","relational-database","olap","data-warehouse","denormalization"],"answer_count":4,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":221,"score":0,"question_id":5192896,"title":"Datawarehouse performance difference denormalize time","body":"<p>In books I read that it is a real performance booster if you split the time into separate column. e.g day,month,year and so on...</p>\n\n<ol>\n<li><p>Do databases already have some smart approch for handling indicies over time columns, so that splitting the time and adding millions of index variantes is obsolete?</p></li>\n<li><p>Any experiance in performance difference?</p></li>\n</ol>\n\n<p>A possible query would be sales on monday morning between 13:00-14:00 o'clock.</p>\n"},{"tags":["sql-server","visual-studio-2005","ssas","trace","olap"],"answer_count":3,"favorite_count":1,"up_vote_count":5,"down_vote_count":0,"view_count":1688,"score":5,"question_id":12578,"title":"No trace info during processing of a cube in SSAS","body":"<p>When I process a cube in Visual Studio 2005 I get following message:</p>\n\n<blockquote>\n  <p>Process succeeded. Trace information\n  is still being transferred. If you do\n  not want to wait for all of the\n  information to arrive press Stop.</p>\n</blockquote>\n\n<p>and no trace info is displayed. Cube is processed OK by it is a little bit annoying. Any ideas? I access cubes via web server.</p>\n"},{"tags":["datasource","olap","cognos"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":137,"score":0,"question_id":3767556,"title":"Problem with query as a new data source in Cognos PowerPlay","body":"<p>Normally you can add a query as a new data source in Cognos PowerPlay (I'm running PowerPlay version 7.3), but when I try to do so I cannot select any queries from my Access database. The dropdown menu which normally shows the existing queries in the database is empty. When I add a table as a new data source it works fine, and all the tables are shown in the dropdown.</p>\n\n<p>Previously it worked fine for queries too, but now it won't work.\nDoes anybody know if it's a Cognos error or some system configuration on my pc that causes this error to appear?</p>\n"},{"tags":["mdx","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":265,"score":0,"question_id":5090812,"title":"Differing NON EMPTY behaviour in Analysis Server 2000 and 2008","body":"<p>We currently run a front-end Manager Information tool that connects to a SQL analysis server to provide flexible reporting. Essentially the front-end builds up some MDX which it then executes on Analysis Services, and prettifies the result as a table.</p>\n\n<p>We are currently upgrading from SQL 2000 to SQL 2008 and have come across a difference in the use of NON EMPTY in MDX.</p>\n\n<p>This is the MDX query in question</p>\n\n<pre><code>SELECT NON EMPTY {[Measures].allMembers} ON ROWS, NON EMPTY {} ON COLUMNS FROM Sales\n</code></pre>\n\n<p>When run on Analysis Server 2000 it returns the list of Measure member names for the rows, but when run in Analysis Server 2008 nothing is returned.</p>\n\n<p>Looking at the MDX I think 2008 is working as expected, and 2000 is wrong, but it has sort of broken our front-end as it is showing nothing in the case where this MDX is run (the user is then expected to drag on some columns after this you see, but with nothing showing, they can't do this).</p>\n\n<p>So, is there a reason for a difference. Was this a 'bug' in 2000 that was fixed in 2008? Or is there some configuration option somewhere that can affect what is returned? (Essentially I want to avoid to having make a change to our front-end to cope with this!)</p>\n\n<p>Thanks.</p>\n"},{"tags":["mdx","olap","mondrian"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":411,"score":0,"question_id":3398206,"title":"How can I use an MDX Level property in the slicer?","body":"<p>Suppose I have a [Sales] cube which has a [Store] level and a store has a \"type\" property.\nWhich query should I use for showing the sum of sales for all the stores of type \"Supermarket\"?\n(e.g. You sold 6M $ in all stores of type \"Supermarket\")</p>\n"},{"tags":["sql-server-2008","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":513,"score":0,"question_id":4924722,"title":"Error deploying OLAP cube from Visual Studio","body":"<p>I've imported a OLAP cube which was created by one of my colleagues directly on SQL Server Management Studio.\nSo I import it in a Visual Studio project and then just make one little modification. I want to depoy it to a server. But I have a lot of errors.</p>\n\n<p>The errors appear when I try to deploy my project, but not when I compile the project .</p>\n\n<p>Did someone already have this problem? Can someone help me for this problem?</p>\n\n<p><em><strong></em>*</strong>*Details of error log in visual studio development : </p>\n\n<pre> \nError   76  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MARCHE NUM' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   77  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   78  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'CODE NUM' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   79  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   80  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   81  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   82  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DEVISE STR' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   83  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   84  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   85  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   86  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   87  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   88  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   89  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   90  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   91  Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   92  Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     \nError   135 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'LIBELLE' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   136 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   137 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   138 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   139 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   140 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   141 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   142 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'SSECTION' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   143 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   144 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   145 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Commo' et le nom 'Commo'.     0   0   \nError   146 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'COMMO NAME' de la dimensionÂ 'Commo' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   147 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   148 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   149 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'LIBSECTION' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   150 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   151 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   152 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   153 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   154 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   155 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'RefFamily' et le nom 'RefFamily'.     0   0   \nError   156 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATEJ' de la dimensionÂ 'RefFamily' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   157 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   158 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   159 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   160 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   161 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MATURITY DAY' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   162 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   163 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   164 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   165 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   166 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   167 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   168 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'REFERENCE' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   169 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   170 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   171 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   172 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   173 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   174 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DELIVERY TYPE' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   175 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   176 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   177 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   178 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   179 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   180 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   181 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   182 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   183 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   184 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   185 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DEVISE NUM' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   186 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   187 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   188 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Commo' et le nom 'Commo'.     0   0   \nError   189 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATEJ' de la dimensionÂ 'Commo' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   190 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   191 Erreur interneÂ : L'opÃ©ration n'a pas abouti.        0   0   \nError   192 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   193 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'INVERSERRIC' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   194 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   195 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MASTERCURRENCY' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   196 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   197 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MARKET' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   198 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   199 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'REF COMMODITY' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   200 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   201 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   202 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Commo' et le nom 'Commo'.     0   0   \nError   203 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'SICOVAM' de la dimensionÂ 'Commo' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   204 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   205 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'CODE STR' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   206 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   207 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATE NEG' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   208 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   209 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   210 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   211 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'REFCON' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   212 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   213 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'SICOVAM' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   214 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   215 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   216 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Family' et le nom 'Family'.       0   0   \nError   217 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'FAMILY' de la dimensionÂ 'Family' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   218 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   219 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MODEL NAME' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   220 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   221 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'FOLIO' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   222 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   223 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'UNIT TRADDING' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   224 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   225 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'CONTREPARTIE' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   226 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   227 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'AFFECTATION STR' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   228 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Positions' et le nom 'Positions'.     0   0   \nError   229 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATEJ' de la dimensionÂ 'Positions' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   230 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   231 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MATURITY DATE' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   232 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   233 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'STATUT' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   234 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   235 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATEJ' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.       0   0   \nError   236 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Devises' et le nom 'Devises'.     0   0   \nError   237 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MEASURE UNIT' de la dimensionÂ 'Devises' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   238 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   239 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'ENTITE' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   240 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Instruments' et le nom 'Instruments'.     0   0   \nError   241 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MARCHE STR' de la dimensionÂ 'Instruments' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   242 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   243 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'TYPE' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   244 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Folio' et le nom 'Folio'.     0   0   \nError   245 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'SICOVAM' de la dimensionÂ 'Folio' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   246 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   247 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   248 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   249 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'AFFECTATION' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   250 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   251 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   252 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   253 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'MVTIDENT FW' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.     0   0   \nError   254 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   255 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   256 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'RefFamily' et le nom 'RefFamily'.     0   0   \nError   257 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'REF FAMILY' de la dimensionÂ 'RefFamily' de la base de donnÃ©esÂ 'CubeCom'.      0   0   \nError   258 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   259 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'DATE VAL' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.        0   0   \nError   260 Erreurs dans le moteur relationnel de haut niveau. L'exception suivante s'est produite lors de l'utilisation de l'interface IDbConnection managÃ©eÂ :Â ORA-12154: TNS : l'identificateur de connexion indiquÃ© n'a pas pu Ãªtre rÃ©solu .     0   0   \nError   261 Erreurs dans le moteur relationnel de haut niveau. Une connexion n'a pas pu Ãªtre Ã©tablie Ã  la source de donnÃ©es avec le DataSourceID, 'resultatMX', nom de 'resultat-msrsot'.       0   0   \nError   262 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement deÂ dimension portant l'ID 'Deals' et le nom 'Deals'.     0   0   \nError   263 Erreurs dans le moteur de stockage OLAPÂ : Une erreur s'est produite lors du traitement de l'attributÂ 'SICOVAM FW' de la dimensionÂ 'Deals' de la base de donnÃ©esÂ 'CubeCom'.      0   0****   \n</pre>\n"},{"tags":["sql-server","iis","olap","analysis-services","asp.net-development-serv"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":999,"score":1,"question_id":5007315,"title":"Analysis Services database works with ASP.NET Development Server but NOT IIS","body":"<p>I have an ASP.NET application which needs to connect to Analysis Services database.\nAll components are on the same machine: </p>\n\n<ul>\n<li>Web application </li>\n<li>IIS</li>\n<li>Visual Studio 2008</li>\n<li>SQL Server 2008</li>\n</ul>\n\n<p>My domain account (DOMAINNAME\\MyWindowsUsername) is an administrator on the SQL Server and also in \"Administrators\" group on the local machine.</p>\n\n<p>Web application uses Windows Authentication and identity impersonate=\"true\".</p>\n\n<p>My IIS Windows Authentication settings (I have also tried other combinations but no success...):</p>\n\n<ul>\n<li>Extended Protection: Off</li>\n<li>Enable Kernel-mode authentication: true</li>\n<li>Enables Providers: NTLM</li>\n</ul>\n\n<p><br>\n<br></p>\n\n<p>When I use web application on ASP.NET Development Server (deployed from Visual Studio) then everything works ok. My domain account and corresponding database roles are recognized correctly, and security is working as defined in database roles. </p>\n\n<p>But, when I deploy the same web application (without any changes in code) to IIS I get error (in browser):</p>\n\n<p><strong>An error was encountered in the transport layer.\nThe peer prematurely closed the connection.</strong></p>\n\n<p><br>\n<br></p>\n\n<p>In SQL Profiler (for IIS case when connection fails) I get only these two events:</p>\n\n<p><strong>Audit Login</strong>     MyWindowsUsername DOMAINNAME    </p>\n\n<p><strong>Audit Logout</strong>    MyWindowsUsername DOMAINNAME</p>\n\n<p>It seems Analysis Services recognizes the impersonated account, but still the connection breaks.</p>\n\n<p>I have noticed that ASP.NET Development Server runs under DOMAINNAME\\MyWindowsUsername while IIS under LocalSystem (the default setting). I tried to play with the accounts, adding various system/network account as Analyis Services administrators (just to understand the logic behind this), but also with no success (always the same error).</p>\n"},{"tags":["ssas","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":324,"score":1,"question_id":5023218,"title":"Measure names containing \"Total\" have strange grand total calculation in cubes","body":"<p>In programmatically building cubes for SQL Server Analysis Services using AMO, I've discovered that when a measure has \"Total\" in it's title, the grand total in the cube is calculated by a distinct sum instead of just a sum (creating very strange results)</p>\n\n<p>This doesn't occur when building cubes using DSO. Does anyone know of why this could be happening?</p>\n\n<p>Please pardon my use of python:</p>\n\n<pre><code>class MeasureSpec(MeasureSpec):\n    def create(self, measureGroup, cube, dsv, factTable):\n        log(\"creating measure:\", self.name)\n        measure = measureGroup.Measures.Add(self.name)\n        measure.AggregateFunction = self.aggregateFunction\n        measure.FormatString = self.format\n        # Set datatype to integer for counts otherwise this is set to the same\n        # type as the source column in createDataItem\n        if self.aggregateFunction in (aggCount, aggDistinctCount):\n            measure.DataType = MeasureDataType.Integer\n        measure.Visible = self.isVisible\n        measure.Source = createDataItem(dsv, factTable, self.column.getColumnName())\n</code></pre>\n"},{"tags":["mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":160,"score":0,"question_id":5023052,"title":"OLAP cube with filtered data","body":"<p>I have an ordinary OLAP cube (MS AS2000) with three dimensions, time, market, geography. Each of these dimensions has a simple hierarchy, e.g. time - [all][year][quarter][month], product - [all][market][brand][product]. There are two measures: value, units. </p>\n\n<p>Assume that for business reasons I don't want to distribute that cube with all product brands data. Someone may order/buy sales data for his brand and selected competitor. However for the market level, the cube should have full market aggregated data. In other words, there are four brands: B1, B2, B3, B4. A client orders data only for B1 and B2, so his cube should have data for B1 and B2. But the brands market should have aggregated sum of four brands.</p>\n\n<ol>\n<li>It is possible to build a such OLAP cube, where aggregated data of lower level cells doesn't sum up to parent cell value? </li>\n<li>If yes to above, then how to find cells with values that do not equal to aggregated lower levels.     </li>\n</ol>\n"},{"tags":["olap","pentaho","mondrian","data-presentation","olap4j"],"answer_count":1,"favorite_count":3,"up_vote_count":3,"down_vote_count":0,"view_count":1291,"score":3,"question_id":4893993,"title":"Presentation of data from Mondrian OLAP engine + Olap4j","body":"<p>I'm doing a little bit of planning of an application that uses Mondrian OLAP engine with Olap4j and should present/display data to user. I understand all the back-end stuff, but I'm not sure how should I display the data in the view layer. </p>\n\n<p>For example olap4j has a formatter that prints the SELECT nicely into the console. </p>\n\n<p>How is the data that I get from olap4j displayed in view layer ? I just went through the olap4j API, and there doesn't seem to be anything for getting the result in a form that can be somehow further processed and displayed. Is this process part of the Pentaho solution ? So that otherwise it is really not easy to present data just from Mondrian OLAP engine and olap4j ?</p>\n\n<p>EDIT: I'm used to traditionally get some data from a database into my DTO and display it in view layer. But how do I create DTOs for such a complicated result set ?</p>\n"},{"tags":["c#","vsto","excel-2007","olap","pivot-table"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":620,"score":2,"question_id":951495,"title":"ManualUpdate on Excel PivotTable","body":"<p>I'm attemping to update an Excel 2007 pivot table in VSTO (C#) and would like to ensure that the pivot table doesn't get updated until all of my edits are done.  So there's a property on the PivotTable class, ManualUpdate, that apparently does exactly what I want.  Unfortunately it appears that often times when I assign it the value \"true\" the value doesn't change.  Additionally, I've also seen on other occassions where it will change from \"true\" to \"false\" by itself.</p>\n\n<p>BTW, I'm working with an OLAP cube.  Does anyone know what the issue/conditions I need to consider with PivotTable.ManualUpdate?</p>\n\n<p>Thanks!</p>\n"},{"tags":["c#","ssas","olap","analysis-services","adomd.net"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1390,"score":0,"question_id":4785686,"title":"ADOMD.NET - An existing connection was forcibly closed by the remote host","body":"<p>We have a WPF application which gets data from an Analysis Services Cube.  The client connects directly to the database using ADOMD.NET.</p>\n\n<p>The WPF application works fine on existing Windows XP machines.  Windows 7 however throws the following error:</p>\n\n<pre><code>System.Reflection.TargetInvocationException: An exception occurred during the operation, making the result invalid.  Check InnerException for exception details. ---&gt; Microsoft.AnalysisServices.AdomdClient.AdomdConnectionException: The connection either timed out or was lost. ---&gt; System.IO.IOException: Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host. ---&gt; System.Net.Sockets.SocketException: An existing connection was forcibly closed by the remote host\n</code></pre>\n\n<p>I've narrowed the issue down further to be something around how the data is retrieved using ADOMD.NET.  From what I understand, there <a href=\"http://msdn.microsoft.com/en-us/library/ms123479.aspx\" rel=\"nofollow\">4 methods to retrieve</a> data.  It is only when I use a CellSet that this error occurs.</p>\n\n<p>In fact, I can use the same MDX statement which causes the exception above to return data just fine using the XmlReader.  It is only when I use the CellSet that the exception gets thrown.</p>\n\n<p>Any ideas?</p>\n"},{"tags":["sql","sql-server","ssas","mdx","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":170,"score":1,"question_id":4935976,"title":"Problem in cube's dimensions","body":"<p>I've got the following question.</p>\n\n<p>I have 3 dimensions:<br>\nDim1<br>\nDim2<br>\nDim3</p>\n\n<p>And a fact table, let's say:<br>\nFACT<br></p>\n\n<p>After processing the cube, I run a query which is to obtain the values filtered by dimension Dim1. However, I only get values for one member of Dim1<br><br></p>\n\n<pre><code>select [Measures].[Volume] on columns,\n[Dim1].[ID].[ID].members on rows\nfrom [Cube]\n\nDim1ID  | Volume\n  A     |  10\n  B     | (NULL)\n  C     | (NULL)\n</code></pre>\n\n<p>But when I run the following SQL:<br></p>\n\n<pre><code>select d.id, f.volume\nfrom fact f, dim1 d\nwhere d.id=f.id\n\nDim1ID  | Value\n  A     |  10\n  B     |  20\n  C     |  30\n</code></pre>\n"},{"tags":["data-warehouse","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":209,"score":0,"question_id":2793355,"title":"Star schema [fact 1:n dimension]...how?","body":"<p>I am a newcomer to data warehouses and have what I hope is an easy question about building a star schema:</p>\n\n<p>If I have a fact table where a fact record naturally has a one-to-many relationship with a single dimension, how can a star schema be modeled to support this? For example:</p>\n\n<ul>\n<li><strong>Fact Table: Point of Sale entry (the\nmeasurement is DollarAmount)</strong></li>\n<li><strong>Dimension Table: Promotions (these\nare sales promotions in effect when a\nsale was made)</strong></li>\n</ul>\n\n<p>The situation is that I want a single Point Of Sale entry to be associated with multiple different Promotions. These Promotions cannot be their own dimensions as there are many many many promotions.</p>\n\n<p>How do I do this?</p>\n"},{"tags":["ssas","olap","mdx","olap-cube"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":771,"score":1,"question_id":4625112,"title":"Help understanding OLAP MDX Query","body":"<p>I've been trying to learn SSAS Cubes and MDX. So far I have managed to create a cube that returns the correct data/calculations when viewed through the cube browser.</p>\n\n<p>The Query Builder was used to build a query in reporting services to query the cube, I've looked at the MDX this generated and pulled out the stuff that doesn't seem to make a difference to the actual results. The query looks like this:</p>\n\n<pre><code>SELECT NON EMPTY { [Measures].[AverageConnectedSeconds] } ON COLUMNS,    \nNON EMPTY { ([Operator].[ACCESS DEF].[ACCESS DEF].ALLMEMBERS * [Calls].[Notification Time Bands].[Notification Time Bands].ALLMEMBERS) } ON ROWS    \nFROM ( SELECT ( -{ [Calls].[Notification Time Bands].&amp;[0] } ) ON COLUMNS    \nFROM ( SELECT ( { [Calls].[Incoming YN].[N] } ) ON COLUMNS    \nFROM ( SELECT ( -{ [Calls].[Entity Type].&amp;[6] } ) ON COLUMNS   \nFROM ( SELECT ( -{ [Calls].[Reason Text].&amp;[Background Call] } ) ON COLUMNS    \nFROM ( SELECT ( { STRTOMEMBER(@OperatorId) } ) ON COLUMNS   \nFROM [PNC5data] )))))\n</code></pre>\n\n<p>I've read up on the Syntax and I <strong><em>THINK</em></strong> I understand why the query is doing nested selects.\nAm I right in understanding that the nested SELECT FROM's are acting as a WHERE clause would in SQL?</p>\n\n<p>If so: What is the WHERE clause used for in MDX and when/why would I use one?</p>\n\n<p>If anyone is able to give me a breakdown of what is actually happening in this query I'd really appreciate it! Or if you're able to direct me to a resource I could further my understanding of MDX, I'd be greatful!</p>\n\n<p>Thanks,</p>\n\n<p>James</p>\n"},{"tags":["olap","mdx","cubes"],"answer_count":0,"favorite_count":1,"up_vote_count":8,"down_vote_count":0,"view_count":1186,"score":8,"question_id":2067052,"title":"MDX Calculated Member CrossJoin question","body":"<p>I have an MDX query with the following calculated member:</p>\n\n<pre><code>with member [Measures].[BBOX] as\nCount(\n    Filter(\n        CrossJoin([Dim Response].[Response ID].Children, [Dim Question].[Question Text].Children),\n        [Measures].[Question Bottom Box] &gt; 0\n    )\n)\n</code></pre>\n\n<p>The idea is that I want a count of the combinations of two members of a dimension.  (Forgive me if my MDX vocabulary is a little off).  It is also based on some criteria.</p>\n\n<p>The rest of the query looks like this:</p>\n\n<pre><code>select \n{({[Measures].[TBOX], [Measures].[BBOX]}, \n[Dim Product].[Category Name].&amp;[Office])} on columns,\n{[Dim Question].[Question Text].Members} on rows \nfrom H1_FY10_Revised\nwhere ({[Dim Question].[Category Name].&amp;[Partner]}, \n{[Dim Subsidiary].[Subsidiary Alias Name].&amp;[Germany]})\n</code></pre>\n\n<p>My question is: does the slicing of data that occurs in the main query (the where clause) translate to the calculated member?  Is there any sort of implicit join between the data that comes back from the calculated member and the axises in the main query?</p>\n\n<p>Or another way to phrase it: does the cross join in the calculated member execute in the context of the main query?</p>\n"},{"tags":["sql-server-2008","olap","cube","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":354,"score":1,"question_id":4705633,"title":"Add translations to calculated member through AMO","body":"<p>I am using AMO to programmatically generate an OLAP Cube. How can I add translations for the calculated members? (SQL Server 2008)</p>\n\n<p>I have tried as follows, but it does not work:</p>\n\n<pre><code>MdxScript mdx = cube.MdxScripts[0];\nCalculationProperty calculation = new CalculationProperty();\ncalculation.CalculationReference = \"[Calculated measureName]\";\ncalculation.CalculationType = CalculationType.Member;\nTranslation translation = new Translation();\ntranslation.Caption = \"Some Caption\";\ntranslation.Language = \"Language Code\";\ncalculation.Translations.Add(translation);\nmdx.CalculationProperties.Add(calculation);\n</code></pre>\n"},{"tags":["sql-server","oledb","olap","mdx","openrowset"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":328,"score":1,"question_id":4780633,"title":"OpenRowSet ICommandPrepare::Prepare Error","body":"<p>I've got a DTS Package executing a number of steps that was working 100% correctly in the past.\nIn recent weeks it keeps failing on a step where OpenRowSet is used to perform an MDX Query against a SQL 2000 OLAP Cube.</p>\n\n<p>I know the issue isn't a problem with the MDX Syntax because it used to run correctly in this package and if i just perform the MDX query it returns the correct results.</p>\n\n<p>The server this runs on is a clients server so I cannot be 100% sure that nothing on the server has changed in the last few weeks but if something has changed I'm not being told about it.</p>\n\n<p>Here's the OpenRowSet Command with the MDX Query:</p>\n\n<pre><code>select * from \nOPENROWSET('MSOLAP',\n'Data Source=localhost; Initial Catalog=XVStock;',\n'WITH \nMEMBER [Measures].[year to date] AS  ''[Measures].[Sales Qty]''\nMEMBER [Measures].[Total Revenue] AS  ''[Measures].[Sales Value]''\nMEMBER [Measures].[Week to date Qty] AS  ''Sum(Wtd([Time].[Fiscal].CurrentMember),[Measures].[Sales Qty])''\nMEMBER [Measures].[Week to date Revenue] AS  ''Sum(Wtd([Time].[Fiscal].CurrentMember),[Measures].[Sales Value])''\nSELECT \nNON EMPTY {crossjoin(\n{[time].[fiscal].currentmember,\nancestor([time].[fiscal].currentmember, fyear)},\n\n{[Measures].[SOH],\n[Measures].[SOH Value],\n[Measures].[Week to date Qty],\n[Measures].[Week to date Revenue],\n[Measures].[year to date],\n[Measures].[Total Revenue]})\n} ON COLUMNS, \nNON EMPTY {crossjoin(\n{[Supplier].[All Supplier].[ACTIVISION BLIZZARD UK LTD]\n  ,[Supplier].[All Supplier].[BUENA VISTA]\n  ,[Supplier].[All Supplier].[CAPCOM]\n  ,[Supplier].[All Supplier].[CGS LTD]\n  ,[Supplier].[All Supplier].[CODEMASTERS]\n  ,[Supplier].[All Supplier].[ELECTRONIC ARTS]\n  ,[Supplier].[All Supplier].[SCI]\n  ,[Supplier].[All Supplier].[SQUARE ENIX LIMITED]\n  ,[Supplier].[All Supplier].[EMPIRE GAMES]\n  ,[Supplier].[All Supplier].[JOYTECH EUROPE]   \n  ,[Supplier].[All Supplier].[KONAMI UK]\n  ,[Supplier].[All Supplier].[MICROSOFT]\n  ,[Supplier].[All Supplier].[MIDWAY GAMES]\n  ,[Supplier].[All Supplier].[NINTENDO UK]\n  ,[Supplier].[All Supplier].[SONY COMPUTER ENT]\n  ,[Supplier].[All Supplier].[SEGA EUROPE]\n  ,[Supplier].[All Supplier].[SHERLANE AGENCIES]\n  ,[Supplier].[All Supplier].[SOLD OUT]\n  ,[Supplier].[All Supplier].[TAKE 2 INTERACTIVE]\n  ,[Supplier].[All Supplier].[THQ]\n  ,[Supplier].[All Supplier].[UBISOFT]\n  ,[Supplier].[All Supplier].[VIVENDI UNIVERSAL GAMES]\n  ,[Supplier].[All Supplier].[MIDIA DISTRIBUTION]\n},\n{[SBU Items].[All SBU Items].[TNR].[Retail].[Games Retail],\n[SBU Items].[All SBU Items].[TNR].[Retail].[Games Retail].[Consoles],\n[SBU Items].[All SBU Items].[TNR].[Retail].[Games Retail].[Game Accessories],\ndescendants([SBU Items].[All SBU Items].[TNR].[Retail].[Games Retail].[New S/W],[level 08],SELF_AND_AFTER)\n}\n)\n} DIMENSION PROPERTIES member_caption, [SBU Items].[level 08].[sbu key], [SBU Items].[level 08].[barcode]\n  ON ROWS \nFROM [Retail Stock Cube] \n'\n)\n</code></pre>\n\n<p>I've checked permissions on the DTS Package and I've poured through numerous articles without much success.\nMicrosoft's comments on the error message aren't much help either.</p>\n\n<p>I'd really appreciate any recommendations.</p>\n"},{"tags":[".net","postgresql","olap","business-intelligence","xmla"],"answer_count":2,"favorite_count":4,"up_vote_count":5,"down_vote_count":0,"view_count":2543,"score":5,"question_id":4022777,"title":"What options do I have for creating OLAP cubes with Postgres and making it accessible via .net webservices/wcf?","body":"<p>We have a large POSTGRESQL transactional database (around 70 million rows in all), and have previously created a data warehouse from this (updated daily) to run reports off of.</p>\n\n<p>To make this more flexible (as lots of different users require different reports and aren't very good at specifying what they want) we would like to create a multi dimensional OLAP cube and expose this via web services to our customers and possibly outsource report creation.</p>\n\n<p>We program in .NET (mainly vb.net) and I believe this can be achieved by using XMLA for the webservice (or WCF) layer, but after a bit of research (everything seems propietory - either SSAS and SQL server, or Jasper Server and Jasper Analysis etc), I'm unsure of the following and wondered if anyone else out there has any experience they can share:</p>\n\n<ol>\n<li>How do (various) front ends integrate with this? - we don't want to tie users to a particular front end.</li>\n<li>what front ends are available?</li>\n<li>What can I use to build the OLAP cube?</li>\n<li>Are there any alternative that I haven't found other than this XMLA approach?</li>\n</ol>\n\n<p>Scalability and Performance are huge factors for us, along with quick development time and an interface that is usable by users who only just learned how to use a mouse :p</p>\n\n<p>Note: ideally this solution be OpenSource and Free or less than Â£1k (most enterprise solutions are silly money)</p>\n"},{"tags":["ssas","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":395,"score":0,"question_id":4499139,"title":"How do I add KPI targets to my cube that are at a higher grain to my fact table?","body":"<p>I have a simple star schema with 2 dimensions; course and student.  My fact table is an enrolment on a course.  I have KPI Values set up which use data in the fact table (e.g. percentage of students that completed course).  All is working great.</p>\n\n<p>I now need to add KPI Goals though that are a different grain to the fact table.  The goals are at the course level, but should also work at department level, and for whatever combination of dimension attributes are selected.  I have the numerator and denominators for the KPI Goals so want to aggregate these when there are multiple courses involved - before dividing to get the actual percentage goal.</p>\n\n<p>How can I implement this?  From my understanding I should only have one fact table in my star schema.  So in that case would I perhaps store the higher grain values in the fact table?  Or would I create a dimension with these values in?  Or some alternative solution?</p>\n"},{"tags":[".net","mysql","mono","pivot","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":5,"down_vote_count":0,"view_count":669,"score":5,"question_id":3486561,"title":"Free OLAP solution for .NET running on Mono / MySQL","body":"<p>I'm developing my university graduation project and I'd like to include an OLAP-based reporting module. </p>\n\n<p>In the past, I've used Mondrian with JPivot as an OLAP solution for Java projects and I'm looking for something similar using .NET. The tricky part is that my project should run on Mono and MySQL (installation environment is a Linux machine) so MSSQL OLAP is out of the question.</p>\n\n<p>Anyone knows anything similar to Mondrian / JPivot that I can use? I don't mind even creating most of the aggregation tables myself as long as I have some sort of a crosstab/pivot control for my aspx page</p>\n"},{"tags":["olap"],"answer_count":2,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":872,"score":3,"question_id":4536933,"title":"Offline OLAP cube file format","body":"<p>In Excel pivot table you can request the generation of a offline OLAP cube : i.e., a file with the .cub extension. Does anybody know or have any pointer about this file format ?</p>\n\n<p>Thanks, _marc</p>\n"},{"tags":["c#",".net","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":257,"score":0,"question_id":3985884,"title":"Microsoft Analysis Services Translations","body":"<p>I have the following scenario:</p>\n\n<p>From .NET (v3.5, c#) I connect to an OLAP Cube using the Microsoft.AnalysisServices namespace and objects in order to manage dinamycally the translations of dimensions, measures, attributes,etc.</p>\n\n<p>A sample code updating an attribute caption translation looks like this:</p>\n\n<pre><code>foreach (DimensionAttribute dimAttribute in dimension.Attributes)\n{\n  dimAttribute.Translations.Add(1043, \"Some caption\") //language code\n}\n</code></pre>\n\n<p>However, the above code throws an \"InvalidOperationException\" -- \"The item type Translation is not valid\"</p>\n\n<p>Any ideas?</p>\n\n<p>Thanks in advance</p>\n"},{"tags":["osx","ssas","olap","mdx"],"answer_count":1,"favorite_count":1,"up_vote_count":3,"down_vote_count":0,"view_count":758,"score":3,"question_id":4672692,"title":"non-Windows OLAP desktop client?","body":"<p>Working with SSAS 2008 in an environment with mostly Mac desktops. Use DbVisualizer and Aqua Data Studio for writing relational queries, but need a native desktop app to write MDX queries and view results from OLAP sources.</p>\n\n<p>VMWare / Parallels is not the approach we need, and RDP / Terminal Services is used in some situations. Web based interfaces are OK for endusers, but BI developers would prefer something more convenient.</p>\n\n<p>Google searches have not returned too many useful hits.</p>\n\n<p>Can anyone recommend a native / Java desktop app for browsing and querying OLAP sources?</p>\n"},{"tags":["excel-vba","olap","slice","excel-2010","powerpivot"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":531,"score":0,"question_id":4127296,"title":"How to Print a Chart in Excel 2010 for every value of a Slicer?","body":"<p>Before I give a description of the problem, here is the list of technologies I am using - Excel 2010, PowerPivot Add-in, Win 7, Macros - VBA</p>\n\n<p>I have created charts using multiple data sources (via PowerPivot). PowerPivot has provided Slicers and I want to <strong>print various states of the chart to separate PDFs for each value of the Slicer</strong>. I have already written the code that does the printing job. I need help with a snippet of code to <strong>loop through the list of Slicers</strong> and select them in such a way that the state of the chart changes everytime.</p>\n\n<p>Through my research I found out that there is a property named SlicerItem.Selected which can be set to TRUE or FALSE to select a particular item in the Slicer. But apparently we can Set this property for OLAP pivot table/chart.</p>\n\n<p>Any help is appreciated.</p>\n\n<p>Thanks,\nRushabh. </p>\n"},{"tags":["olap","mdx","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":195,"score":0,"question_id":4613306,"title":"Calculated measure that combines two values to form a fractional value [Analysis Services]","body":"<p>In my cube I have two measure: A that stores values of the form <em>aaaaa</em> and B that stores values like <em>bbbbb</em>. I want to define measure C that will give the values <em>aaaaa.bbbbb</em>. How can I achieve this?</p>\n"},{"tags":["olap","business-intelligence","olap-cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":333,"score":0,"question_id":3718404,"title":"What database Palo OLAP server handles?","body":"<p>I was wondering what Palo OLAP Server handles as input Database ?</p>\n\n<p>Does someone know where I can find a list of the input Database supported ?</p>\n\n<p>Thank you !</p>\n"},{"tags":["excel","pivot","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":554,"score":1,"question_id":4592830,"title":"Excel 2010 Pivot Table Filter - How to print multiple filter selection values","body":"<p>Assume we have a country dimension which I use as an filter in Excel Pivot Table, datasource is a OLAP Cube.</p>\n\n<p>Now we choose some countries, the filter cell in excel is now named \"(Multiple Items)\" or a like, but I would like to print out / show the country names instead.</p>\n\n<p>How can I achieve this?</p>\n\n<p>Thanks</p>\n"},{"tags":["olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":634,"score":0,"question_id":4458398,"title":"OLAP vs Column DB","body":"<p>I am evaluating a choice between Oracle OLAP and Pentaho Mondrian.</p>\n\n<p>At the same time some people say that using a column DB could simply make the use of OLAP's redundant as they are much faster.</p>\n\n<p>has anyone got any experience on the same. \nWill it help if ou OLAP sits on a column db ?</p>\n"},{"tags":["python","database","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":926,"score":1,"question_id":2670887,"title":"MS Analysis Services OLAP API for Python","body":"<p>I am looking for a way to connect to a MS Analysis Services OLAP cube, run MDX queries, and pull the results into Python. In other words, exactly what Excel does. Is there a solution in Python that would let me do that?</p>\n\n<p>Someone with a similar question going pointed to Django's ORM. As much as I like the framework, this is not what I am looking for. I am also not looking for a way to pull rows and aggregate them -- that's what Analysis Services is for in the first place.</p>\n\n<p>Ideas? Thanks.</p>\n"},{"tags":["postgresql","olap","cubes"],"answer_count":2,"favorite_count":1,"up_vote_count":9,"down_vote_count":0,"view_count":6688,"score":9,"question_id":1778673,"title":"Postgresql for OLAP","body":"<p>Does anyone have experience of using postgresql for an OLAP setup, using cubes against the database etc. Having come across a number of idiosyncracies when using MySql for OLAP, are there reasons in favour of using postgresql instead (assuming that I want to go the open source route)?</p>\n"},{"tags":["olap","analysis-services","olap-cube","measure"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":59,"score":0,"question_id":4106618,"title":"Inheriting fields from a parent table olap cube","body":"<p>I have an OLAP cube containing a numeric measure that represent a foreign key against a parent table. I would like display the 'name' field from the parent table instead of the measure in my reports. it is possible?</p>\n"},{"tags":["ssis","ssrs-2008","ssas","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":413,"score":0,"question_id":4371322,"title":"When processing a SSAS cube, how can I gain visibility into progress?","body":"<p>When I issue the ProcessFull command, I would like to know the following:</p>\n\n<ul>\n<li>What is the current dimension being processed</li>\n<li>How many more dimensions will need to be processed before the ProcessFull command completes</li>\n</ul>\n\n<p>What APIs can I use to build my own progress bar?</p>\n"},{"tags":["ssas","olap","business-intelligence","xmla"],"answer_count":2,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":982,"score":0,"question_id":4317288,"title":"SSAS - Is it possible to add an attribute to an existing dimension w/o redeploying the entire cube","body":"<p>I have a dimension <code>Entity</code> with just <code>Key</code> and <code>Value</code> attributes. We need to add a new attribute, <code>IsSpecial</code> with a default member of <code>[False]</code>.</p>\n\n<p>When I try to run the xmla, I get the following error:</p>\n\n<blockquote>\n  <p>Errors in the metadata manager. The\n  cube with the ID of 'X', Name\n  of 'Y' was invalidated by\n  operations in the transaction.</p>\n</blockquote>\n\n<p>Here's a fragment of the XMLA used to alter the dimension</p>\n\n<pre><code>&lt;Dimension&gt;\n    &lt;ID&gt;Dim Entity&lt;/ID&gt;\n    &lt;Name&gt;Entity&lt;/Name&gt;\n    &lt;UnknownMemberName&gt;Unknown&lt;/UnknownMemberName&gt;\n    &lt;Attributes&gt;\n        &lt;Attribute&gt;\n            &lt;ID&gt;Dim Entity&lt;/ID&gt;\n            &lt;Name&gt;Entity&lt;/Name&gt;\n            &lt;Usage&gt;Key&lt;/Usage&gt;\n            &lt;EstimatedCount&gt;119&lt;/EstimatedCount&gt;\n            &lt;KeyColumns&gt;\n                &lt;KeyColumn&gt;\n                    &lt;DataType&gt;Integer&lt;/DataType&gt;\n                    &lt;Source xsi:type=\"ColumnBinding\"&gt;\n                        &lt;TableID&gt;shared_DimEntity&lt;/TableID&gt;\n                        &lt;ColumnID&gt;EntityKey&lt;/ColumnID&gt;\n                    &lt;/Source&gt;\n                &lt;/KeyColumn&gt;\n            &lt;/KeyColumns&gt;\n            &lt;NameColumn&gt;\n                &lt;DataType&gt;WChar&lt;/DataType&gt;\n                &lt;DataSize&gt;32&lt;/DataSize&gt;\n                &lt;Source xsi:type=\"ColumnBinding\"&gt;\n                    &lt;TableID&gt;shared_DimEntity&lt;/TableID&gt;\n                    &lt;ColumnID&gt;EntityValue&lt;/ColumnID&gt;\n                &lt;/Source&gt;\n            &lt;/NameColumn&gt;\n            &lt;AttributeRelationships&gt;\n                &lt;AttributeRelationship&gt;\n                    &lt;AttributeID&gt;IsSpecial&lt;/AttributeID&gt;\n                    &lt;Name&gt;IsSpecial&lt;/Name&gt;\n                &lt;/AttributeRelationship&gt;\n            &lt;/AttributeRelationships&gt;\n        &lt;/Attribute&gt;\n        &lt;Attribute&gt;\n            &lt;ID&gt;IsSpecial&lt;/ID&gt;\n            &lt;Name&gt;IsSpecial&lt;/Name&gt;\n            &lt;KeyColumns&gt;\n                &lt;KeyColumn&gt;\n                    &lt;DataType&gt;Boolean&lt;/DataType&gt;\n                    &lt;Source xsi:type=\"ColumnBinding\"&gt;\n                        &lt;TableID&gt;shared_DimEntity&lt;/TableID&gt;\n                        &lt;ColumnID&gt;IsShadowTracking&lt;/ColumnID&gt;\n                    &lt;/Source&gt;\n                &lt;/KeyColumn&gt;\n            &lt;/KeyColumns&gt;\n            &lt;NameColumn&gt;\n                &lt;DataType&gt;WChar&lt;/DataType&gt;\n                &lt;Source xsi:type=\"ColumnBinding\"&gt;\n                    &lt;TableID&gt;shared_DimEntity&lt;/TableID&gt;\n                    &lt;ColumnID&gt;IsShadowTracking&lt;/ColumnID&gt;\n                &lt;/Source&gt;\n            &lt;/NameColumn&gt;\n            &lt;DefaultMember&gt;[Entity].[IsSpecial].[False]&lt;/DefaultMember&gt;\n        &lt;/Attribute&gt;\n    &lt;/Attributes&gt;\n    &lt;Hierarchies&gt;\n        &lt;Hierarchy&gt;\n            &lt;ID&gt;Hierarchy&lt;/ID&gt;\n            &lt;Name&gt;Hierarchy&lt;/Name&gt;\n            &lt;Levels&gt;\n                &lt;Level&gt;\n                    &lt;ID&gt;IsSpecial&lt;/ID&gt;\n                    &lt;Name&gt;IsSpecial&lt;/Name&gt;\n                    &lt;SourceAttributeID&gt;IsSpecial&lt;/SourceAttributeID&gt;\n                &lt;/Level&gt;\n            &lt;/Levels&gt;\n        &lt;/Hierarchy&gt;\n    &lt;/Hierarchies&gt;\n&lt;/Dimension&gt;\n</code></pre>\n\n<p>Any suggestions?</p>\n"},{"tags":["database","database-design","project-management","performance","olap"],"answer_count":3,"favorite_count":1,"up_vote_count":0,"down_vote_count":2,"view_count":199,"score":-2,"question_id":4325586,"title":"Why is the business activity/engagement of OLAP so small in comparison to OLTP one?","body":"<p><a href=\"http://sql.wikis.com/wc.dll?SQL~datawarehouse\" rel=\"nofollow\">http://sql.wikis.com/wc.dll?SQL~datawarehouse</a> tells: </p>\n\n<ul>\n<li>\"Sid Adelman of Sid Adelman &amp; Associates in a recent presentation observed that the Meta group estimates <strong>the cost of a single data warehouse implementation project runs around $3 million, and that is for a single, initial implementation</strong>, nowhere near the scope of providing integrated views for an entire Enterprise\"</li>\n</ul>\n\n<p>I am afraid $3 million does not tell anything to majority of ppl.  </p>\n\n<p>How does it relate to the cost of corresponding (by size and level of data processing of) OLTP database implementation?<br>\nIs it higher/lower? how many times?  </p>\n\n<p>Note that OLAP solutions are usually being implemented after the costs of DBMS were already made for OLTP solutions...  </p>\n\n<p>Why are the costs so elevated?  </p>\n\n<p><strong>Update:</strong><br>\nLet me reformulate the question:\nWhy are the OLAP solutions rather very rare in comparison with OLTP ones?  </p>\n\n<p>Does the laboriousness and costs of OLAP seem too prohibitive?  </p>\n\n<p>Nobody seems to doubt in the need and necessity to spend money on OLTP.<br>\nThough, from the logical point of view, it is not clear to me why it is not vice versa?<br>\nThere are a lot of legacy data sources already accumulated even outside of DBMS...</p>\n\n<p><strong>Update2:</strong><br>\nReformulating the question again...<br>\nOne can judge about professional and business activity in certain areas by activity (number and frequency) of forum posts questions, vacancies, etc.<br>\nOLTP related questions has 2 orders more frequency(number) of questions compared to OLAP ones in this SO site.<br>\nWhy is it?  </p>\n"},{"tags":["olap","mdx","cube","pentaho","mondrian"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":268,"score":1,"question_id":4194846,"title":"MDX result categorisation","body":"<p>I'm new to mdx and have been trying to solve the following problem for about a day now. Any help would be appreciated:</p>\n\n<p>My Query:</p>\n\n<pre><code>select {[Measures].[Kunden]} ON COLUMNS,\nNON EMPTY Hierarchize(Union({CurrentDateMember([dimZeit], \"[\\di\\mZeit] \n\\.[yyyy]\"), CurrentDateMember([dimZeit], \"[\\di\\mZeit]\\.[yyyy]\").Children}, \nCurrentDateMember([dimZeit], \"[\\di\\mZeit]\\.[yyyy]\\.[q]\").Children))) ON ROWS\nFROM Center\n</code></pre>\n\n<p>which gives the following result, as expected:</p>\n\n<pre><code>Zeit        Kunden\n2010        1561\n - Q1       523\n - Q2       470\n - Q3       256\n - Q4       312\n  - Nov.    312\n</code></pre>\n\n<p>Now, what I want to achieve is to split the column 'Kunden' into columns 'Kunden &lt; 5 min' and 'Kunden > 5min' which means customers who have waited for less or more than 5 minutes.</p>\n\n<p>The closest I could get was the following:</p>\n\n<pre><code>WITH \nMEMBER [Measures].[LT5] AS \nAggregate(\nFilter([Measures].[Kunden], [Measures].[Wartezeit] &lt; 3000))\nselect {[Measures].[LT5]} ON COLUMNS,\nNON EMPTY Hierarchize(Union({CurrentDateMember([dimZeit], \"[\\di\\mZeit]\\.[yyyy]\"), \nCurrentDateMember([dimZeit], \"[\\di\\mZeit]\\.[yyyy]\").Children}, \nCurrentDateMember([dimZeit], \"[\\di\\mZeit]\\.[yyyy]\\.[q]\").Children)) ON ROWS\nFROM Center\n</code></pre>\n\n<p>The result is:</p>\n\n<pre><code>Zeit        Kunden\n2010        -\n - Q1       75\n - Q2       23\n - Q3       86\n - Q4       71\n  - Nov.    71\n</code></pre>\n\n<p>I understand the cause for this is, because the aggregated [Measure].[Wartezeit] for the whole year 2010 is above 3000 seconds. But I'd like to see the amount of customers with a waiting time below 3000 seconds, so it should be 75+23+86+71 = 255 for 2010.</p>\n"},{"tags":["python","django","orm","olap","mdx"],"answer_count":3,"favorite_count":8,"up_vote_count":6,"down_vote_count":0,"view_count":3328,"score":6,"question_id":469200,"title":"Any Python OLAP/MDX ORM engines?","body":"<p>I'm new to the MDX/OLAP and I'm wondering if there is any ORM similar like Django ORM for Python that would support OLAP.</p>\n\n<p>I'm a Python/Django developer and if there would be something that would have some level of integration with Django I would be much interested in learning more about it.</p>\n"},{"tags":["sql-server","oracle","database-design","architecture","olap"],"answer_count":1,"favorite_count":2,"up_vote_count":3,"down_vote_count":0,"view_count":414,"score":3,"question_id":3836282,"title":"What are locking issues in OLAP?","body":"<p>In one local financial institution I was rebuked by their programmers for expressing them my opinion that (their programmers' obsession with) (b)locking issues in their MS SQL Server 2005 OLAP (SSAS) database(s) did not make much sense to me. (The OLTP databases are SQL Server, Oracle and non-RDBMS ERP).   </p>\n\n<p>What are locking issues in OLAP processing if OLAP (SSAS) databases are used <strong>only for reading</strong> (read-only after deployment)?  </p>\n\n<p>In which context do such (an whic?)  issues arise - during SSIS processing and transfer of data from OLTP databases?<br>\nduring deployment of SSAS (OLAP) databases to SSAS? </p>\n\n<p>This question is not restricted to SQL Server.  </p>\n"},{"tags":["olap","analysis-services","olap-cube","measure"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":184,"score":0,"question_id":4106134,"title":"Varchar measure in Olap Cube","body":"<p>All the measures should be necessarily numerical? what about a varchar measure?</p>\n"},{"tags":["olap","multidimensional","dimensions","analysis-services","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":147,"score":1,"question_id":4106336,"title":"Adding a Relationship in olap Cube","body":"<p>Is possible to join a dimension to an OLAP cube using fields that do not have a foreign-key relationship in the underlying relational DB?</p>\n"},{"tags":["sql","database","database-design","data-warehouse","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":158,"score":0,"question_id":4001944,"title":"database: summarizing data which expires","body":"<p>I'm struggling to find an efficient and flexible representation for my data. We have a many-to-many relationship between two entities which have arbitrary lifetimes. Let's call these <code>Voter</code> and <code>Candidate</code>. Each relationship has a measurement which we'd like to summarize in various ways. These are timestamped and are guaranteed to be within the lifetime of the two related entities. Let's say the measure is approval rating, or just <code>Rating</code>.</p>\n\n<p>One unusual requirement is that if I'm summarizing a period which has no measurement, I should substitute the latest valid measurement, rather than giving NULL.</p>\n\n<p>Our current solution is to compile a list of valid voters and candidates for each day, then formulate a many-to-many table which records the latest valid measure.</p>\n\n<p>What would your solution be?</p>\n\n<p><img src=\"http://i.stack.imgur.com/uE8EB.png\" alt=\"Example diagram\"></p>\n\n<p>This allows me to do a single query to get a daily summary:</p>\n\n<pre><code>   select \n       avg(rating), valid_date, candidate_SSN, candidate_DOB\n   from \n       daily_rating natural join rating\n   group by\n       valid_date, candidate_SSN, candidate_DOB\n</code></pre>\n\n<p>This might work ok, but It seems inefficient to me. We're repeating a lot of data, especially if nothing happens for a given day. It also is unclear how to do weekly/monthly summaries without compiling even more tables. Since we're dealing with millions of rows (we're not really talking about voter polls...) I'm looking for a more efficient solution.</p>\n"},{"tags":["sql-server","pivot","olap","recursive-query"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":313,"score":0,"question_id":4025380,"title":"Transform a parent/child table to a fixed column dimentional table","body":"<p>I've a relational table (id, parentId, name)</p>\n\n<p>which I'd like to convert to a flattened dimentional table</p>\n\n<p>(id, Level1, Level2, Level3, Level4)</p>\n\n<p>I'm ok fixing the depth at 4 deep.</p>\n\n<p>I've made progress with a recursive CTE and pivot, but the result set isn't right</p>\n\n<p>I get</p>\n\n<pre><code>Id  Name   Level1 Level2\n0   Root   NULL   NULL\n1   NULL   L1     NULL\n</code></pre>\n\n<p>but I need</p>\n\n<pre><code>Id  Name   Level1 Level2\n0   Root   NULL   NULL\n1   Root   L1     NULL\n</code></pre>\n\n<p>here's what I have to date</p>\n\n<pre><code>with rcte as\n(\n      select h.id\n      ,h.parent_id\n      ,h.name\n      ,1 as HierarchyLevel \n  FROM RelTable h\n  where id = 1\n  union all\n  select h2.id\n       , h2.parent_id \n      , h2.name\n      , r.HierarchyLevel + 1 AS HierarchyLevel \n  FROM RelTable h2\n  inner join rcte r on h2.parent_id = r.id\n )\nselect id, parent_id, [1] as L1,[2] as L2,[3] as L3, [4] as L4\nfrom (\nselect id,parent_id,name,HierarchyLevel from rcte\n) as src\npivot  ( max(name)  for HierarchyLevel   in ([1],[2],[3],[4]) ) as pvt\n</code></pre>\n\n<p>what am I doing wrong?</p>\n"},{"tags":["olap"],"answer_count":2,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":148,"score":0,"question_id":3889512,"title":"Data Warehouse Design Question","body":"<p>In my OLTP database I have a layout consisting of instructors and students. Each student can be a student of any number of instructors. A student can also sign up for an instructor, but not necessarily book any tuition (lesson).</p>\n\n<p>In a data warehouse, how best would this be modelled? If I create a dimension table for Lessons, Instructors and Students and a fact table for the lessons students have taken then this will work when an instructor wants to see what lessons a student has taken.</p>\n\n<p>However, how will an instructor see how many students are REGISTERED with the instructor but has not yet taken a lesson? </p>\n\n<p>In my OLTP, I have a many to many table (InstructorStudents) that links each student with one more more instructors. In an OLAP database, this isn't appropriate.</p>\n\n<p>What would be the best schema in this case? Would a many to many be appropriate in this instance? I can't store a list of which students are registered to which instructors in the student table, so I feel another dimension table is necessary but cannot work out what should be contained in it.</p>\n"},{"tags":["sql-server","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":424,"score":2,"question_id":3950948,"title":"Microsoft SQL Server Analysis Services OLAP cube","body":"<p>I was trying to find a tool to increase performance in the reports of our application and I heard about OLAP + Reporting Services which is described as an excellent combination to do this work. Anyway I didn't find the way to keep the OLAP cube up-to-date since the data in the original DB can change. (It's a transactional application and one pending record can be mark as paid etc).</p>\n\n<p>Is this the better way to do this, or should I use another technology?</p>\n\n<p>If the suggestion is still to use OLAP + Reporting services how can I have the information up-to-date?</p>\n"},{"tags":["ssas","olap","analysis-services","cubes"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1705,"score":1,"question_id":3933177,"title":"Cube Design - Bridge Tables for Many To Many mapping with additional column","body":"<p>Am making a cube in SQL Server Analysis Services 2005 and have a question about many to many relationships.</p>\n\n<p>I have a many to many relationship between two entities that contains an additional descriptive column as part of the relationship. </p>\n\n<p>I understand that I may need to a bridge table to model the relationship but I am not sure where to store the additional column - in the bridge table or elsewhere?</p>\n"},{"tags":["sql-server","olap"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":85,"score":0,"question_id":3813491,"title":"Same measure ID/name conflict (SQL Server AMO)","body":"<p>I am currently importing two measure groups from two different cubes in a single new cube. There is a measure with the same name in the two cubes, when I import the measures in the new cube I get an error during cube processing because of the duplicate ID. How can I avoid this? I am using AMO to build the cube pro grammatically. (SQL Server 2005/2008)</p>\n"},{"tags":["ubuntu","olap","business-intelligence","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":447,"score":0,"question_id":3915292,"title":"Palo Suite 3.1, Ubuntu, missing OLAP Server","body":"<p>I just installed Palo Suite 3.1 with the archive I got form the official web site.\nI am running Ubuntu 10.04.\nOnce installed and logged in I got the surprise to do not have the \"OLAP Server\" menu.</p>\n\n<p>Does anyone know if there is something extra to do ?</p>\n"},{"tags":["sql-server","olap","analysis-services","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":882,"score":1,"question_id":3515033,"title":"Time dimension not working in SQL Server Analysis Services","body":"<p>My fact table has a \"Date\" column that I have used as a foreign key to the Time Dimension table I used SSAS to create for me in the datasource. However when I deploy the cube and browse it, adding the time dimension attributes or any of its hierarchies do not filter anything on the measures. Its like there is a disconnect between the time information in my fact table and the time dimension table SSAS created for me.</p>\n\n<p>Am I missing something here ? How do I link them such that I can use the generated time dimension to apply slice and dice analytics on my cube based on the date values in my fact table ?</p>\n"},{"tags":["sql-server","database-design","career-development","data-warehouse","olap"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":139,"score":1,"question_id":3878603,"title":"why is the engagement of OLAP practically neglected?","body":"<p>With astonishment observe that:<br>\n1)\nthat no answer to question <a href=\"http://stackoverflow.com/questions/3872996/transactional-and-reporting-databases-how\">Transactional And Reporting Databases - How?</a>\nmentions SSAS databases from MS BI (Business Intelligence) platform:</p>\n\n<ul>\n<li>SSAS (SQL Server Analysis Services) databases (OLAP, datawarehouses, datamarts) + DM (DataMining). </li>\n<li>SSRS - SQL Server Reporting Services</li>\n<li>SSIS - SS Integration S</li>\n</ul>\n\n<p>2)<br>\nI was Java, ASP.NET/C# dev for many years  and couple years ago I had got a remote free-lance job in SSAS.<br>\nI liked this area and tried to further specialize in it. </p>\n\n<p>I live in 1,000, 000 city with plenty of databases-oriented jobs. But nobody is hiring SSAS, MS BI (Business Intelligence) OLAP specialists.  In 2 my last full-time office job I I had even been hired for OLAP development but all ended in non-database-related  CRM/ERP maintenance routine. Mainly it was not even programming related.   </p>\n\n<p>The conclusion from 1), 2), as well as internet job searching and freelance projects bids, is that even IT development shops neglect OLAP or lack any influx of such projects/customers and and I am to abandon the attempts specialize in OLAP and to  return back to my previous C#/ASP.NET development.     </p>\n\n<p>Why is such situation with OLAP?<br>\nIs it going to change?<br>\nHow one could manage to get into and continue specializing in OLAP/BI?<br>\nIs my conclusion that specialization in OLAP is career dead-end wrong?   </p>\n"},{"tags":["olap","analysis-services"],"answer_count":0,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":249,"score":1,"question_id":3675263,"title":"Linked dimensions and measure groups","body":"<p>I am programmatically defining an OLAP cube (SQL Server Analysis Services) which imports measure groups and dimensions from two other cubes. How can I connect a dimension from one cube to a measure from another cube?</p>\n"},{"tags":[".net","windows-authentication","olap","kerberos","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":1045,"score":2,"question_id":3446220,"title":"Connecting to Microsoft Analysis Services cube with double hop windows authentication","body":"<p>I'm trying to enforce windows authentication for users of a .Net application on Web Server to access a cube on a Microsoft Analysis Services database on SSAS and just going nuts trying to get it to work! </p>\n\n<p>I am using <code>&lt;identity impersonate=\"true\" /&gt;</code> in the web.config. Anonymous access is turned off in IIS and Integrated Windows Authentication is selected. The appPool is running as a specified identity; a separate windows account which has been granted \"Account is trusted for delegation\" in Active Directory. I have also got the network guys to create and register a SPN for this identity on Web Server. The users trying to access the .Net application do not have \"Account is sensitive and cannot be delegated\" selected on their AD accounts.</p>\n\n<p>It works fine if the user is accessing the .Net application locally from the Web Server, but when accessing the .Net application from the client's PC they get an error: \"an error was encountered in the transport layer\" \"the peer prematurely closed the connection\". Doing a trace with SQL Profiler I can see that the NTUserName trying to authenticate unsuccessfully is ANONYMOUS LOGON. </p>\n\n<p>Why is it not delegating the user's authentication??</p>\n\n<p><strong>Solution:</strong></p>\n\n<p>Registering a SPN for the OLAP service as described <a href=\"http://support.microsoft.com/kb/917409\" rel=\"nofollow\">here</a> on the SSAS server fixed it! ie Setspn.exe -A MSOLAPSvc.3/Servername mydomain\\theuser.</p>\n"},{"tags":["java","olap","olap4j"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":368,"score":1,"question_id":3831308,"title":"Are there any JOLAP or Olap4j driver available?","body":"<p>Are there any driver available for JOLAP or Olap4j to access existing OLAP services? I think on OLAP services like Oracle, MS SQL, etc.</p>\n\n<p>We want start a OLAP project with Java? With which of the both API should we start?</p>\n"},{"tags":["excel","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1028,"score":1,"question_id":2064535,"title":"trouble connecting Excel to Analysis Services server","body":"<p>We have an SSAS server with a cube deployed on a server over the WAN..  We are trying to connect to the cube from Excel on various client workstations.  The server is not on a domain with the clients.  It \"works\" for some of us but not for others.  We are trying and failing yet to determine what the difference is on the machines that work versus the ones that don't.  However, even for the ones that work, it isn't as seamless as we think it should be.  I'll explain:</p>\n\n<p>In Excel, we use the Data-Other Sources-Analysis Server option, which presents us with the standard dialog:\n<img src=\"http://www.freeimagehosting.net/uploads/de3420ec26.gif\" alt=\"standard dialog\"></p>\n\n<p>Now, we believe the firewall and server settings are correct, because we are then presented with the dialog which lets you pick which cube to use from the server:\n<img src=\"http://www.freeimagehosting.net/uploads/882a09ee7f.gif\" alt=\"pick a cube dialog\"></p>\n\n<p>And, clicking \"Finish\" lets Excep being to work with the cube, as evidenced by the standard Excel dialog:\n<img src=\"http://www.freeimagehosting.net/uploads/fdf4626609.gif\" alt=\"all seems OK\"></p>\n\n<p>But then we are presented with the dreaded \"transport layer error\" message:\n<img src=\"http://www.freeimagehosting.net/uploads/243d5f3d49.gif\" alt=\"transport layer error\"></p>\n\n<p>Note that this error appears even on the machines that \"work.\"  What makes them \"work\" is that after clicking OK on that dialog, the next dialog appears:\n<img src=\"http://www.freeimagehosting.net/uploads/b8fc6bae18.gif\" alt=\"mysterious new dialog\"></p>\n\n<p>Once this dialog appears, you re-enter your password, and everything \"just works\" after that.  While I'd like it to \"just work\" without that second dialog, at least it works...  But on many machines we've tested this new dialog never comes up.  Instead, they just get the following error message, leaving them out of luck:\n<img src=\"http://www.freeimagehosting.net/uploads/601b9294e3.jpg\" alt=\"final error\"></p>\n\n<p>Can anyone offer any advice for this?  Thanks!</p>\n"},{"tags":["ssas","mdx","olap","cube"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":407,"score":0,"question_id":3736419,"title":"MDX query doesn't filter correctly","body":"<p>I have the following star schema:</p>\n\n<pre><code>Objects       &lt;-&gt; Facts         &lt;-&gt; Simulation\n-ObjectID         -ObjectID         -SimulationID\n-SimulationID     -SimulationID     \n-ObjHierarchy     -Volume\n-ObjectType\n</code></pre>\n\n<p>Now I'm trying to filter the cube using both dimensions:</p>\n\n<pre><code>select [Measures].[Volume] on columns,\n[Objects].[ObjHierarchy].[Level 02] on rows\nfrom [DM OC]\nwhere ([Objects].[ObjectType].&amp;[2], [Simulation].[SimulationID].&amp;[52])\n</code></pre>\n\n<p>However, this returns rows for <code>SimulationID=52</code> (with values) but also duplicates for <code>SimulationID=53</code> (with nulls):</p>\n\n<pre><code>ObjHierarchy | Volume\nMyObj1       | 12345\nMyObj2       | 54321\nMyObj1       | (NULL)\nMyObj2       | (NULL)\n</code></pre>\n\n<p>A workaround is to use NonEmpty, however it just seems the cube isn't modeled the right way.</p>\n"},{"tags":["database","data","data-warehouse","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":254,"score":0,"question_id":3808915,"title":"Drill Up/Down example?","body":"<p>I need an example of what drill up/down is ( + if it's graphical ) for a better understanding of these operations. I'm new to the whole Data Warehouse subject so high level explanations would be appreciated.</p>\n"},{"tags":["olap","mdx","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":73,"score":0,"question_id":1331389,"title":"can any body tell me the difference, why they produce different results?","body":"<p>1)</p>\n\n<pre><code>select non empty \n\n           [Measures].[carded transactions] on 0,\n           {[Date Dimension].[DATE].&amp;[39446]:[Date Dimension].[DATE].&amp;[39505]} on 1\n\nfrom [Food and Beverage]\n\nwhere \n(\n       FILTER(\n\t  {( [Revenue Center].[Revenue Center].[Revenue Center]\n\t   * [Date Dimension].[Fiscal Calendar].[Fiscal Day] \n\t   * [Date Dimension].[Day Name].[Day Name])}\n\t   , [Measures].[FnB Checks] &gt; 0\n             )\n )\n</code></pre>\n\n<p>2)</p>\n\n<pre><code>select non empty \n\n    [Measures].[carded transactions] on 0,\n    {[Date Dimension].[DATE].[DATE]} on 1\n\nFROM\n\n (SELECT \n        ([Date Dimension].[Fiscal Calendar].[Fiscal Day].&amp;[2008]&amp;[1]&amp;[1] \n        : [Date Dimension].[Fiscal Calendar].[Fiscal Day].&amp;[2008][2]&amp;[60]) ON  0  \n  FROM [Food and Beverage]\n ) \n\nwhere \n(  \n  FILTER(\n           {( [Revenue Center].[Revenue Center].[Revenue Center]\n\t   * [Date Dimension].[Fiscal Calendar].[Fiscal Day] \n\t   * [Date Dimension].[Day Name].[Day Name])}\n\t, [Measures].[FnB Checks] &gt; 0\n        )\n  )\n</code></pre>\n\n<p>thanx. help appreciated.</p>\n"},{"tags":["python","django-models","sqlalchemy","data-warehouse","olap"],"answer_count":3,"favorite_count":3,"up_vote_count":7,"down_vote_count":0,"view_count":891,"score":7,"question_id":3782386,"title":"Python: interact with complex data warehouse","body":"<p>We've worked hard to work up a full dimensional database model of our problem, and now it's time to start coding. Our previous projects have used hand-crafted queries constructed by string manipulation.</p>\n\n<p>Is there any best/standard practice for interfacing between python and a complex database layout?</p>\n\n<p>I've briefly evaluated SQLAlchemy, SQLObject, and Django-ORM, but (I may easily be missing something) they seem tuned for tiny web-type (OLTP) transactions, where I'm doing high-volume analytical (OLAP) transactions.</p>\n\n<p>Some of my requirements, that may be somewhat different than usual:</p>\n\n<ol>\n<li>load large amounts of data relatively quickly</li>\n<li>update/insert small amounts of data quickly and easily</li>\n<li>handle large numbers of rows easily (300 entries per minute over 5 years)</li>\n<li>allow for modifications in the schema, for future requirements</li>\n</ol>\n\n<p>Writing these queries is easy, but writing the code to get the data all lined up is tedious, especially as the schema evolves. This seems like something that a computer might be good at?</p>\n"},{"tags":["sql-server","ssis","data-warehouse","olap","business-intelligence"],"answer_count":2,"favorite_count":3,"up_vote_count":4,"down_vote_count":0,"view_count":484,"score":4,"question_id":3705011,"title":"What should I have in mind when building OLAP solution from scratch?","body":"<p>I'm working for a company running a software product based on a MS SQL database server, and through the years I have developed 20-30 quite advanced reports in PHP, taking data directly from the database. This has been very successful, and people are happy with it.</p>\n\n<p>But it has some drawbacks:</p>\n\n<ul>\n<li>For new changes, it can be quite development intensive</li>\n<li>The user can't experiment much with the data - it is locked to a hard-coded view</li>\n<li>It can be slow for big reports</li>\n</ul>\n\n<p>I am considering gradually going to a OLAP-based approach, which can be queried from Excel or some web-based service. But I would like to do this in a way that introduces the least amount of new complexity in the IT environment - the least amount of different services, synchronization jobs etc!</p>\n\n<p>I have some questions in this regard:</p>\n\n<p><strong>1) Workflow-related:</strong></p>\n\n<ul>\n<li>What is a good development route from \"black box SQL server\" to \"OLAP ready to use\"? </li>\n<li>Which servers and services should be set up, and which scripts should be written? </li>\n<li>Which are the hardest/most critical/most time-intensive parts?</li>\n</ul>\n\n<p><strong>2) ETL:</strong></p>\n\n<ul>\n<li>I suppose it is best to have separate servers for their Data Warehouse and Production SQL?</li>\n<li>How are these kept in sync (push/pull)? Using which technologies/languages?</li>\n<li>For me SSIS looks overly complicated, and the graphical workflow doesn't appeal much to me -- I would rather like a text based script that does the job. Is this feasible? </li>\n<li>Or is it advantagous to use the graphical client with only one source and one destination?</li>\n</ul>\n\n<p><strong>3) Development:</strong></p>\n\n<ul>\n<li>How much of this (data integration, analysis services) can be efficiently maintained from a CLI-tool? </li>\n<li>Can the setup be transferred back and forth between production and development easily?</li>\n</ul>\n\n<p>I'm happy with any answer that covers just some of this - and even though it is a MS environment, I'm also interested to hear about advantages in other technologies.</p>\n"},{"tags":["olap","etl","business-intelligence","datamart"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":281,"score":2,"question_id":3707881,"title":"Is this a proper idea of BI workflow?","body":"<p>I am new to Business Intelligence.</p>\n\n<p>I just got hired by a company in order to complete their websolution, implementing a BI Module. After lot of reading, I think I could get an idea of what a BI Process looks like, you'll find enclose my idea of a BI process.</p>\n\n<p>Can you please tell me if this is a correct vision of the all workflow ? If not please correct me. Another question, I can't see the place of data mining in the schema, where should I use it if needed ?</p>\n\n<p>Thanks a lot,<img src=\"http://i.stack.imgur.com/TTraY.jpg\" alt=\"alt text\"></p>\n"},{"tags":["olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":678,"score":1,"question_id":3558447,"title":"How do you design an OLAP Database?","body":"<p>I need a mental process to design an OLAP database...</p>\n\n<p>Essentially for standard relational it'd be (loosely)</p>\n\n<p>Identify Entities\nIdentify Relationships\nIdentify Properties of Entities</p>\n\n<p>For each property\n  ensure property can be related to only one entity\n  ensure property is directly related to entity</p>\n\n<p>For OLAP databases, I understand the terminology, the motivation and the structure,\nbut have no clue as to how to decompose my relational model into an OLAP model.</p>\n"},{"tags":["oracle","olap","cubes"],"answer_count":6,"favorite_count":3,"up_vote_count":7,"down_vote_count":0,"view_count":1406,"score":7,"question_id":42483,"title":"Simulated OLAP","body":"<p>We have a client that has Oracle <em>Standard</em>, and a project that would be ten times easier addressed using OLAP. However, Oracle only supports OLAP in the <em>Enterprise</em> version.</p>\n\n<p>Migration to enterprise is <strong>not</strong> possible</p>\n\n<p>I'm thinking of doing some manual simulation of OLAP, creating relational tables to simulate the technology.</p>\n\n<p>Do you know of some other way I could do this? Maybe an open-source tool for OLAP? Any ideas?</p>\n"},{"tags":["excel","vba","pivot","olap"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":1510,"score":0,"question_id":420190,"title":"Loop through PageField in OLAP Cube [PivotTable]","body":"<p>I'm trying to write a VBA script that will draw buttons beside the PageFields in a Pivot Table, these buttons will loop through the values in the PageField. I had this working for a regular Pivot Table, but I've been asked to adapt it for an OLAP Cube (External Data Source) and I can't work out how to find the values for a Member using VBA (for an OLAP Cube).</p>\n\n<p>Can anyone help?</p>\n\n<p>Previously I had the following</p>\n\n<pre><code>Public Function Next_page(row)\nDim pivTable As PivotTable\nDim pgField As PivotField\n\nSet pivTable = ActiveSheet.PivotTables(1)\nFor Each pgField In pivTable.PageFields\n    If pgField.DataRange.row = CInt(row) Then\n        If pgField.CurrentPage.Name = \"(All)\" Then\n            If pgField.PivotItems.Count &gt; 0 Then\n                pgField.CurrentPage = pgField.PivotItems(1).Name\n            End If\n            Exit Function\n        End If\n        For j = 1 To pgField.PivotItems.Count Step 1\n            If pgField.PivotItems(j) = pgField.CurrentPage.Name Then\n                If (j &lt; pgField.PivotItems.Count) Then\n                    pgField.CurrentPage = pgField.PivotItems(j + 1).Name\n                    Exit Function\n                End If\n            End If\n        Next j\n        Exit Function\n    End If\nNext\n</code></pre>\n\n<p>End Function</p>\n\n<p>But because the CurrentPage doesn't exist for an OLAP Cube it doesn't work.</p>\n"},{"tags":["oracle","data-warehouse","olap","business-intelligence"],"answer_count":5,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":199,"score":1,"question_id":3583626,"title":"Business Intelligence for small and medium scale companies","body":"<p>I would like to know if i can get a case study for my dissertation with the above topic. I am in dire need of data I can use for the developing the data warehouse and that would help me arrive at a possible conclusion of using the BI application I would be developing.Many thanks for your audience.</p>\n\n<p>Regards,\nTunde</p>\n"},{"tags":["database","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":228,"score":0,"question_id":3544951,"title":"Multidimensional databases and online analytical processing (OLAP) how it is related?","body":"<p><a href=\"http://en.wikipedia.org/wiki/Online_Analytical_Processing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Online_Analytical_Processing</a></p>\n\n<p>How is this two related? How to know that we are dealing with this type of programme?</p>\n"},{"tags":[".net","sql-server","ssas","olap","mdx"],"answer_count":3,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":904,"score":0,"question_id":2128137,"title":"How to get \"raw\" facts data from Analysis Services","body":"<p>We are developed a custom <a href=\"http://en.wikipedia.org/wiki/MOLAP\" rel=\"nofollow\">MOLAP</a> engine for live processing a large amount of data in process. And now we got a requirement to integrate SSAS with our system. Dimension's meta info and attributes data are very easy to get. \nBut how can I get facts data without making SSAS to calculate aggregates i.e. data that stored only on leafs? \nAggregates and calculations we perform ourselves.</p>\n\n<p>Selecting data from SQL Database is not a solution because Cube while loading can perform joins, filtering. clearing of data etc. </p>\n\n<h1>Example:</h1>\n\n<p>Suppose we have Product Dimension:</p>\n\n<ul>\n<li>Product.All<br>\n+Product.Bread<br>\n+Product.Chair<br>\n+Product.Book  </li>\n</ul>\n\n<p>And facts table - Sales:</p>\n\n<pre><code>|Product|Qty|  \n|Bread  | 1 |  \n|Chair  | 3 |  \n</code></pre>\n\n<p>I want to get from cube only real data, not aggregated one: </p>\n\n<pre><code>|Product|Qty|\n|All    | 4 |  \n|Book   | 0 |  \n|Bread  | 1 |  \n|Chair  | 3 |\n</code></pre>\n"},{"tags":["c#","asp.net","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":358,"score":2,"question_id":3524427,"title":"I am new to OLAP, Dundas with C#.net. Is there any sites to learn easily and quickly?","body":"<p>I am new to OLAP, Dundas. Is there any sites to learn easily and quickly?</p>\n\n<p>anywhere can I see the source code, like how the controls are talking to db and how the dundas charting controls are customized in code behind?</p>\n"},{"tags":["olap","project-server","olap-cube","project-server-2007"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":146,"score":0,"question_id":3400544,"title":"How to add Enterprise custom field to display actual costs from a different DB in Project Server?","body":"<p>I am trying wrap my head around how data is being served to Project Server.</p>\n\n<p>I am trying match up a value (actual cost) to project lines in an Executive View of Project Center which displays each project.  This actual cost comes from another database; the accounting database.</p>\n\n<p>I am assuming I have to build it in an OLAP Cube.</p>\n\n<p>Anyways, I would like to know if anyone knows how to link the cube to the enterprise custom field.</p>\n"},{"tags":["database-design","data-warehouse","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":261,"score":2,"question_id":3467931,"title":"Data Warehousing Design Question","body":"<p>I'm developing a data warehouse and have come up against a problem I'm not sure how to fix. The current schema is defined below:</p>\n\n<p>DimInstructor &lt;- Dimension table for instructors\nDimStudent &lt;- Dimension table for students</p>\n\n<p>I want to implement a scenario whereby if details of an instructor change in my OLTP database, I want to add a new record in the DimInstructor table for historical reporting reasons.</p>\n\n<p>Now, I'm wanting to create a lesson dimension table called DimLesson. In DimLesson I want to create a reference to the instructor.</p>\n\n<p>The DimInstructor table contains:</p>\n\n<p>InstructorDWID &lt;- Identity field when entered into DW\nInstructorID &lt;- The instructor ID that has come from the OLTP database</p>\n\n<p>Now, I can't make InstructorID a primary key because it isn't guaranteed to be unique (if the instructor changes their name, there will be 2 records in the DW with the same InstructorID value).</p>\n\n<p>So my question is, how do I reference the instructor from DimLesson? Do I use the InstructorDWID? If so, should I have 2 entries for an instructor in DimInstructor, it would make queries more complicated when I'm wanting to look at all lessons by a specific instructor.</p>\n\n<p>Any help would be appreciated!</p>\n"},{"tags":["sql-server","olap","etl"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":2,"view_count":300,"score":-2,"question_id":3454860,"title":"ETL Performance Problem","body":"<p>I have an important problem running ETL Process in production environment. While my ETL is running, the OLAP Server turns extremely slowly, I think this is because the ETL is updating several existing rows in the fact table and adding new ones. I tried to avoid this problem having a whole data base replication and ETL writes in DB1 and OLAP Server read from DB2(the replicated ones). It doesn't work at all. </p>\n\n<p>Can you give me some advices which point me in the right solutions to avoid this problem.</p>\n\n<p>I'm using SQL Server 2005. 8GB RAM\n   Mondrian OLAP Server into a Jboss Server. 8GB RAM.\n   ETL is running every 3 hours and is taking 2 hours running.</p>\n\n<p>I'd appreciate any help.</p>\n"},{"tags":["ssas","olap","cube","xmla"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":611,"score":0,"question_id":2916983,"title":"How to query (xmla) the size of an OLAP catalog in MSAS2008?","body":"<p>I would like to be able to query against an SSAS2008 instance and get a listing of all the catalogs that exist in it, as well as their respective storage sizes.  In Management Studio, I can right click on the catalog and go to its properties, which retrieves this data, so I know it exists somewhere.  A query that has some of the information I need is below:</p>\n\n<pre><code>&lt;Discover xmlns=\"urn:schemas-microsoft-com:xml-analysis\"&gt;\n  &lt;RequestType&gt;DBSCHEMA_CATALOGS&lt;/RequestType&gt;\n  &lt;Restrictions /&gt;\n  &lt;Properties /&gt;\n&lt;/Discover&gt;\n</code></pre>\n"},{"tags":["sql-server-2008","olap","analysis-services"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":77,"score":0,"question_id":2511859,"title":"Excluding facts having unrelated dimensions","body":"<p>In my Analysis Service OLAP Cube I would like to exclude facts having unrelated dimensions, which during processing produce errors. I would also like to avoid making Named Queries in Data Source View (with specific WHERE conditions).</p>\n\n<p>Is there any way to do this at the level of a cube? \nWhat is the easiest way to accomplish this?</p>\n\n<p>(I am using Visual Studio 2008 and SQL Server 2008.)</p>\n"},{"tags":["sql-server","ssas","olap","cube","analysis-services"],"answer_count":3,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":326,"score":1,"question_id":3198619,"title":"Why does my cube compute so slowly at the lowest drill down level?","body":"<p>I'm still learning the ropes of OLAP, cubes, and SSAS, but I'm hitting a performance barrier and I'm not sure I understand what is happening. </p>\n\n<p>So I have a simple cube, which defines two simple dimensions (type and area), a third Time dimension hierarchy (goes Year->Quarter->Month->Day->Hour->10-Minute), and one measure (sum on a field called Count).  The database tracks events: when they occur, what type are, where they occurred.  The fact table is a precalculated summary of events for each 10 minute interval. </p>\n\n<p>So I set up my cube and I use the browser to view all my attributes at once: total counts per area per type over time, with drill down from Year down to the 10 Minute Interval.  Reports are similar in performance to the browse.</p>\n\n<p>For the most part, it's snappy enough.  But as I get deeper into the drill-tree, it takes longer to view each level.  Finally at the minute level it seems to take 20 minutes or so before it displays the mere 6 records.  But then I realized that I could view the other minute-level drilldowns with no waiting, so it seems like the cube is calculating the entire table at that point, which is why it takes so long.</p>\n\n<p>I don't understand.  I would expect that going to Quarters or Years would take longest, since it has to aggregate all the data up.  Going to the lowest metric, filtered down heavily to around 180 cells (6 intervals, 10 types, 3 areas), seems like it should be fastest.  Why is the cube processing the entire dataset instead of just the visible sub-set?  Why is the highest level of aggregation so fast and the lowest level so slow?</p>\n\n<p>Most importantly, is there anything I can do by configuration or design to improve it?</p>\n\n<p>Some additional details that I just thought of which may matter: This is SSAS 2005, running on SQL Server 2005, using Visual Studio 2005 for BI design.  The Cube is set (as by default) to full MOLAP, but is not partitioned.  The fact table has 1,838,304 rows, so this isn't a crazy enterprise database, but it's no simple test db either.  There's no partitioning and all the SQL stuff runs on one server, which I access remotely from my work station.</p>\n"},{"tags":["visual-studio-2008","visual-studio-2005","ssas","olap"],"answer_count":5,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":3196,"score":1,"question_id":301289,"title":"OLAP Cubes: Compatibility between Analysis Services 2005 and 2008","body":"<p>I'm working with Analysis Services and I have run into a compatibility issue. Here is my situation. I have 3 machines:</p>\n\n<ul>\n<li>Server2005: This machine has SQL Server,  Analysis Services and Visual Studio, all in 2005 versions.</li>\n<li>Client2008: This machine has Visual Studio 2008.</li>\n<li>Client2005: This machine has Visual Studio 2005</li>\n</ul>\n\n<p>What I'd like to do:</p>\n\n<ul>\n<li>Develop cubes working on Client2008 and deploying on Server2005.</li>\n</ul>\n\n<p>The problem:</p>\n\n<ul>\n<li>I can read data and deploy cubes. However, when I try to \"process\" a cube I get an error message: Errors in the high-level relational engine. A connection could not be made to the data source with the DataSourceID of 'xxxxx', Name of 'xxxxx'. Impersonation information is set to \"Use service account\". I don't know why I can use the connection to read data, I can deploy the cube (a new AnalysisServices db is created in Server2005) but I can't process data.</li>\n</ul>\n\n<p>Tests that have worked:</p>\n\n<ul>\n<li>I can deploy and process cubes locally on Client2008 with SQL Server 2008.</li>\n<li>I can deploy and process cubes locally on Server2005.</li>\n<li>I can deploy and process cubes on Server2005 from Client2005.</li>\n<li>Here comes the strangest of all: I develop a cube using Client2005. I copy the visual project to Client2008 and update the project to use it with VS2008 and... it works! However if I develop exactly the same cube with VS2008 from the beginning I get the previous error. I have compared the .ds files generated with VS2005 and VS2008 and have not found any significant differences.</li>\n</ul>\n\n<p>I'm clueless. Any help is appreciated, thank you!</p>\n"},{"tags":["olap","msas"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":195,"score":0,"question_id":3131607,"title":"OLAP, if dimension has 'unknown' member, then only it is displayed if no measures added. Any ways to fix it?","body":"<p>I have cube in Microsoft Analysis Services with several dimensionsions and measures.</p>\n\n<p>When I(in cube browser, or through pivot tables in excel) try to drag dimension's attribute to grid with no measures added the following happens:</p>\n\n<ul>\n<li>if there were unknown member, then only it is displayed. Other rows from dimension are not displayed.</li>\n<li>if dimension had no unknown member, then everything from attribute is displayed. </li>\n<li>after dragging measures to grid, everything is displayed for dimension with unknown member as well.</li>\n</ul>\n\n<p>Is it possible to change behaviour to display all rows for dimension even if it has unknown member? </p>\n\n<p>Or I did miss something and having unknown member has nothing to do with number of rows being displaying from dimension when no measures are added? </p>\n"},{"tags":["sql-server","olap","cubes"],"answer_count":7,"favorite_count":3,"up_vote_count":2,"down_vote_count":0,"view_count":3266,"score":2,"question_id":49876,"title":"Simpler interface for SQL Server analysis services cubes for end users","body":"<p>Is there a simpler interface for end users to run \"queries\" on pre-existing SqlServer Analysis Service cubes?  I'm looking for a way to deploy the cubes and allow the users to work with the data through a simpler interface than BIDS.  Is this even possible?</p>\n"},{"tags":["reporting-services","crystal-reports","reporting","olap","business-intelligence"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":798,"score":0,"question_id":3133077,"title":"How to create a Cross-Tab Report with Split Grand Total","body":"<p>Can We create such kind of reports using Crystal Reports XI Cross-Tab?</p>\n\n<pre>\n\n Product Sales Comparison\n +---------------------------------------------------------------------------------+      \n |        |   Jan     |   Feb     |   Mar     |  April    |   May     |  TOTAL     | \n |        |------------------------------------------------------------------------|    \n |        |  09 | 08  |  09 | 08  |  09 | 08  |  09 | 08  |  09 | 08  |  09 | 08   |  \n |--------|-----------------------------------------------------------|------------|   \n | P1     |  89 | 76  |  10 | 96  |  78 | 86  |  13 | 87  | 23  |  65 | 213 | 410  |     \n | P2     |  85 | 75  |  92 | 38  |  63 | 17  |  87 | 33  | 78  |  37 | 405 | 200  |   \n | P3     |  82 | 83  |  95 | 96  |  76 | 95  |  32 | 99  | 93  |  65 | 378 | 438  |    \n | P4     |  93 | 80  |  47 | 17  |  47 | 65  |  46 | 34  | 45  |  86 | 278 | 282  |   \n | P5     |  67 | 28  |  82 | 78  |  84 | 84  |  58 | 76  | 58  |  63 | 349 | 329  |   \n | P6     |  93 | 58  |  36 | 39  |  15 | 85  |  67 | 25  | 36  |  98 | 247 | 305  |   \n |-------------------------------------------------------------------------------- | \n | TOTAL  | 509 |400  |362  | 364 | 363 | 432 | 303 | 354 | 333 | 414 | 1870| 1964 |\n +---------------------------------------------------------------------------------+\n</pre>\n"},{"tags":["python","database","django","olap","multidimensional"],"answer_count":3,"favorite_count":3,"up_vote_count":1,"down_vote_count":0,"view_count":848,"score":1,"question_id":2949602,"title":"Python / Django : emulating a multidimensional layer on a MySQL database","body":"<p>I'm working on a Django project where I need to provide a lot of different visualizations on the same data (for example <code>average of a value for each month</code>, <code>for each year</code> / <code>for a location</code>, etc...).</p>\n\n<p>I have been using an OLAP database once in college, and I thought that it would fit my needs, but it appears that it is much too heavy for what I need. Actually the volume of data is not very big, so I don't need any optimization, just a way to present different visualizations of the same data without having to write 1000 times the same code.</p>\n\n<p>So, to recap, I need a python library:</p>\n\n<ul>\n<li>to emulate a multidimensional database (OLAP style would be nice because I think it is quite convenient : star structure, and everything)</li>\n<li>non-intrusive, because I can't modify anything on the existing MySQL database</li>\n<li>easy-to-use, because otherwise there's no point in replacing some overhead by another.</li>\n</ul>\n"},{"tags":["hadoop","olap","hbase","log-analysis"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":319,"score":0,"question_id":3104899,"title":"Do you know batch log processing tools for hadoop (zohmg alternatives)?","body":"<p><br>\nSince the zohmg project seems to be dead (no new commits since nov 2009), I would like to know if any of you used/uses it (with successful results). Or if you know anything about future of this project.  </p>\n\n<p>And if not, is there any alternative for this project. I'm looking for tool that will help to extract data from (apache) logs (using Hadoop as a batch processing system), store it into HBase, help with querying this data.</p>\n"},{"tags":["sql-server","sql-server-2005","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":979,"score":0,"question_id":991692,"title":"Distribute OLAP cubes as part of application setup","body":"<p>We currently have our custom application that is being distributed with our database (SQL 2005/2008). It is an easy task, before we release a new version we just pack our database into SQL initialization scripts (these create tables and populate data). We use SQL Management studio to generate these scripts.</p>\n\n<p>As a next step we would like to deploy OLAP cube (along with ETL commands made with Integration Services) that would be used to analyze the data in the original database. . </p>\n\n<p>We know to create and design a cube, but I do not even know how could be generalize all these packages and deploy them as a solution, script or something that our customers could install on their servers. Customers do not have a Visual studio and we need to create \"something\" in a wizard (with some input required from customer e.g. OLAP cube name, server etc) for them to deploy it.</p>\n\n<p>How do you do that?</p>\n"},{"tags":["database","ssis","ssas","olap"],"answer_count":3,"favorite_count":6,"up_vote_count":7,"down_vote_count":0,"view_count":1506,"score":7,"question_id":1030712,"title":"What is the best approach to get from relational OLTP database to OLAP cube?","body":"<p>I have a fairly standard OLTP normalised database and I have realised that I need to do some complex queries, averages, standard deviations across different dimensions in the data.</p>\n\n<p>So I have turned to SSAS and the creation of OLAP cubes.</p>\n\n<p>However to create the cubes I believe my data source structure needs to be in a 'star' or 'snowflake' configuration (which I don't think it is right now).</p>\n\n<p>Is the normal procedure to use SSIS to do some sort of ETL process on my primary OLTP DB into another relational DB that is in the proper 'star' configuration with facts and dimensions, and then use this DB as the datasource for the OLAP cubes?</p>\n\n<p>Thanks</p>\n"},{"tags":["sql","database-design","data-warehouse","olap"],"answer_count":4,"favorite_count":0,"up_vote_count":6,"down_vote_count":0,"view_count":2174,"score":6,"question_id":2934193,"title":"Database warehouse design: fact tables and dimension tables","body":"<p>I am building a poor man's data warehouse using a RDBMS. I have identified the key 'attributes' to be recorded as:</p>\n\n<ul>\n<li>sex (true/false)</li>\n<li>demographic classification (A, B, C etc)</li>\n<li>place of birth</li>\n<li>date of birth</li>\n<li>weight (recorded daily):  The fact that is being recorded</li>\n</ul>\n\n<p>My requirements are to be able to run 'OLAP' queries that allow me to:</p>\n\n<ul>\n<li>'slice and dice'</li>\n<li>'drill up/down' the data and </li>\n<li>generally, be able to view the data from different perspectives</li>\n</ul>\n\n<p>After reading up on this topic area, the general consensus seems to be that this is best implemented using dimension tables rather than normalized tables.</p>\n\n<p>Assuming that this assertion is true (i.e. the solution is best implemented using fact and dimension tables), I would like to seek some help in the design of these tables.</p>\n\n<p>'Natural' (or obvious) dimensions are:</p>\n\n<ul>\n<li>Date dimension</li>\n<li>Geographical location</li>\n</ul>\n\n<p>Which have hierarchical attributes. However, I am struggling with how to model the following fields:</p>\n\n<ul>\n<li>sex (true/false)</li>\n<li>demographic classification (A, B, C etc)</li>\n</ul>\n\n<p>The reason I am struggling with these fields is that:</p>\n\n<ol>\n<li>They have no obvious hierarchical attributes which will aid aggregation (AFAIA) - which suggest they should be in a fact table</li>\n<li>They are mostly static or very rarely change - which suggests they should be in a dimension table.</li>\n</ol>\n\n<p>Maybe the heuristic I am using above is too crude?</p>\n\n<p>I will give some examples on the type of analysis I would like to carryout on the data warehouse - hopefully that will clarify things further. </p>\n\n<p>I would like to aggregate and analyze the data by sex and demographic classification - e.g. answer questions like:</p>\n\n<ul>\n<li>How does male and female weights compare across different demographic classifications?</li>\n<li>Which demographic classification (male AND female), show the most increase in weight this quarter.</li>\n</ul>\n\n<p>etc.</p>\n\n<p>Can anyone clarify whether sex and demographic classification are part of the fact table, or whether they are (as I suspect) dimension tables.?</p>\n\n<p>Also assuming they are dimension tables, could someone elaborate on the table structures (i.e. the fields)?</p>\n\n<p>The 'obvious' schema:</p>\n\n<pre><code>CREATE TABLE sex_type (is_male int);\nCREATE TABLE demographic_category (id int, name varchar(4));\n</code></pre>\n\n<p>may not be the correct one.</p>\n"},{"tags":["flex","dynamic","olap","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":737,"score":0,"question_id":1898669,"title":"Dynamic OLAPCube Flex","body":"<p>I'm trying to push data into an OLAPCube in flex.  The data coming in is flat and nothing else is known before hand.<br>\nHow do I have flex automatically create dimensions and such so that I can bind something to the cube?  Using a flex chart, it's as simple as setting the data provider to an array collection and it works.  </p>\n\n<p>The ONLY examples I have come across show how to hard-code names of data using flex; nothing dynamic.  Any help would be appreciated.</p>\n"},{"tags":["sql-server","ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":216,"score":0,"question_id":2410910,"title":"SSAS: distribution of measures over percentage","body":"<p>I am running a SSAS cube that stores facts of HTTP requests. The is a column \"Time Taken\" that stores the milliseconds a particular HTTP request took.</p>\n\n<p>Like...</p>\n\n<pre><code>RequestID     Time Taken\n--------------------------\n1             0\n2             10\n3             20\n4             20\n5             2000\n</code></pre>\n\n<p>I want to provide a report through Excel that shows the distribution of those timings by percentage of requests. A statement like \"90% of all requests took less than 20millisecond\".</p>\n\n<p>Analysis:</p>\n\n<pre><code>100%          &lt;2000\n80%           &lt;20\n60%           &lt;20\n40%           &lt;10\n20%           &lt;=0\n</code></pre>\n\n<p>I am pretty much lost what would be the right approach to design aggregations, calculations etc. to offer this analysis through Excel.</p>\n\n<p>Any ideas?</p>\n\n<p>Thanks,\nAlex</p>\n"},{"tags":["data-warehouse","olap","olap-cube","star-schema"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1278,"score":0,"question_id":2785158,"title":"Star schema [fact 1:n dimension]...how?","body":"<p>I am a newcomer to data warehouses and have what I hope is an easy question about building a star schema:</p>\n\n<p>If I have a fact table where a fact record naturally has a one-to-many relationship with a single dimension, how can a star schema be modeled to support this? For example:</p>\n\n<ul>\n<li><strong>Fact Table: Point of Sale entry (the\nmeasurement is DollarAmount)</strong></li>\n<li><strong>Dimension Table: Promotions (these\nare sales promotions in effect when a\nsale was made)</strong></li>\n</ul>\n\n<p>The situation is that I want a single Point Of Sale entry to be associated with multiple different Promotions. These Promotions cannot be their own dimensions as there are many many many promotions.</p>\n\n<p>How do I do this?</p>\n"},{"tags":["books","olap","cognos-tm1"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":741,"score":0,"question_id":2764402,"title":"Any books or other resources on Cognos TM1?","body":"<p>I have been assigned to a project to create a activity based costing system using Cognos TM1. I'm familiar with a number of other OLAP tools but have zero experience with TM1. Can anyone suggest a good book (searching doesn't turn up anything obvious) or any good online resources?</p>\n"},{"tags":["olap","business-intelligence"],"answer_count":1,"favorite_count":2,"up_vote_count":1,"down_vote_count":0,"view_count":182,"score":1,"question_id":2804152,"title":"How would you go about an OLAP dimension with a variable depth hierarchy?","body":"<p>In most cases, each level of a hierarchy within a dimension represents different concepts (i.e. country->region->city, year->month->day) and this is simple enough to use in a cube.</p>\n\n<p>What I'm interested in are variable depth hierarchies which tend to consist of instances of the same concept, i.e. nodes in a computer network where the \"depth\" is the <a href=\"http://en.wikipedia.org/wiki/Hop_count\" rel=\"nofollow\">hop count</a> from a specific point of observation.</p>\n\n<p>I'm considering setting up an arbitrary list of synthetic levels (level 1 = 1 hop away, level 2 = 2 hops away etc.), but then I probably have to pad the shorter branches all the way down to the lowest levels, which doesn't seem like a very elegant solution.</p>\n\n<p>I'm looking for comments, ideas, suggestions and best practices.</p>\n"},{"tags":["excel","olap","udf"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":328,"score":0,"question_id":2815427,"title":"Is it possible to create an efficient UDF alternative to Excel's CUBEVALUE function?","body":"<p>We'd like to create a simpler alternative to Excel's CUBEVALUE function for retrieving data from an OLAP server. The details aren't critical, but briefly, our function will \"know\" the source connection and accept a very simple ticker-like parameter and a date, in place of CUBEVALUE's MDX-style parameters. This is for internal use within our firm, just FYI.</p>\n\n<p>However, Excel has optimized CUBEVALUE so that calls to the OLAP server are batched.</p>\n\n<p>Question: Is there a way to code the new function so that it can similarly batch calls rather than issue a separate query for each cell?</p>\n"},{"tags":["flex","reporting-services","reporting","jasper-reports","olap"],"answer_count":1,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":690,"score":2,"question_id":2764495,"title":"OLAP Web Visualization and Reporting Recommendations","body":"<p>I am preparing an offer for a customer. They proide weekly data to different organizations. There is huge amount data suits OLAP that needed to be visualized with charts and pivot tables on web and custom reports will be built by non-it persons (an easy gui). They will enter a date range, location which data columns to be included and generate report and optionally export the data to Excel. They currently prepare reports with MS Excel with Pivot Tables and but they need a better online tool now to show data to their customers. Tables are huge and  need of drill-down functionality. My current knowledge Spring, Flex, MySql, Linux. I have some knowledge of PostgreSQL and MSSQL and Windows. What is the easiest way of doing this project. Do you think that  SSRP (haven't tried yet) and ASP.NET better suits for this kind of job. Actually I prefer open source solutions. Flex have OLAP Data Grid control which do aggregation on client side. JasperServer seems promising but it seems I need enterprise version  (multiple organizations and ad hoc queries). What about Modrian + Flex + PostgreSQL solution? Any previous experience will be appreciated. Yes I am confused with options.</p>\n"},{"tags":["ssas","olap","mdx","olap-cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":230,"score":0,"question_id":2687857,"title":"MDX Selective Summation for a Normalization Problem","body":"<p>I'm new to MDX and have a problem regarding filtering out values from a summation.</p>\n\n<p>We want to perform normalization calculations, specifically a quantity (q) divided by a basis (b) to get an Intensity (I). The formula is fairly simple I=q/b.</p>\n\n<p>OUR CUBE STRUCTURE:</p>\n\n<p>We have fact tables FactQuantity and FactBasis, each of which are tied to our DimOrg and DimTime dimension table. Both dimensions have hierarchies: Months rollup into years in DimTime, and Locations roll up into business units and groups in DimOrg.</p>\n\n<p>The fact tables are not in sync with each other: just because a quantity exists for a particular org_id and time, a basis is not guaranteed to exist for that same org_id and time.</p>\n\n<p>MY ATTEMPT AT A SOLUTION:</p>\n\n<p>The basic form of the calculated member is easy: \n    [Measures].[Quantity]/[Measures].[Basis]</p>\n\n<p>This works fine when we view at the lowest level of both dimensions, but the problems arise when you roll up the dimensions and begin aggregating.</p>\n\n<p>The problem is that Quantity values that don't have a corresponding Basis value at the same time and location are included, thus making the numerator too large and therefore incorrect.</p>\n\n<p>QUICK EXAMPLE:</p>\n\n<p>org_id 001 in Group A has a basis of 100 and a quantity of 1000, so its calculated intensity is 1000/100=10. Good so far.\norg_id 002 also in Group A has no basis but it does have a quantity of 2000, so its calculated intensity errors out.  Fine.</p>\n\n<p>Rolling up to Group A sums the quantity (3000) and the basis (100), leaving a calculated intensity of 30, which is incorrect for the Group.  The 2000 should have been excluded because it had no corresponding basis value for the same org_id and time.</p>\n\n<p>Any help you can offer is much appreciated.</p>\n\n<p>Thanks,</p>\n"},{"tags":["ssas","olap","mdx","cube","cubes"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1139,"score":1,"question_id":2653745,"title":"Calculated Measure using dimension","body":"<p>I am trying to build a calculated measure in SSAS that incorporates a dimension parameter. I have two facts: Members &amp; Orders and one Dimension: Date. Members represents all the unique members on my site. Orders are related to members by a fact key representing a unique user. Orders also contains a key representing the vendor for an order. Orders contains a key to the date dimension.</p>\n\n<p>FactMember\n - MemberFactKey\n - MemberId\nFactOrder\n - FactOrderKey\n - OrderId\n - FactMemberKey\n - DimVendorKey\n - DimDateKey\nDimDate\n - DimDateKey\n - FYYear</p>\n\n<p>The calculated measure I am trying to build is the number of unique vendors a member has ordered from. The value of the calculation must of course change based on the date dimension.</p>\n"},{"tags":["sql-server","ssas","olap","mdx"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":2113,"score":1,"question_id":2655020,"title":"How do I define a Calculated Measure in MDX based on a Dimension Attribute?","body":"<p>I would like to create a calculated measure that sums up only a specific subset of records in my fact table based on a dimension attribute.  </p>\n\n<p>Given:  </p>\n\n<p>Dimension    </p>\n\n<ul>\n<li>Date  </li>\n<li>LedgerLineItem {Charge, Payment, Write-Off, Copay, Credit}</li>\n</ul>\n\n<p>Measures  </p>\n\n<ul>\n<li>LedgerAmount  </li>\n</ul>\n\n<p>Relationships<br>\n* LedgerLineItem is a degenerate dimension of FactLedger  </p>\n\n<p>If I break down LedgerAmount by LedgerLineItem.Type I can easily see how much is charged, paid, credit, etc, but when I do not break it down by LedgerLineItem.Type I cannot easily add the credit, paid, credit, etc into a pivot table.  I would like to create separate calculated measures that sum only specific type (or multiple types) of ledger facts.</p>\n\n<p>An example of the desired output would be: </p>\n\n<pre><code>| Year  | Charged | Total Paid | Amount - Ledger |\n| 2008  | $1000   | $600       | -$400           |\n| 2009  | $2000   | $1500      | -$500           |\n| Total | $3000   | $2100      | -$900           |\n</code></pre>\n\n<p>I have tried to create the calculated measure a couple of ways and each one works in some circumstances but not in others.  Now before anyone says do this in ETL, I have already done it in ETL and it works just fine.  What I am trying to do as part of learning to understand MDX better is to figure out how to duplicate what I have done in the ETL in MDX as so far I am unable to do that.</p>\n\n<p>Here are two attempts I have made and the problems with them.\nThis works only when ledger type is in the pivot table.  It returns the correct amount of the ledger entries (although in this case it is identical to [amount - ledger] but when I try to remove type and just get the sum of all ledger entries it returns unknown.  </p>\n\n<pre><code>CREATE MEMBER CURRENTCUBE.[Measures].[Received Payment]\nAS CASE WHEN ([Ledger].[Type].currentMember = [Ledger].[Type].&amp;[Credit]) \nOR ([Ledger].[Type].currentMember = [Ledger].[Type].&amp;[Paid])\nOR ([Ledger].[Type].currentMember = [Ledger].[Type].&amp;[Held Money: Copay])\nTHEN [Measures].[Amount - ledger] \nELSE 0\nEND \n, FORMAT_STRING = \"Currency\"\n, VISIBLE = 1 \n, ASSOCIATED_MEASURE_GROUP = 'Ledger'  ; \n</code></pre>\n\n<p>This works only when ledger type is not in the pivot table.  It always returns the total payment amount, which is incorrect when I am slicing by type as I would only expect to see the credit portion under credit, the paid portion, under paid, $0 under charge, etc.  </p>\n\n<pre><code>CREATE MEMBER CURRENTCUBE.[Measures].[Received Payment]\nAS sum({([Ledger].[Type].&amp;[Credit]), ([Ledger].[Type].&amp;[Paid])\n, ([Ledger].[Type].&amp;[Held Money: Copay])}\n,  [Measures].[Amount - Ledger])\n, FORMAT_STRING = \"Currency\"\n, VISIBLE = 1 \n, ASSOCIATED_MEASURE_GROUP = 'Ledger'  ;  \n</code></pre>\n\n<p>Is there any way to make this return the correct numbers regardless of whether Ledger.Type is included in my pivot table or not?</p>\n"},{"tags":["database","olap","denormalization"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":366,"score":0,"question_id":2605536,"title":"Denormalization database","body":"<p>I was taking a look at <a href=\"http://www.percona.com/docs/wiki/_media/benchmark%3assb%3astarschemab.pdf\" rel=\"nofollow\">Star Schema Benchmark</a> and then I was thinking is it possible to denormalize all tables from the SSB?</p>\n\n<p>So database size will increase a lot but potentially the performance will grow up. Is that right? Is it possible?</p>\n\n<p>Thanks and sorry for my poor English.</p>\n"},{"tags":["delphi","pivot","olap","adomd.net"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":244,"score":1,"question_id":2534559,"title":"How to create a custom ADO Multi Dimensional Catalog with no database","body":"<p>Does anyone know of an example of how to dynamically define and build ADO MD (ActiveX Data Objects Multidimensional) catalogs and cube definitions with a set of data other than a database?</p>\n\n<p>Background: we have a huge amount of data in our application that we export to a database and then query using the usual SQL joins, groups, sums etc to produce reports.  The data in the application is originally in objects and arrays.  The problem is the amount of data is so large the export can take > 2 hours.  So I am trying to figure out a good way of querying the objects in memory, either by a custom OLAP algorithm or library, or ADO MD.  But I haven't been able to find an example of using ADO MD without a database behind it.</p>\n\n<p>We are using Delphi 2010 so would use ADO ActiveX but I imagine the ADO.NET MD is similar.  I realize that if the application data was already stored in a database the problem would solve itself.  Also if Delphi had LINQ capability I could query the objects and arrays that way.</p>\n"},{"tags":["query","olap","mdx","pentaho"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":2579,"score":1,"question_id":2511426,"title":"MDX Except function in where clause","body":"<p>i'm having problem restricting a query in mdx, using except function at where clause. i need to retrieved a set of data but which not in an specific set. Then i created the next query:</p>\n\n<pre><code>select {[Measures].[Amount], [Measures].[Transaction Cost], [Measures].[Transaction Number]} ON COLUMNS,{[ManualProcessing].[All ManualProcessings].[MAGNETICSTRIPE], ManualProcessing].[All ManualProcessings].[MANUAL]} ON ROWS \nFROM [Transactions]\nwhere except([Product].[All Products].Children,{[Product].[All Products].[Debit})\n</code></pre>\n\n<p>apparently this works fine, but when i try to add another restriction to slicer, i got this error: No function matches signature (Set,Member).</p>\n\n<p>I'm currently working on mondrian 3.1</p>\n\n<p>Is it possible to add multiple restriction to slicer when im sing the except funtion ? \nare there any other way to get this ?</p>\n\n<p>thanks in advance.</p>\n"},{"tags":["sql-server-2005","visual-studio-2005","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":526,"score":0,"question_id":538924,"title":"Visual Studio hangs when deploying a cube","body":"<p>I'm having an issue with an Analysis Services project in Visual Studio 2005. My project always builds but only occasionally deploys.  No errors are reported and VS just hangs.  This is my first Analysis Services project so I am hoping that there is something obvious that I am just missing.</p>\n\n<p>Here is the situation I have a cube that I have successfully deployed.</p>\n\n<p>I then make some change, e.g., adding a hierarchy to a dimension.  When I try to deploy again VS hangs.  I have to restart Analysis Services to regain control of VS so I can shut it down.  I restart everything sometimes once, sometimes twice or more before the project will eventually deploy.  This happens with any change I make there seems to be no pattern to this behaviour.  </p>\n\n<p>Sometimes I have to delete the cube from Analysis Services before restarting everything to get a successful deploy.  </p>\n\n<p>Also I have successfully deployed the cube, and then subsequently successfully reprocessed a dimension then when I open a query window in SQL Server Management Studio it says that it can find any cubes.</p>\n\n<p>As a test I have deployed a cube successfully.  I have then deleted it in Analysis Services and attempted to redeploy it, without making any changes to the cube, only to have the same behaviour mentioned above.</p>\n\n<p>VS just hangs with no reason so I have no idea where to start hunting down the problem.</p>\n\n<p>It is taking 15-20 minutes to make a change as simple as setting the NameColumn of a dimension attribute.  As you can imagine this is taking hours of my time so I would greatly appreciate any assistance anyone can give me.</p>\n"},{"tags":["database-design","data-modeling","olap","star-schema","dimensional-modeling"],"answer_count":4,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":444,"score":3,"question_id":2396378,"title":"Star-schema: Separate dimensions for clients and non-clients or shared dimension for attendants?","body":"<p>I'm new to modeling star schemas, fresh from reading the <a href=\"http://rads.stackoverflow.com/amzn/click/0471200247\" rel=\"nofollow\">Data Warehouse Toolkit</a>.</p>\n\n<p>I have a business process that has clients and non-clients calling into conference calls with some of our employees. </p>\n\n<p>My fact table, call it \"Audience\", will contain a measure of how long an attending person was connected to the call, and the cost of this person's connection to the call. The grain is \"individual connection to the conference call\".</p>\n\n<p>Should I use my conformed Client dimension and create a non-client dimension (for the callers that are not yet clients) this way (omitting dimensions that are not part of this questions):</p>\n\n<p><img src=\"http://i50.tinypic.com/1416xr7.png\" alt=\"First potential model\"></p>\n\n<p>Or would it be OK/better to have a non-conformed Attending dimension related to the conformed Client dimension in this manner:</p>\n\n<p><img src=\"http://i47.tinypic.com/2ccm9tg.png\" alt=\"Second potential model\"></p>\n\n<p>Or is there a better/standard mechanism to model business processes like this one?</p>\n\n<p><strong>Edit:</strong></p>\n\n<p>What about using model 2 above, but creating a view on top of the client dimension table and the attending dimension to make it look like it is only one dimension?</p>\n\n<p>Is that an acceptable alternative to Damir's answer below? </p>\n"},{"tags":["c#",".net","olap","multidimensional","cubes"],"answer_count":3,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":883,"score":2,"question_id":2368896,"title":"c# cube / multidimensional dataset","body":"<p>I'm working on a problem where i need to process multi dimensional data in memory using C#. My requirement resemble OLAP cubes but are not as complex. for example i don't need calculations or aggregation or stuff like that.  I basically would like to reference data using multidimensional keys. for example:</p>\n\n<pre><code>var key = new Key();\nkey[\"Dim1\"] = \"DimValue1\";\nkey[\"Dim2\"] = \"DimValue2\";\nkey[\"Time\"] = 1999;\nDataSet[key] = 4.43434m;\n</code></pre>\n\n<p>And it would allow me to iterate on the values or slices of the dataset. Have you come across such a library in C#?</p>\n"},{"tags":["version-control","olap","mdx","olap-cube"],"answer_count":2,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":534,"score":1,"question_id":2371539,"title":"Calculated measure/dimension","body":"<p>I'm relatively new to MDX and am trying to accomplish what I think should be an easy thing, but I haven't found any solution.</p>\n\n<p>I have a sales cube and one of the measure is profit which can be negative or positive. I want to get one measure which is effectively the sum of positive profit, i.e. only include in the new measure those profit numbers that have a positive profit.</p>\n\n<p>The trick here is this is on the row detail level and something like </p>\n\n<p>WITH MEMBER Measures.PositivePNL as IIF (Measures.PNL > 0, Measures.PNL,0)</p>\n\n<p>doesn't work as that only works with the aggregate number</p>\n"},{"tags":["database","hadoop","olap","hbase","olap-cube"],"answer_count":4,"favorite_count":1,"up_vote_count":8,"down_vote_count":0,"view_count":2762,"score":8,"question_id":2075797,"title":"Any scalable OLAP database (web app scale)?","body":"<p>I have an application that requires analytics for different level of aggregation, and that's the OLAP workload. I want to update my database pretty frequently as well.</p>\n\n<p>e.g., here is what my update looks like (schema looks like: time, dest, source ip, browser -> visits)</p>\n\n<pre><code>(15:00-1-2-2010, www.stackoverflow.com, 128.19.1.1, safari) --&gt;  105\n\n(15:00-1-2-2010, www.stackoverflow.com, 128.19.2.1, firefox) --&gt; 110\n\n...\n\n(15:00-1-5-2010, www.cnn.com, 128.19.5.1, firefox) --&gt; 110\n</code></pre>\n\n<p>And then I want to ask what is the total visit to www.stackoverflow.com from a firefox browser last month.</p>\n\n<p>I understand Vertica system can do this in a relatively cheap way (performance and scalability wise, but not cost-wise probably). I have two questions here.</p>\n\n<p>1) Is there an open-source product that I can build upon to solve this problem? In particular, how well does a Mondrian system work? (scalability, and performance)\n2) Is there an HBase or Hypertable base solution (obviously, a naked HBase/Hypertable can't do this) for this? -- but if there is a project based on HBase/Hypertable, scalability probably won't be an issue IMO)?</p>\n\n<p>Thanks!</p>\n"},{"tags":["security","olap","cubes","dimension"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":464,"score":0,"question_id":1707555,"title":"Dimension Security in OLAP Cubes","body":"<p>I have defined dimension security in my OLAP cube by creating roles and assigning users to each roles. Each user in a role can only see the location they belong to.</p>\n\n<p>When I browse the cube using a role , I see correct location for that role. But, when I browse the cube using \"Other User\" feature in \"Change User\" and test it for the same user which exist in the role, it fails and I see all the locations.</p>\n\n<p>What could be the problem?</p>\n\n<p>Thanks,\nKailash</p>\n"},{"tags":["sql-server-2005","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":731,"score":0,"question_id":2219942,"title":"Problems creating ragged hierarchy with Analysis Services","body":"<p>I'm attempting to create a ragged hierarchy in SSAS 2005. The \"Category Name\" and \"Sub-Category Name\" levels should be hidden in the hierarchy if either of them is blank. Leaf nodes which always have a value must display even if these two levels are blank.</p>\n\n<p>An image of how the measure has been configured is as follows:</p>\n\n<p><img src=\"http://img39.imageshack.us/img39/9468/dimmeasuretrim.png\" alt=\"Measure dimension\" title=\"Measure dimension\"></p>\n\n<p>I thought using HideMemberIf would fix this problem but it hasn't made any difference. Here is the Translations configuration:</p>\n\n<p><img src=\"http://img37.imageshack.us/img37/3710/dimmeasuretranstrim.png\" alt=\"Dimension translations\" title=\"Dimension translations\"></p>\n\n<p>According to MSDN, <a href=\"http://msdn.microsoft.com/en-us/library/ms129445%28SQL.90%29.aspx\" rel=\"nofollow\">HideMemberIf</a> with a NoName value hides the member when it is empty.</p>\n\n<p>Any ideas why this isn't working?</p>\n"},{"tags":["sql-server","olap","mdx","analysis-services"],"answer_count":1,"favorite_count":2,"up_vote_count":21,"down_vote_count":0,"view_count":1824,"score":21,"question_id":2203261,"title":"Designing dimension hierarchies: Natural or Unnatural","body":"<p>I'm using Analysis Services and when designing dimensions I'm never sure how far to go to build natural hierarchies.</p>\n\n<p>What I mean is I've added in all the genuine attribute relationships.  So most hierarchies are natural anyway but the most commonly requested hierarchy is 3 or more levels with a middle level as a slowly changing attribute.</p>\n\n<p>The scenario is tracking jobs.  The job has many attributes which are all static but the Debtor attribute (i.e. who's paying the invoice) can change over the course of the job.  So the hierarchies look like this</p>\n\n<pre><code> - Manager -&gt; Debtor -&gt; Job Name\n - Director -&gt; Debtor -&gt; Job Name \n - Office -&gt; Debtor -&gt; Job Name \n - Office -&gt; Manager -&gt; Debtor -&gt; Job Name\n</code></pre>\n\n<p>So within the dimension there are many hierarchies that start with static attribute(s) of the job followed by the debtor (wich slowly changes) with the job name (dimension key) at the bottom.</p>\n\n<p>So what we do at the moment to \"naturalize\" these hierarchies is create \"fake\" attributes for each debtor that appears in a hierarchy that is a combination of the attributes above it.  e.g. for the first example above the Debtor level attribute would have a key of Manager and Debtor id's.  And for the last example the Manager level would have a key of Manager and Office and the Debtor level attribute would have a key of Office, Manager &amp; Debtor.  We then hide all these attributes so they are only used in the hierarchies.</p>\n\n<p>So this makes our dimensions a lot more complicated but we do get the benefit of extra performance on our queries.  Often this is a noticeable improvement.  Apart from complexity we constantly hit problems because we now have multiple versions of a \"Debtor\" and the key of the attribute is not the id of the debtor.  So this affects Drillthrough and Reporting actions as well as making certain types of calculation more difficult if we want to change behaviour for certain levels.</p>\n\n<p>The clients we use are Reporting Services, Excel and Office Web Components.</p>\n\n<p>I've been told that on early versions of SQL 2005 complex queries involving unnatural hierarchies could result in the server getting completely tied in knots which is another reason we've gone to great lengths to avoid unnatural hierarchies.</p>\n\n<p>Also, the exclamation mark design warning is so dramatic in Visual Studio that it seems like a really bad thing to have unnatural hierachies.</p>\n\n<p>What do other designers do in these situations?  How far do you go to avoid unnatural hierarchies?</p>\n"},{"tags":["sql-server-2008","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1643,"score":1,"question_id":1689581,"title":"Parent-child dimension in Analysis Services from Server2008","body":"<p>Someone know some interesting and complete tutorial about how to create a Parent-Child dimension in Server2008?\nI found a brief introduction in Server2005, but a lot of step are changed.</p>\n\n<p>thanks in advance.</p>\n"},{"tags":["asp.net","asp.net-mvc","ajax","olap","dundas"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":617,"score":1,"question_id":2199116,"title":"Getting data from ASP.NET Dundas control before Ajax.Submit in ASP.NET MVC","body":"<p>I am working on a project in ASP.NET MVC using C# 3.0.</p>\n\n<p>I am using the Dundas Chart Control for OLAP. As the Dundas control does not directly support MVC it is used on a standard ASP.NET page with a codebehind file. This page is displayed in an iFrame of a normal View returned from a Controller Action.</p>\n\n<p>I have a button in the iFrame which submits a form via Ajax (using jQuery) to a method on the controller. I have also written an extension method for the OlapChart which returns the XML of the current report.</p>\n\n<p>What I am looking for is a way of getting the XML produced by the extension method to the Controller Action which handles the Ajax submit.</p>\n\n<p>I have only developed using ASP.NET MVC so I may be missing something obvious with Code Behind and ASP.NET controls.</p>\n\n<p>Thanks.</p>\n"},{"tags":["olap","mdx"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":115,"score":0,"question_id":2223888,"title":"Get share of dimension member in calculated measure","body":"<p>Not sure if what I'm trying to do is possible or if I need to change my data model.  </p>\n\n<p>I have a dimension containing the different amouts a customer can loan so what I wan't to do is see the share of a certain amount compared to total sales.  </p>\n\n<p>Pseudo code:  </p>\n\n<pre><code>member [Measures].[Share 5000] as 'count([Amount].[5000])/([Measures].[Total Sales], [Time].CurrentMember)'\n</code></pre>\n"},{"tags":["ssas","olap","mdx","cube"],"answer_count":3,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":164,"score":2,"question_id":1089926,"title":"how to find out which columns to join","body":"<p>Is there an easy way to find out the column dependencies between tables in the DSV of a cube? \nThe reason I am asking this question is: When there are lots of tables (fact and dim tables) in the dsv, it is hard to follow the lines. </p>\n\n<p>Help appreciated!</p>\n"},{"tags":["asp.net","olap","cubes"],"answer_count":3,"favorite_count":1,"up_vote_count":2,"down_vote_count":0,"view_count":2208,"score":2,"question_id":336695,"title":"Free controls for showing OLAP cubes","body":"<p>is there a free set of controls to be used for representing the OLAP cubes in aspx pages? something like the ones from Dundas, but free and (if possible) cross-browser.</p>\n\n<p>Thanks,\nLucian</p>\n"},{"tags":["data-warehouse","olap","etl"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":92,"score":0,"question_id":2110264,"title":"When is data erased from the OLAP DB?","body":"<p>I am new to OLAP.</p>\n\n<p>I understand the table structure and ETL process.</p>\n\n<p>I don't understand when data is supposed to be deleted from the fact table.\nSay I'm creating a reporting application for events. each event has the duration it took to complete, the exit code and total bytes read. There are several dimensions, e.g. time and location.</p>\n\n<p>Say I have 1 million new records ready for my fact table daily, A total of 1 GB.\nIf my ETL process only adds data to my fact table it grows indefinitely.\nWhen should I delete data from my fact table? Should I divide the data into several fact tables (e.g. monthly tables)?</p>\n\n<p>Is there any rule-of-thumb?</p>\n\n<p>Thanks</p>\n"},{"tags":["iis6","olap","application-pool"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":749,"score":2,"question_id":2109346,"title":"IIS 6.0 Application Pool Identity Being Ignored","body":"<p>I am using IIS 6.0 on Windows 2003 in a workgroup, and have created a web which runs in its own pool to connect to a Sqlserver 2005 Analysis Services database using msmdpump.dll. I have set the pool up with its own identity, but when I look on the Analysis Services server using Sqlserver Profiler, I can see that the requests  are being made, but not with the Pool identity. They are using the identity of the user signed into the web server.</p>\n"},{"tags":["olap","mdx","analysis"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":1077,"score":2,"question_id":2039301,"title":"MDX: How to turn tuples with multiple members into tuples with a single member?","body":"<p>I have this MDX query (based on the Foodmart sample database):</p>\n\n<pre><code>SELECT\n{[Measures].[Profit]} ON COLUMNS,\n{CROSSJOIN([Product].[All Products].Children, [Time].[1997].Children)} ON ROWS\nFROM [Sales]\n</code></pre>\n\n<p>This generates a result like this:</p>\n\n<pre><code>[Product].[Product Family] [Time].[Year] [Time].[Quarter] [Measures].[Profit]\n--------------------------+-------------+----------------+-------------------\nDrink                     |1997         |Q3              |7203.3445\nDrink                     |1997         |Q4              |8005.2245\nFood                      |1997         |Q1              |60814.47140000001\nFood                      |1997         |Q2              |57323.3736\n</code></pre>\n\n<p>What I would like to have, is this:</p>\n\n<pre><code>[Product Family],[Year],[Quarter] [Measures].[Profit]\n---------------------------------+-------------------\nDrink, 1997, Q3                  |7203.3445\nDrink, 1997, Q4                  |8005.2245\nFood, 1997, Q1                   |60814.47140000001\nFood, 1997, Q2                   |57323.3736\n</code></pre>\n\n<p>I know I can use <code>SetToStr()</code> to serialize the row headers to one string. So now I would like to use that result as rowheader: basically turning each tuple from the original multi-member tuples on the ROW axis into a tuple with just one member, who'se value is a concatenation of the original member names. So basically this:</p>\n\n<pre><code>SELECT\n{[Measures].[Profit]} ON COLUMNS,\nSetToStr(\n    {CROSSJOIN([Product].[All Products].Children, [Time].[1997].Children)}\n) ON ROWS\nFROM [Sales]\n</code></pre>\n\n<p>...but of course this does not work, because <code>SetToStr()</code> returns a string, not a set. So I need some way to 'cast' this string back to a set, but with only one member.</p>\n\n<p>Is this possible in standard MDX? How? I can rework the resultset after receiving it but I could really use a pure MDX solution to tackle this problem.</p>\n"},{"tags":["sql-server","olap","business-intelligence","analysis-services"],"answer_count":2,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":1555,"score":3,"question_id":2028837,"title":"Cant connect to analysis services via excel","body":"<p>I have an analysis services cube in SQL server 2005 which I'm connecting to via an excel front end.</p>\n\n<p>When I connect via one user its fine, but when I log on to the same machine as another user I get an error in my excel spreadhseet - \"user...does not have access to the [Cube name] database\"</p>\n\n<p>Obviously the first user has the correct permissions, but how do I set up analysis services to allow other users to join the party?</p>\n"},{"tags":["mysql","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":822,"score":0,"question_id":1839527,"title":"Externalized time dimension in MySQL OLAP cubes?","body":"<p>It appears to be a common practice to let the time dimension of OLAP cubes be in a table of its own, like the other dimensions.</p>\n\n<p>My question is: why?</p>\n\n<p>I simply don't see what the advantage would be to have a <code>time_dimension</code> table of <code>(int, timestamp)</code> that is joined with the cube on some <code>time_id</code> foreign key, instead of having a <code>timestamp</code> column in the cube itself.</p>\n\n<p>Principally, points in time are immutable and constant, and they are their own value. I don't find it very likely that one would want to change the associated value for a given <code>time_id</code>.</p>\n\n<p>In addition, the <code>timestamp</code> column type is 4 bytes wide (in MySQL), as is the <code>int</code> type that would otherwise typically be the key, so cannot be to save space either.</p>\n\n<p>In discussing this with my colleagues, the only somewhat sensible argument I have been able to come up with is conformity with the other dimensions. But I find this argument rather weak.</p>\n"},{"tags":["olap","cubes","project-server-2007"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":195,"score":0,"question_id":1076843,"title":"Cube Configuration","body":"<p>On \"Cube Configuration\" page of Project Server, you have the option to add enterprise fields to the cube as dimensions. When you select the option \"Assignment\" from the cube drop down, you are given a list of available fields to choose from. However, some of the fields are labeled with a <strong>\"R__Assignment\"</strong> or <strong>\"T__Assignment\"</strong> suffix and i can't find any documentation on what they do.</p>\n\n<p>Any help would be appreciated ;).</p>\n\n<p><img src=\"http://img39.imageshack.us/img39/9567/cubefieldselect.gif\" alt=\"alt text\" /></p>\n"},{"tags":["sql-server-2005","ssas","olap","mdx"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":314,"score":0,"question_id":1562917,"title":"MDX geographic distance calculation","body":"<p>I'm using <a href=\"http://en.wikipedia.org/wiki/Microsoft%5FSQL%5FServer#Analysis%5FServices\" rel=\"nofollow\">SQL Server 2005 Analysis Services</a> and I'm trying to calculate distance inside of an MDX query - so that I can get counts of the items that are near my current location.  I've created a dimension with Latitude &amp; Longitude, and have also created a .NET assembly to do the math - but am having a hard time getting it all to work out in the query.</p>\n\n<p>My query to find items in a 100 mile radius looks something like this:</p>\n\n<pre><code>select   FILTER([DimProducts].[Product].[Product],\n         ZipCalculatorLib.GetDistance(43.474208, [Zip].[Latitude], 96.687689, [Zip].[Longitude]) &lt; 100)  on rows,\n    \t[Measures].[RowCount] on columns\nfrom     MyCube;\n</code></pre>\n\n<p>And my distance code in .NET looks like this:</p>\n\n<pre><code>public static double GetDistance(double startLat, double endLat,\n    double startLong, double endLong)\n{\n    return Math.Sqrt(Math.Pow(69.1 * (startLat - endLat), 2) + Math.Pow(Math.Cos(endLat / 57.3) * 69.1 * (startLong - endLong), 2));\n}\n</code></pre>\n\n<p>However, when I run that query, I come up with zero records.  If I change the distance from 100 to 10000 - I get counts similar to what should be in the 100 mile radius.  It looks like the .NET class isn't doing the square root - but I've tested that code many times over, and it looks right.</p>\n\n<p>Does anyone have any suggestions as to where I should look to fix my problem?</p>\n\n<p>EDIT:\nI started to wonder if maybe the latitude and longitude weren't being passed into my GetDistance function correctly - so I added a line of code there to throw an exception to show me what they were.  I added the following:</p>\n\n<pre><code>throw new ArgumentException(\"endLat\", string.Format(\"endLat: {0}, endLong: {1}\", endLat, endLong));\n</code></pre>\n\n<p>And now when I run my query, I get the following error:</p>\n\n<blockquote>\n  <p>Execution of the managed stored\n  procedure GetDistance failed with the\n  following error: Exception has been\n  thrown by the target of an\n  invocation.endLat Parameter name:\n  endLat: 1033, endLong: 1033.</p>\n</blockquote>\n\n<p>So now the question becomes: how do I get my actual latitudes values to pass through that function in the filter?  It looks like just a language code is being passed in now.</p>\n"},{"tags":["sql-server","ssas","data-warehouse","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":5,"down_vote_count":0,"view_count":2700,"score":5,"question_id":1787883,"title":"What is Multi Dimention OLAP CUBE and give example cube with more than 3 dimentions","body":"<p>Hi\nAs I am new to SSAS,have been reading  an article on  Multi-Dimention OLAP Cube and struggling to understand Cube concepts, It has been said that Although the term \"cube\" suggests three dimensions, a cube can have up to 64 dimensions. Could you please explain how is this possible on cube\n(other than 3-Dim example x,y,z planes)? Please don't give only links to study but also expecting some explanation.\nThanks</p>\n"},{"tags":["db2","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":141,"score":1,"question_id":1057500,"title":"DB2 web OLAP Viewer","body":"<p>Does anybody know of a web based something that would allow end users to interact (change selection) for an OLAP cube on DB2</p>\n"},{"tags":["algorithm","design-patterns","database-design","storage","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":5,"down_vote_count":0,"view_count":201,"score":5,"question_id":1676916,"title":"Is there a data storage pattern similar to mipmaps in graphics?","body":"<p>We've got a bunch of data the users may want to view windows of and do so quickly. They may want to look at a window of the data that is a day, a week, a month, or an arbitrary beginning and ending data. Sorting and summing up all of this stuff in real time is proving to be painful for us so I got the idea of doing something similar to Mipmaps in 3D rendering. You end up storing the same data pre-calculated at a variety of different scales and then interpolate the results using the varying scales. So I would already know what the numbers were for a year, a given month, a given week, and a given day for a store and if they ask for a particular range I use the various scales to quickly add up something that gives the right results but I don't have to necessarily reprocess the full data set, I just retrieve four or five records and add or subtract them.</p>\n\n<p>Is this a real pattern? Does it make any sense and there are places I can read about how to do it best or are there much better ways of dealing with large chunks of data like this where it needs to be viewed in varying slices?</p>\n\n<p>It seems like this should be a well known and solved problem. For example, lots of people have stock portfolios and they need to do this kind of thing every day. Our data isn't stock prices, but the idea is the same.</p>\n"},{"tags":["sql","db2","olap","rank"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":574,"score":0,"question_id":1457135,"title":"DB2 - Ranking data by timeframe","body":"<p>I am trying to write a report (DB2 9.5 on Solaris) to do the following:</p>\n\n<p>I have a set of data, let's say it's an order table. I want to run a report which will give me, for each month, the number of orders per customer, and their \"rank\" that month. The rank would be based on the number of orders. I was playing around with the RANK() OVER clauses, but I can't seem to get it to give me a rank per month (or other \"group by\"). If there are 100 customers and 12 months of data, i would expect 1200 rows in the report, 100 per month, each with a rank between 1 and 100. Let me know if more detail would be helpful. Thanks in advance.</p>\n"},{"tags":["c#","wpf","olap","pivot-table","adomd.net"],"answer_count":2,"favorite_count":2,"up_vote_count":0,"down_vote_count":0,"view_count":1905,"score":0,"question_id":539858,"title":"Has anyone used ADOMD.NET with WPF DataGrid?","body":"<p>I am trying to find a good way of accessing a Business Intelligence OLAP Cube from C#.</p>\n\n<p>I don't really care much as to how this is done, but since currently I am trying to implement this with the <a href=\"http://www.codeplex.com/wpf\" rel=\"nofollow\">codeplex WPF Toolkit</a>, I would be happy if it was something directly related to the tool, but any suggestions are very welcomed.</p>\n\n<p>My WPF skills are lacking, so the tips &amp; tricks on the site aren't enough for me to get how to bind the DataGrid to an OLAP cube. </p>\n\n<p>I presume I should use ADOMD.NET, but not so sure yet if thats the way to go, and if so, how to go about it, tutorials and informative links are baffling me quite significantly.</p>\n\n<p>Since I keep going round in circles when it comes to finding any example of this having been made, I would appreciate any pointers in this regard.</p>\n\n<p>Tutorials, links, personal tips or experiences welcomed.</p>\n\n<p>Extra info: <em>this is in order to replace the currently used pivot table in an Excel Spread Sheet.</em></p>\n\n<p>thanks,</p>\n\n<p>Ric</p>\n"},{"tags":["asp-classic","ms-office","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":163,"score":0,"question_id":1560794,"title":"PivotTable Drillthrough not supported","body":"<p>We migrated our old ASP app to ASP.NET and can't seem to figure out the cause of this error.</p>\n\n<p>Webpage error details</p>\n\n<p>User Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022; InfoPath.2; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; MS-RTC EA 2; MS-RTC LM 8)\nTimestamp: Mon, 12 Oct 2009 20:50:06 UTC</p>\n\n<p>Message: Object doesn't support this property or method: 'PivotTable1.Drillthrough'\nLine: 1173\nChar: 2\nCode: 0\nURI: http:///DSS2009/HospitalVisitsCube.aspx</p>\n\n<p>Before, the page was hosted on a Windows 2000 Server, IIS 5.0 and SQL Server 2000.  We migrated the app to a new environment: Windows 2003 Server, IIS 6.0, SQL Server 2005 w/ Analysis Services and now the pages are using ASP.NET (ASP.NET 2.0 to be exact).  Anyone have a clue as to what's happening and a possible solution?  My first thought was that IIS 6 supports ASP 3.0 which might have deprecated this method/property. However, I'm clueless and can't prove my theory because my ASP knowledge is very limited.  Does anyone have any clue aso to what's happening?</p>\n"},{"tags":["sql","oracle","plsql","views","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":446,"score":1,"question_id":1526579,"title":"Oracle material views vs analytic workspaces","body":"<p>In Oracle, what are the pros and cons of using materialized views, and of analytic workspaces? What are the best practices surrounding the use of these features?</p>\n\n<p>We have an OLTP system, but would also like to access summary information in reports and interactive decision support tools. </p>\n"},{"tags":["sql","sql-server","tsql","olap"],"answer_count":4,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":756,"score":3,"question_id":1511553,"title":"SQL Server aggregates for very large tables","body":"<p>We have a table with 17Mil rows containing product attributes, let's say they're:</p>\n\n<p>brandID, sizeID, colorID, price, shapeID  </p>\n\n<p>And we need to query for aggregates by brand and size. Currently we query and filter this data by doing something like this:</p>\n\n<p>select brandID, sizeID, count(*) from table where \n    colorID in (1,2,3) and price=10 and shapeID=17\n    --\"additional complex where clause here\"\ngroup by brandID, sizeID\norder by brandID, sizeID</p>\n\n<p>And we report this data. The problem is, it takes 10 seconds or so to run this query (and this is a very simple example) in spite of the fact that the actual data returned will be just a few hundred rows.</p>\n\n<p>I think we've reached our capacity for indexing this table so I don't think any amount of indexes will get us to near-instant results.</p>\n\n<p>I know very little about OLAP or other analysis services, but what's out there for SQL Server that can pre-filter or pre-aggregate this table so that queries like the above (or similar returning equivalent data) can be performed? \nOR What's the best way to handle arbitrary where clauses on a very large table?</p>\n"},{"tags":["query","olap","mdx"],"answer_count":1,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":360,"score":1,"question_id":1361039,"title":"MDX - Concurrent calculations based on a \"record time range\"?","body":"<p><strong>Dear MDX experts,</strong></p>\n\n<p><em>- Is it possible to get the concurrent calculation based on a record time range?</em></p>\n\n<p><strong><em>Lets say I have;</em></strong> <em>'start date'</em>, <em>'end date'</em>, <em>'used'</em>, and <em>'color'</em> available... in my fact table..</p>\n\n<p>Is it possible to get the concurrent of <em>'used'</em> per time (the biggest sum of 'used' that happened during the same range), if yes - what about concurrent used per 'color'?</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":370,"score":2,"question_id":1351362,"title":"SSAS 2005: working with database slow after processing","body":"<p>I have a SSAS 2005 database with 10 cubes. When I create the cubes from an XMLA script, it works fast, and I can browse cubes from SSMS, just as I should.</p>\n\n<p>After processing the cubes during the night, eveyrthing starts to work VERY slow. Opening cube list in SSMS takes few minutes, and it is like this all the time. What can cause this?</p>\n"},{"tags":["ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":111,"score":1,"question_id":1302684,"title":"help needed on OLAP cubes","body":"<p>While processing an SSAS cube, the query that I got from processing window like \"under SQL queries 1\" is producing resultset, but when the processing is done and the measures are pulled into the brower, the values do not show up. </p>\n\n<p>What could be the reason???</p>\n"},{"tags":["sql-server","sql-server-2005","reporting","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":3,"down_vote_count":0,"view_count":609,"score":3,"question_id":1231945,"title":"Package for presenting OLAP data","body":"<p>I'm managing a very large data warehouse (>1 TB) based on MS SQL 2005. I would like to create a solution for the users to present data from the cubes on-line (web interface). Right now they are using Office Web Components, but it's not so good. I don't have any controls over the reports that they create. I googled, and there are some solution like Dundas or Analyzer.</p>\n\n<p>Maybe someone has some experience with this (or other) packs and can share opinions? I have some basic requirements:</p>\n\n<ul>\n<li>high performance and no unnecessary queries to the OLAP server</li>\n<li>being able to store reports (for example: users creates filters, selects dates ranges and he must be able to store it)</li>\n<li>ability to export to Excel</li>\n<li>some charting engine built in would be nice.</li>\n</ul>\n\n<p>Some ideas?</p>\n"},{"tags":["sql","database","data-warehouse","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":235,"score":0,"question_id":1202526,"title":"How does OLAP address dimensions that are numeric ranges?","body":"<p>To preface this, I'm not familiar with OLAP at all, so if the terminology is off, feel free to offer corrections.</p>\n\n<p>I'm reading about OLAP and it seems to be all about trading space for speed, wherein you precalculate (or calculate on demand) and store aggregations about your data, keyed off by certain dimensions. I understand how this works for dimensions that have a discrete set of values, like { Male, Female } or { Jan, Feb, ... Dec } or { @US_STATES }. But what about dimensions that have completely arbitrary values like (0, 1.25, 3.14156, 70000.23, ...)?</p>\n\n<p>Does the use of OLAP preclude the use of aggregations in queries that hit the fact tables, or is it merely used to bypass things that can be precalculated? Like, arbitrary aggregations on arbitrary values still need to be done on the fly?</p>\n\n<p>Any other help regarding learning more about OLAP would be much appreciated. At first glance, both Google and SO seem to be a little dry (compared to other, more popular topics).</p>\n\n<p>Edit: Was asked for a dimension on which there are arbitrary values.</p>\n\n<ul>\n<li>VELOCITY of experiments: 1.256 m/s, -2.234 m/s, 33.78 m/s</li>\n<li>VALUE of transactions: $120.56, $22.47, $9.47</li>\n</ul>\n"},{"tags":["sql-server","command-line","olap","mdx","ascmd"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":555,"score":0,"question_id":283543,"title":"How to persuade ascmd.exe to make tables as output, not a XML file?","body":"<p>I'm trying to see data in my OLAP cube by ascmd utility. As input I put a MDX query, but only what I have as output (in command line) is a XML file. I tried to use -Tf text and -Tf csv parameters, but they don't work in the way I think they should (I have a XML on output all the time). I want to have on my output something like this www.pinaldave.com/download/sqlcmd4.gif -- Is it possible to get text output in ascmd (as it is in sqlcmd)?</p>\n\n<p>Thanks for help.\nBest Regards.</p>\n\n<p>PS. syntax I use: ascmd.exe -S Servername -d Database -i query.mdx -Tf csv -o output.csv</p>\n"},{"tags":["ssas","olap","dimensions"],"answer_count":0,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":120,"score":0,"question_id":1187618,"title":"Processing dimension in SSAS 2000","body":"<p>I have a shared dimension in SQL Server Analysis Services 2000. The dimension is used in two cubes. The dimension is marked as non-changing dimension. </p>\n\n<p>Names of some memebers in the database have changed. However no structal changes have been made. I process the dimension incrementaly, but the names of the memebrs stored in dimension don't change. </p>\n\n<p>Is the only option for me to fully process the dimension? I don't want to do it, because it would require reporocessing two very large cubes (30 GB cubes, and 300 GB of raw fact data).</p>\n\n<p>Any suggestions?</p>\n\n<p>EDIT: I have a similar solution working on SSAS 2005, and the Process Update option is working, that means name of memebers are changing.</p>\n"},{"tags":["sql-server","microsoft","ssas","olap","msas"],"answer_count":1,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":1485,"score":2,"question_id":1122979,"title":"What is the best way to model a ragged hierarchy in SSAS for both ROLAP and MOLAP?","body":"<p>I'm currently trying to model a ragged hierarchy in SSAS and I'm stuck.</p>\n\n<p>First, I was trying to model it like so:</p>\n\n<pre><code>ItemKey,Level0Key,Level1Key,Level2Key\nItem1,Lvl0-1,Lvl1-1,Lvl2-1\nItem2,Lvl0-1,Lvl1-1,Lvl2-1\nItem3,Lvl0-1,Lvl1-1,Lvl2-2\n**Item4,Lvl0-1, , **\n</code></pre>\n\n<p>Where the last line in this example had blanks for the \"missing\" levels.</p>\n\n<p>Here, ROLAP managed to interpret the hierarchy okay, but MOLAP mode wound up mis-classifying members from the fact table, so the aggregations were off.</p>\n\n<p>Next, I changed it to this based on the AdventureWorksDW example SalesTerritory dimension which was a ragged hierarchy:</p>\n\n<pre><code>ItemKey,Level0Key,Level1Key,Level2Key\nItem1,Lvl0-1,Lvl1-1,Lvl2-1\nItem2,Lvl0-1,Lvl1-1,Lvl2-1\nItem3,Lvl0-1,Lvl1-1,Lvl2-2\n**Item4,Lvl0-1,Item4,Item4**\n</code></pre>\n\n<p>I'm taking advantage of the HideIfOnlyChildAndSameNameAsParent to hide the members.</p>\n\n<p>Now MOLAP's numbers line up, but in ROLAP land, I'm having major slowdowns because level 1 of my hierarchy has about 10000 members - SSAS goes out to lunch on an expansion.</p>\n\n<p>So obviously I'm missing something, but I haven't seen many examples on the \"right\" way to do a ragged hierarchy.</p>\n\n<p>Thanks for any answers.</p>\n"},{"tags":["ssas","olap","cube","cubes"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":631,"score":0,"question_id":1002334,"title":"Can an OLAP cube be constructed where the details of the model are not known in advance?","body":"<p>Pardon me for the woolly question - I'm not really that familiar with OLAP &amp; cubes. Let me explain my situation...</p>\n\n<p>I'd like to build a database to store questionnaire results, where there might be a few dozen questions per questionnaire. Having gathered a few thousand completed questionnaires, I'd like to analyze the results, and that sounds like a good candidate for OLAP type stuff (of which I know very little). I need to be able to run queries on \"all male respondents age 20-30 who own a dog\" - i.e. combining the answers to \"how old are you\", \"do you own a dog\", etc.</p>\n\n<p>I also want to be able to store the results of next month's survey, and the month after that, etc., and run queries showing this month versus last, etc. So far, so good, I assume.</p>\n\n<p>Here's the nub of my question: whereas this month my questionnaire might have questions about sex, age &amp; dog ownership, next month's questionnaire might include a question about (say) eye color. It might (or might not) also drop some questions. Is that do-able in the OLAP world, or do you need to know all the \"dimensions\" (if I'm using the right term) in advance when you design your cube?</p>\n\n<p>Also, if I'm running several different surveys with different-but-overlapping questions, can I store them all in the same cube and run queries across surveys? Each survey might have a few dozen questions, with a couple of dozen overlapping with other surveys. Do OLAP systems cater for this sort of thing? I just don't know how rigid they are, and whether they are in fact appropriate for this kind of usage.</p>\n\n<p>Any help greatly appreciated.</p>\n\n<p>PS. Before someone suggests it, I did just buy Kimball's Data Warehouse Toolkit but haven't had a chance to read it yet. (I suspect it may not directly answer this question anyway).</p>\n"},{"tags":["ssas","olap","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":145,"score":0,"question_id":1100287,"title":"Help needed on calculated measures","body":"<p>Patron Revenue Cube:</p>\n\n<p>In one of the calculated measures â€œAcutal Gross Profitâ€, there are four measures used  as </p>\n\n<p>â€œ[Measures].[Acutal Win]-[Measures].[Operator Pay]-[Measures].[Redeeming Dollars]-[Measures].[Redeeming Comp]â€</p>\n\n<p>The first two measures belong to vw_fact_patronrevenue  view  and the other two belong to vw_fact_patronredemption view.</p>\n\n<p>Those two views do not have any foreign key relation to each other. They are related through dimension views.  </p>\n\n<p>To verify the calculated measure, I need to get the\n column_names for  the select statement (which I have),\ntable/view (i also have them)\njoining column_names (which I donâ€™t have, and how do I figure out which columns do I need for not-directly-related tables)\n There are however some  columns which are common to both tables </p>\n"},{"tags":["ssas","olap"],"answer_count":3,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":443,"score":1,"question_id":1050045,"title":"OLAP and SQL Server Analysis Services","body":"<p>Could you recommend some tutorials regarding OLAP cubes (especially in the context of Microsoft Project Server) and SQL Server Analysis Services? Books would also be great.</p>\n"},{"tags":["ssas","olap","cubes"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":604,"score":0,"question_id":1094228,"title":"Calculated members: SSAS","body":"<p>In the \"Calculations\" tab of an SSAS cube project, does \"Measures\" dimension represent all measures within the measure groups as well?</p>\n\n<p>For instance:\nPatron Revenue has measures actual win, cash in, cash out....\nPatron Redemption has measures operator pay, redeeming dollars, redeeming comp...</p>\n\n<p>In calculation tab, \n[Actual Gross Profit] is calculated as \n[Measures].[Actual Win]-[Measures].[Operator Pay]-[Measures].[Redeeming Comp]-[Measures].[Redeeming Dollars]</p>\n\n<p>So, in this case, does the [Measures] dimension represent the measures such as actual win, operator pay, redeeming comp and redeeming dollars etc located in different measure groups?</p>\n\n<p>Help appreciated!</p>\n"},{"tags":["ssas","olap","fact-table"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":447,"score":0,"question_id":1070527,"title":"cube partitions: is the fact table in the DSV designer just one of the cube partitions?","body":"<p>There are 16 partitions for a fact table. All 16 of them have the same structure and have the same aggregation scheme. 15 of them contains data and while the 16th contains no data. </p>\n\n<p>So, is  the fact table in the DSV designer just one of those partitions? (the name in the header matches one of the partitions though) </p>\n\n<p>if it is so, then whenver we need to process a different partition, just replace the fact table in the designer and reprocess? </p>\n"},{"tags":["tsql","olap","mdx","cubes"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":294,"score":0,"question_id":1058796,"title":"how to figure out which columns in the fact table are used for calculating measures in an OLAP cube?","body":"<p>I have to verify that olap cube data and the data from relational tables from where a cube is built is correct. \nAnd I will do so by writing the TSQL queries and compare the values with that of cube.</p>\n\n<p>But, I got stuck in the course of determining which columns are used for measure. How do I figure out which columns are used for measures?</p>\n\n<p>Help appreciated!</p>\n"},{"tags":["sharepoint","ssas","olap","kpi"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1704,"score":0,"question_id":1006461,"title":"How do I show graphs and KPIs from an OLAP cube in Sharepoint?","body":"<p>I need to display content from an OLAP cube in Sharepoint. This could be done using PerformancePoint Server but unfortunately Microsoft has decided to drop support for that product some time ago. Their plan is to integrate some of the functionality directly into the next version of Sharepoint instead. The problem is that I can't wait that long and it would not be wise to base the solution on abondoned software.</p>\n\n<p>How can I solve this, should I use Excel Services and/or how can I do this?</p>\n\n<p>How would you solve it?</p>\n\n<p>With regards\nMarcus Lindholm</p>\n"},{"tags":["olap","business-intelligence","data-mining"],"answer_count":2,"favorite_count":4,"up_vote_count":4,"down_vote_count":0,"view_count":560,"score":4,"question_id":844376,"title":"How is BI related to data mining?","body":"<p>I'm a little confused on how to connect BI with data mining. Can BI be termed as some kind of a manifestation of data mining? </p>\n\n<p>How different is a BI tool like Microsoft Analysis Services from a data mining tool like Weka?</p>\n\n<p>I guess BI involves more of reporting and analysis of data, where in the data undergoes some kind of aggregation and is represented in the form of cubes, but data mining also involves different algorithms to perform clustering, no?</p>\n\n<p>Any pointers?</p>\n\n<p>cheers</p>\n"},{"tags":["sql-server","excel","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":666,"score":0,"question_id":954902,"title":"Fiscal Year in Excel When Browsing SSAS Cube","body":"<p>I am using Excel as the front end to a SQL Server Analysis Services (SSAS 2008) cube. I have a \"calendar\" dimension, which consists of a hierarchy of year-quarter-period where period is a 4 or 5 week month.</p>\n\n<p>Excel offers lots of useful options under its \"Date Filters\" menu such as being able to select just Quarter 1 etc.  This works in that it filters the data based on the underlying date, however, the calendar being used by Excel is a normal calendar rather than a fiscal calendar.  Excel treats Quarter 1 as being January, February March, whereas my fiscal quarter 1 is the first 13 weeks in the year starting April 1st.  Is it possible to get Excel to use a fiscal calendar?</p>\n\n<p>Thanks</p>\n\n<p>Darren</p>\n"},{"tags":["sql-server","olap","mdx"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":4174,"score":0,"question_id":956757,"title":"Dimension Member as Calculated Measure in MDX","body":"<p>I need to get a dimension member returned as a calculated measure.</p>\n\n<p>Given:</p>\n\n<p>Dimensions</p>\n\n<ul>\n<li>Customer {ACME, EMCA, Universal Imports, Universal Exports}</li>\n<li>Salesperson {Bob, Fred, Mary, Joe}</li>\n<li>Credit Type {Director, Manager}</li>\n</ul>\n\n<p>Measures</p>\n\n<ul>\n<li>Credited Value</li>\n<li>Value</li>\n</ul>\n\n<p>Relationships</p>\n\n<ul>\n<li>The Customer is a dimension of the facts that contain Value</li>\n<li>The Customer, Salesperson and Credit Type are dimensions of the facts that contain Credited Value</li>\n</ul>\n\n<p>I am trying to do the following:</p>\n\n<p>Create calculated measures that will return the Salesperson with the largest $s credited in a role for a customer. e.g.</p>\n\n<pre><code>| Customer          | Director | Manager | Value |\n|-------------------|----------|---------|-------|\n| ACME              | Bob      | Fred    | 500   |\n| EMCA              | Bob      | Fred    | 540   |\n| Universal Imports | Mary     | Joe     | 1000  |\n| Universal Exports | Mary     | Fred    | 33    |\n</code></pre>\n\n<ul>\n<li>ACME has Bob credited with 490 as Director</li>\n<li>ACME has Fred credited with 500 as Manager</li>\n<li>ACME has Mary credited with 10 as Director</li>\n</ul>\n\n<p>I would like to use this as a calculated measure that I can use in any case where Customers are the ROW.</p>\n"},{"tags":["sql","sql-server-2008","reporting-services","reportingservices-2008","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1298,"score":0,"question_id":464933,"title":"SQL2008: MSOLAP & SSRS Class not registered error with certain dimension","body":"<p>Our product leverages Analysis Services combined with Reporting Services, we recently made some changed to add compatability for SQL2008. Everything works great except with certain dimensions, drillthroughs or measures added to a report we suddenly get this following error:</p>\n\n<blockquote>\n  <p>Server: The operation has been\n  cancelled. Errors in the high-level\n  relational engine. A connection could\n  not be made to the data source with\n  the DataSourceID of 'Adventure Works\n  DW', Name of 'Adventure Works DW'. OLE\n  DB error: OLE DB or ODBC error: Class\n  not registered.</p>\n</blockquote>\n\n<p>Any ideas?</p>\n"},{"tags":["c#","sql-server-2005","olap","mdx"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":196,"score":0,"question_id":423365,"title":"Detecting KPI cell from Cellset when querying SQL 2005 Analysis Services","body":"<p>Given an MDX query that may return KPI values, is there a way to query the cells in the cellset object to determine whether they are actually KPI's?  This way I can display trend/status images in the results instead of 0. -1 etc.</p>\n"},{"tags":["sql-server","microsoft","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":314,"score":1,"question_id":810704,"title":"What is the correct way to setup readonly access to a MS Sql Ananlysis Server Cube","body":"<p>People don't seem to be able to get the data from the cube unless unless I set the database permission to \"full control\" on the server. What is the right way to give read access (only) to a cube in Microsoft SQL Server Analysis Server</p>\n"},{"tags":["sorting","paging","olap","mdx","cube"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":2172,"score":0,"question_id":853263,"title":"Sorting and Paging in MDX Query (MS Analysis Services)","body":"<p>I built an MDX query, to retrieve specific articles from an OLAP Cube. Basically it returns articles below a specific article-category node that are produced by a specific manufacturer:</p>\n\n<pre><code>SELECT NON EMPTY\n(\n\tHierarchize\n\t(\n\t\t{\n\t\t\tDrilldownLevel\n\t\t\t(\n\t\t\t\t{\n\t\t\t\t\t[T DAT Article].[Ar ID].[All]\n\t\t\t\t}\n\t\t\t)\n\t\t}\t\t\n\t) \n\n)\n\nDIMENSION PROPERTIES PARENT_UNIQUE_NAME,\n[T DAT Article].[Ar ID].[Ar ID].[Ar Key],\n[T DAT Article].[Ar ID].[Ar ID].[Ar LongName] \nON COLUMNS \nFROM [Catalog_2009]\n\nWHERE \n(\n\t[T DAT Structure].[St St ID FK].&amp;[193066], -- specific article-category node\n\t[T DAT Firm].[Fi ID].&amp;[86] -- specific manufacturer\n) \n\nCELL PROPERTIES VALUE, FORMAT_STRING, LANGUAGE, BACK_COLOR, FORE_COLOR, FONT_FLAGS\n</code></pre>\n\n<p>Now I want enhance this query to support paging and sorting. Meaning I can supply:</p>\n\n<ul>\n<li>Page index (like 0)</li>\n<li>Page size (like 30)</li>\n<li>Sort column (like Ar LongName)</li>\n<li>Sort direction (like ascending)</li>\n</ul>\n\n<p>What approach should I take? I looked at the <a href=\"http://technet.microsoft.com/en-us/library/ms144767.aspx\" rel=\"nofollow\">Subset</a> and <a href=\"http://msdn.microsoft.com/de-de/library/ms145587.aspx\" rel=\"nofollow\">order</a> clause. But those basically restricted the results from the 'hierarchize' part of the query, meaning they cut off the hierarchies instead of the end result..</p>\n\n<p>Could anyone give me a hint how to get paging and sorting to work?</p>\n"},{"tags":["sql-server","performance","ssas","olap","cubes"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":397,"score":0,"question_id":839526,"title":"Dealing with large result sets in SQL Server Analysis Services","body":"<p>I have a Database that contains data about <strong>articles</strong>,<strong>structures</strong> and <strong>manufacturers</strong>. Meaning an article is linked to 1 manufacturer and to N structure-nodes (think as article-classification-nodes).</p>\n\n<p>Querying articles using T-SQL with a lot of conditions is currently too slow to be usable for an e-shop, even with good hardware and properly indexed tables. (Should be below 1 sec).\nNow I wonder if it would make sense to access this data through an OLAP Cube. I already developed one to get aggregations, like: <em>How many articles of manufacturer X exist below node Y <strong>recursively</strong>?</em> </p>\n\n<p>These aggregations are pretty fast, now I wonder if it makes sense to also retrieve whole article-result sets through Cubes. Meaning: <em>Give me <strong>every single</strong> article ID of manufacturer X that exist below node Y recursively</em>. Because the result sets can be quite large, the query takes even longer..</p>\n\n<p>Therefore my question, is there a way to deal with large result sets in SSAS, or is this totally the wrong direction I am taking?</p>\n"},{"tags":["sql-server","resources","tutorials","ssas","olap"],"answer_count":1,"favorite_count":5,"up_vote_count":2,"down_vote_count":0,"view_count":574,"score":2,"question_id":798445,"title":"A Developers guide to SQL Server Analysis Services and OLAP","body":"<p><a href=\"http://sqlbatman.com/2009/04/when-do-you-need-a-cube/\" rel=\"nofollow\">This post from SqlBatman</a> describes a situation similar to my current client and, in reality, indicative of many companies that rely on tons of reports which have been shifted to over-night processing because of their performance impact. </p>\n\n<p>How do I get started using Analysis Services in general and OLAP Cubes in particular to help my clients? </p>\n"},{"tags":["sql-server","database","database-design","olap"],"answer_count":3,"favorite_count":0,"up_vote_count":2,"down_vote_count":0,"view_count":235,"score":2,"question_id":686199,"title":"Help figuring out approaches to (near) real time multi dimensional data querying","body":"<p>I have a system that involves numerous related tables.  Think of a standard category/product/order/customer/orderitem scenario.  Some tables are self referencing (like Categories).  None of the tables are particularly large (around 100k rows with an estimated scale to around 1 million rows).  There are a lot of dimensions to this data I need to consider, but must be queried in a near real time way.  I also don't know which dimensions a particular user is interested in- it can be one or many criteria across numerous tables. Things can range from</p>\n\n<ol>\n<li>Give me everything with a category of Jackets</li>\n<li>Give me everything with a category of Jackets->Parkas having a red color purchased in the last month in New York</li>\n<li>Give me everything which wasn't purchased in New York which costs over $100.</li>\n</ol>\n\n<p>Currently we have a very long SP which uses a \"cascading data\" approach- we go table by table, filtering everything into a temp table using whatever criteria was specified for that table.  For the next table, we join the current temp table to whatever table we're using and apply a new filter set into a new temp table.  It works, but manageability and performance is slow.  I need something better.</p>\n\n<p>I need a new approach to this problem.  It's clearly a need for OLAP, possibly using a star schema.  Does this work in real time? Can it be configured to work in real time?  Should I use indexed views to create a set of denormalized tables? Should I offload this outside of the database completely?</p>\n\n<p>FYI We're using Sql Server.</p>\n"},{"tags":["sql-server-2005","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1753,"score":0,"question_id":794319,"title":"SQL Server Analysis question- my cube breaks, claims it can't find a column that is there","body":"<p>I'm trying to learn SSAS on my own and am having troubles understanding a problem with my cube.  I have a database project where I want to do reporting on a single table.  I know this a bit unusual, but its a relatively simple model and data has already been normalized into that one table.  It has two columns that serve as dimensions- time of auction end and product type.  There are a number of measures, including # of items sold and sell price.  After I set up the cube and dimensions in SSAS and process it works fine, and I am able to browse the cube.  I can browse the cube from SAS or from a SSRS report I've made.</p>\n\n<p>However, if I come back on a later day I cannot update the cube anymore.  The table's schema supporting the cube has not changed, though there are new rows.  When I 'process cube' within SSAS, I get this error: </p>\n\n<blockquote>\n  <p>Errors in the OLAP storage engine: The attribute key cannot be found: Table: dbo_ScrapedAuction, Column: Id, Value: 76878. Errors in the OLAP storage engine: The record was skipped because the attribute key was not found. Attribute: Id of Dimension: Scraped Auction from Database: SSAS, Cube: Ebay Scraper, Measure Group: Scraped Auction, Partition: Scraped Auction, Record: 2913. Errors in the OLAP storage engine: The process operation ended because the number of errors encountered during processing reached the defined limit of allowable errors for the operation. Errors in the OLAP storage engine: An error occurred while processing the 'Scraped Auction' partition of the 'Scraped Auction' measure group for the 'Ebay Scraper' cube from the SSAS database.</p>\n</blockquote>\n\n<p>There is definately a table [dbo].[ScrapedAuction], it does still have the [Id] column, and there is a row in the table I can query with Id 76878.  Does anyone have any ideas what issue I'm running into?  I work around this by recreating the cube... which is not a real solution for production systems.</p>\n"},{"tags":[".net","orm","rdbms","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":4,"down_vote_count":0,"view_count":503,"score":4,"question_id":629425,"title":"ORMs are to RDBMSs as xxx is to OLAP cubes? Does xxx exist?","body":"<p>Is there an ORM-analogue for querying OLAP cubes / data-warehouses?  I'm specifically interested in the .NET world, but generally interested in anything ;-)</p>\n"},{"tags":["sql","performance","olap","fact-table","dimensional-modeling"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":2485,"score":0,"question_id":763621,"title":"Reporting Queries: Best Way to Join Multiple Fact Tables?","body":"<p>I'm working on a reporting system that allows the user to arbitrarily query a set of fact tables, constraining on multiple dimension tables for each fact table. I've written a query-builder class that automatically assembles all the correct joins and subqueries based on the constraint parameters, and everything works as designed.</p>\n\n<p>But, I have a feeling that I'm not generating the most efficient queries. On a set of tables with a few million records, these queries take about 10 seconds to run, and I'd like to get them down in the less-than-one-second range. I have a feeling that, if I could get rid of the subqueries, the result would be much more efficient.</p>\n\n<p>Rather than show you my actual schema (which is much more complicated), I'll show you an analogous example that illustrates the point without having to explain my whole application and data model.</p>\n\n<p>Imagine that I have a database of concert information, with artists and venues. Users can arbitrarily tag the artists and the venues. So the schema looks like this:</p>\n\n<pre><code>concert\n  id\n  artist_id\n  venue_id\n  date\n\nartist\n  id\n  name\n\nvenue\n  id\n  name\n\ntag\n  id\n  name\n\nartist_tag\n  artist_id\n  tag_id\n\nvenue_tag\n  venue_id\n  tag_id\n</code></pre>\n\n<p>Pretty simple.</p>\n\n<p>Now let's say I want to query the database for all concerts happening within one month of today, for all artists with 'techno' and 'trombone' tags, performing at concerts with 'cheap-beer' and 'great-mosh-pits' tag.</p>\n\n<p>The best query I've been able to come up with looks like this:</p>\n\n<pre><code>SELECT\n  concert.id AS concert_id,\n  concert.date AS concert_date,\n  artist.id AS artist_id,\n  artist.name AS artist_name,\n  venue.id AS venue_id,\n  venue.name AS venue_name,\nFROM\n  concert\nINNER JOIN (\n  artist ON artist.id = concert.artist_id\n) INNER JOIN (\n  venue ON venue.id = concert.venue_id\n)\nWHERE (\n  artist.id IN (\n    SELECT artist_id\n    FROM artist_tag\n    INNER JOIN tag AS a on (\n      a.id = artist_tag.tag_id\n      AND\n      a.name = 'techno'\n    ) INNER JOIN tag AS b on (\n      b.id = artist_tag.tag_id\n      AND\n      b.name = 'trombone'\n    )\n  )\n  AND\n  venue.id IN (\n    SELECT venue_id\n    FROM venue_tag\n    INNER JOIN tag AS a on (\n      a.id = venue_tag.tag_id\n      AND\n      a.name = 'cheap-beer'\n    ) INNER JOIN tag AS b on (\n      b.id = venue_tag.tag_id\n      AND\n      b.name = 'great-mosh-pits'\n    )\n  )\n  AND\n  concert.date BETWEEN NOW() AND (NOW() + INTERVAL 1 MONTH)\n)\n</code></pre>\n\n<p>The query works, but I <strong>really</strong> don't like having those multiple subqueries. If I could accomplish the same logic purely using JOIN logic, I have a feeling the performance would drastically improve.</p>\n\n<p>In a perfect world, I'd be using a real OLAP server. But my customers will be deploying to MySQL or MSSQL or Postgres, and I can't guarantee that a compatible OLAP engine will be available. So I'm stuck using an ordinary RDBMS with a star schema.</p>\n\n<p>Don't get too hung up on the details of this example (my real application has nothing to do with music, but it has multiple fact tables with an analogous relationship to the ones I've shown here). In this model, the 'artist_tag' and 'venue_tag' tables function as fact tables, and everything else is a dimension.</p>\n\n<p>It's important to note, in this example, that the queries are much simpler to write if I only allow the user to constrain against a single artist_tag or venue_tag value. It only gets really tricky when I allow the queries to include AND logic, requiring multiple distinct tags.</p>\n\n<p>So, my question is: what are the best techniques that you know of for writing efficient queries against multiple fact tables?</p>\n"},{"tags":["sql-server","sql-server-2005","ssas","olap","business-intelligence"],"answer_count":4,"favorite_count":3,"up_vote_count":2,"down_vote_count":0,"view_count":2125,"score":2,"question_id":332535,"title":"What is the best way to use SQL Server Analysis Services data in a line of business application?","body":"<p>We'd like to see if we can get some improved performance for analysis and reporting by moving some of our key data into Analysis Services cubes. However, I haven't been able to find much in the way of good client front ends. </p>\n\n<p>Our users have Office 2003. The move to 2007 is probably at least a year out and the Analysis Services add-in for Excel 2003 isn't great. I also considered just creating a winforms app, but I haven't had much luck finding robust controls for SSAS data. Meanwhile, Reporting Services seems to make you force your multi-dimensional data into a two dimensional dataset before it can be used in a report.</p>\n\n<p>I hope that I'm missing something obvious and that there are some great client tools somewhere that will allow us to bring the multi-dimensional data from SSAS to a client application in a meaningful way. Performance Point seems like overkill, but maybe it's the best option.</p>\n\n<p>Does anyone use SSAS data in line of business apps or is it primarily used for adhoc analysis? If you are using SSAS data for line of business apps, what technology(ies) are you using for the client front end?</p>\n"},{"tags":["sql","sql-server","ssas","olap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":376,"score":0,"question_id":629799,"title":"Deploying / Creating Analysis Services Database using an ASSL Script","body":"<p>Im trying to deploy as Analysis Services database using an ASSL script. </p>\n\n<p>I can create the script using \"script as\" in management studio. But I can't find out how to run this script?</p>\n"},{"tags":["command-line","ssas","olap","mdx","ascmd"],"answer_count":4,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":2692,"score":1,"question_id":265276,"title":"Where can I download a ascmd.exe?","body":"<p>I need to execute MDX query from command line (MS AS 2005). I have heard, that there is a program named ascmd, which can do this. Unfortunately, when I went to codeplex page I found that page supposed to deliver an ascmd doesn't work. Please help if you know any other page, where I can download ascmd or any other program executing MDX in command line. Thanks for reply!</p>\n"},{"tags":["sql-server-2005","olap","mdx"],"answer_count":4,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":537,"score":1,"question_id":586966,"title":"A simple MDX question","body":"<p>I am new to MDX and I know that this must be a simple question but I haven't been able to find an answer.</p>\n\n<p>I am modeling a a questionnaire that has questions and answers.  What I am trying to achieve is to find out the number of people who gave specific answers to questions., e.g. the number of males aged between 20-25</p>\n\n<p>When I run the query below for the questions individually the correct result is returned</p>\n\n<pre><code>SELECT\n      [Measures].[Fact Demographics Count] ON Columns\nFROM\n      [Dsv All]            \nWHERE\n      [Answer].[Dim Answer].&amp;[1]\n</code></pre>\n\n<p><code>[Measures].[Fact Demographics Count]</code> is a count of the primary key column</p>\n\n<p><code>[Answer].[Dim Answer].&amp;[1]</code> is the key for the Male answer</p>\n\n<p>Result for number of people who are male = 150\nResult for number of people who are between 20-25 = 12</p>\n\n<p>But when I run the next query below rather than getting the number people who are males and aged between 20-25.  I get the sum of the number of people who are males and the number of people who are between 20-25.</p>\n\n<pre><code>SELECT \n      [Measures].[Fact Demographics Count] ON Columns\nFROM\n      [Dsv All]            \nWHERE\n      {[Answer].[Dim Answer].&amp;[1],[Answer].[Dim Answer].&amp;[9]}\n</code></pre>\n\n<p>result = 162</p>\n\n<p>The structure of the fact table is</p>\n\n<p>FactDemographicsKey,</p>\n\n<p>RespodentKey,</p>\n\n<p>QuestionKey,</p>\n\n<p>AnswerKey</p>\n\n<p>Any help would be greatly appreciated</p>\n\n<p>Thanks</p>\n"},{"tags":["query","olap","mdx","rolap"],"answer_count":1,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":670,"score":0,"question_id":532441,"title":"MDX - Sum at lowest time, then Max it out","body":"<p>I have;</p>\n\n<ul>\n<li>a Time dimension (<em>Year, Month, Day, Hour</em>),</li>\n<li>a Product dimension (<em>Product, Feature</em>)</li>\n<li>and a User dimension (<em>User</em>)</li>\n</ul>\n\n<p>The measure I have available is: <em>Used</em> (Number of features that are in use)</p>\n\n<p>What I want to do, is to display the <strong>Max</strong> of concurrent usage. (This would be the <strong>Max</strong> of the <strong>Sum</strong> of <em>Used</em> for each <em>Feature</em> used by the same <em>User</em>, that happened in the same <em>Hour</em>).</p>\n\n<p>Is this doable in MDX, or would I need to deal with this in my database? (That feels wrong)</p>\n\n<p>Did I make self understandable? Any suggestion is welcome..</p>\n\n<p><strong>Edit (11 Feb 10:44 Central):</strong></p>\n\n<p>Visual explanation.. (this is what I want):</p>\n\n<pre><code>                               [2008 Feb 11] [2008 Feb 11, 07:00] [2008 Feb 11, 07:30]  [2008 Feb 11, 08:00]\n[Feature A] [Glenn] [Used]              5               2                    1                     2\n[Feature A] [Glenn] [Max Used]          3               2                    1                     2\n</code></pre>\n\n<p><strong>Max Used</strong> is as you see a <strong>Max Used Hourly</strong>. To get this, I would need to do the Sum at the hourly level..</p>\n\n<p>I'm currently using Mondrian</p>\n"},{"tags":["reporting-services","ssas","olap","cubes","rolap"],"answer_count":4,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1648,"score":1,"question_id":133751,"title":"Custom ROLAP Data Source in SSAS","body":"<p>I am trying to build an OLAP datasource from a bunch of binary files, and our current model just isn't working.  We are using SSAS as our analysis / reporting model for our results, but aren't able to get the performance we want out of SQL.  </p>\n\n<p>Our main constraints are:</p>\n\n<ol>\n<li><p>The database is very large.  We have huge dimension tables with millions of rows, and several smaller fact tables (&lt;1,000,000 rows).</p></li>\n<li><p>We have a dynamic cube.  B/C the fact tables are built dynamically, and often (possibly multiple times per day), there can't be any huge overhead in setting up the cube.  Current deploy times on the cube can exceed 24 hours, and we need orders of magnitude increase in performance which hardware just isn't gonna give us.  </p></li>\n</ol>\n\n<p>Basically, we want a fast setup and deploy, which doesn't inherently lend itself to SSAS using SQL Server 2005, but we want to use SSRS for reporting and we want an OLAP model for analysis in Excel, so we'd still like to use SSAS to build the cube if possible.  </p>\n\n<p>The common solution in SSAS for a fast deploy is ROLAP, but we are getting execution errors on larger ROLAP queries, and we also don't like all the overhead involved in converting the binary data to SQL and loading it into the cube.  </p>\n\n<p>Has anyone done work on a custom OLAP datasource that SSAS can use? We are looking to create our own ROLAP engine that will query the binary source files directly.</p>\n"},{"tags":["sql-server-2005","olap","mdx"],"answer_count":2,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":1982,"score":1,"question_id":533180,"title":"Joining fact tables in an MDX query","body":"<p>I am building and Anaysis Services project using VS 2005.  The goal is to analyse advertising campaigns.</p>\n\n<p>I have a single cube with 2 fact tables</p>\n\n<p>factCampaign: which contains details of what people interviewed thought of an advertising campaign\nfactDemographics: which contains demographic information of the people interviewed</p>\n\n<p>These fact tables have a common dimension dimRespodent which refers to the actual person interviewed</p>\n\n<p>I have 2 other dimensions (Iâ€™ve left non relevant dimensions)</p>\n\n<p>dimQuestion: which contains the list of questions asked\ndimAnswer: which contains the list of possible answers to each question</p>\n\n<p>dimQuestion and dimAnswer are linked to factDemogrpahics but not factCampaign</p>\n\n<p>I want to be able to run queries to return results of what people thought about campaign (from factCampaign) but using demographic criteria (using dimQuestion and dimAnswer)</p>\n\n<p>For example the how many Males, aged 18-25 recalled a particular campaign</p>\n\n<p>I am new to OLAP and Analysis Services (2005) so please excuse me if what I am asking is too basic.</p>\n\n<p>I have tried the following options</p>\n\n<ol>\n<li>Linking the to factTables in the datasource view using the common RespondentKey.  Queries run and return results but the same result is returned regardless of the demographic criteria chosen, i.e. it is being ignored.</li>\n<li>Creating a dimension from factDemographics.  I have tried to connect dimAnswer to factCampaign in Dimension Usage tabe of the Cube Structure but with out success.  Either the project just stalls when I try to deploy it or I get the following error (note the attribute hierarchy enabled is set to true)</li>\n</ol>\n\n<p>Errors in the metadata manager. The 'Answer Key' intermediate granularity attribute of the 'Fact Demographics' measure group dimension does not have an attribute hierarchy enabled.</p>\n\n<p>I would appreciate any help that anyone can offer.  Let me know if you require more info and again apologies if this is a basic question</p>\n"},{"tags":["asp.net","database-design","aggregate","olap"],"answer_count":3,"favorite_count":2,"up_vote_count":2,"down_vote_count":0,"view_count":676,"score":2,"question_id":483319,"title":"How to handle large amounts of data for a web statistics module","body":"<p>I'm developing a statistics module for my website that will help me measure conversion rates, and other interesting data.</p>\n\n<p>The mechanism I use is - to store a database entry in a statistics table - each time a user enters a specific zone in my DB (I avoid duplicate records with the help of cookies).</p>\n\n<p>For example, I have the following zones:</p>\n\n<ol>\n<li>Website - a general zone used to count unique users as I stopped trusting Google Analytics lately.</li>\n<li>Category - self descriptive.</li>\n<li>Minisite - self descriptive.</li>\n<li>Product Image - whenever user sees a product and the lead submission form.</li>\n</ol>\n\n<p>Problem is after a month, my statistics table is packed with <strong>a lot</strong> of rows, and the ASP.NET pages I wrote to parse the data load <strong>really</strong> slow.</p>\n\n<p>I thought maybe writing a service that will somehow parse the data, but I can't see any way to do that without losing flexibility.</p>\n\n<p>My questions:</p>\n\n<ol>\n<li>How large scale data parsing applications - like Google Analytics load the data so fast?</li>\n<li>What is the best way for me to do it?</li>\n<li>Maybe my DB design is wrong and I should store the data in only one table?</li>\n</ol>\n\n<p>Thanks for anyone that helps,</p>\n\n<p>Eytan.</p>\n"},{"tags":["sql-server","ssas","olap"],"answer_count":3,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":4594,"score":1,"question_id":455021,"title":"How to use a slowly changing dimension in Sql Server Analysis Services","body":"<p>In a data warehouse, I want to have a fact table which tracks certain metrics of a university application (average score on a standardized test, for example) and also the status of applications during different times of the year. For simpliciy, let's say a given application progresses through 3 states:</p>\n\n<ol>\n<li>New</li>\n<li>Being Assesssed</li>\n<li>Assessed</li>\n</ol>\n\n<p>and these states change over time.</p>\n\n<p>I believe I want to use a slowly changing dimension here, but I can't figure out how to get to work properly.</p>\n\n<p>Can someone give me an example of a fact table and dimension table which tracks two applications as they progress through these states? </p>\n\n<p>I'm using SQL Server Analysis Services 2005. </p>\n\n<p>The goal is to be able to do year on year analysis for the number of applications in each state.</p>\n"},{"tags":["sql-server","performance","olap","mdx"],"answer_count":2,"favorite_count":2,"up_vote_count":2,"down_vote_count":0,"view_count":391,"score":2,"question_id":359374,"title":"How to assess performance of MDX in OLAP processing","body":"<p>I am familiar with standard practices to assess performance query or stored procedure using SQL server 2000/2005/2008.  How is the best way to assess MDX performance? I assume its possible to write structurely correct but poor performance MDX queries as easily as you can with standard T-SQL?  Any suggestions?</p>\n\n<p>FYI: I may be tasked with overhauling current data mining project that uses MS SQL analysis services and Proclarity client.</p>\n"},{"tags":["asp.net","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":963,"score":0,"question_id":145322,"title":"WebFocus - is there a free/open source alternative?","body":"<p>What is a good free/open source alternative to <a href=\"http://en.wikipedia.org/wiki/WebFOCUS\" rel=\"nofollow\">WebFOCUS</a>? </p>\n\n<p>Is there an ASP.NET way of getting info from an OLAP cube?  </p>\n\n<p><strong>Update:</strong> I chose Magnus Smith's answer as the correct one, but <a href=\"http://stackoverflow.com/questions/145322/webfocus-is-there-a-freeopen-source-alternative#145467\">Alexmac's answer</a> was also very good!</p>\n"},{"tags":["database-design","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":1,"down_vote_count":0,"view_count":532,"score":1,"question_id":272196,"title":"Does it make sense to \"fake\" bitmap indexes?","body":"<p>I'm planning software that's an OLAP application at its heart (it helps analyse metering data) and is going to have some kind of star schema for its database, because the stored values will be looked at from different angles (time, source, type etc.) and the requests will be asking for aggregated data along these dimensions. The queries tend to deliver a lot of rows (up to some 100 000).</p>\n\n<p>My research on this topic (see also <a href=\"http://stackoverflow.com/questions/261743/good-fast-storage-strategy-for-facts-with-dynamically-evolving-dimensions\">my question here</a>) seems to indicate that bitmap indices are a good way to search for data the way I'm planning to. However, I want to support multiple db engines, some of which do not offer bitmap indices on their tables (in particular, MySQL).</p>\n\n<p>Now, I can certainly build and maintain my own bitmap index and use it to look for row ids pointing to the fact table. However, I suspect that this is going to defeat the whole purpose of the index, because the database is still going to search for row ids in a B-Tree. Could somebody with more profound theoretical background or more experience tell me if I still gain anything, like not having to do slow JOINs on the dimension tables?</p>\n\n<p>I would also appreciate hints on what I have to evaluate if the answer is not straightforward.</p>\n"},{"tags":["linux","database-design","postgresql","olap"],"answer_count":5,"favorite_count":2,"up_vote_count":4,"down_vote_count":0,"view_count":6682,"score":4,"question_id":144487,"title":"Can you recommend a PostgreSQL Visual Database Designer for Linux?","body":"<p>When I'm in Windows, I use the <strong>excellent</strong> <a href=\"http://www.microolap.com/products/database/postgresql-designer/\" rel=\"nofollow\">MicroOLAP</a> Database Designer for PostgreSQL, but its not open source or multiplataform.<br />\nDo you know or can recommend me an alternative to this software, that I can use in Linux?</p>\n\n<p><em>EDIT: Just to clarify, I don't want to use wine to emulate MicroOlap for PostgreSQL, it doesn't work too well, I would prefer something native, or Java based.</em></p>\n"},{"tags":["database","text-files","olap","hacks","logging"],"answer_count":4,"favorite_count":0,"up_vote_count":1,"down_vote_count":0,"view_count":613,"score":1,"question_id":4541,"title":"Simple MOLAP solution","body":"<P>To analyze lots of text logs I did some hackery that looks like this</P>\r\n<OL>\r\n<LI>Locally import logs into Access </LI>\r\n<LI>Reprocess Cube link to previous mdb in Analisis Service 2000 (yes it is 2k)</LI>\r\n<LI>Use Excel to visualize Cube (it is not big - up to milions raw entries)</LI></OL>\r\n<P>My hackery is a succes and more people are demanding an access to my Tool. As you see I see more automating and easier deployment.</P>\r\n<P>Do you now some tools/libraries that would give me the same but with easier deployment? Kind of <STRONG>embedded OLAP</STRONG> serwice?</P>\r\n<P><STRONG>Edit:</STRONG> I heard of Mondrian but we don't do much with Java. Have you seen something similiar done for .Net/Win32 ? Comercial is also OK.</P>"},{"tags":["excel","vba","olap","pivot-table"],"answer_count":3,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1619,"score":0,"question_id":101223,"title":"Programmatically exclude page items in olap pivot","body":"<p>I have a pivot table on an olap cube. I can go into a page field and manually deselect multiple items. How can I do this in VBA based on a list of items I need excluded? (n.b. I do not have a corrresponding list of items I need included)</p>\n\n<p>I know how to exclude these items in other ways, by altering the underlying query for example. I specifically want to replicate the user action of deselecting items in the pivot.</p>\n"},{"tags":["database","database-design","data-warehouse","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":1897,"score":0,"question_id":149871,"title":"How to design a fact table for delivery data","body":"<p>I'm building a data warehouse that includes delivery information for restaurants. The data is stored in SQL Server 2005 and is then put into a SQL Server Analysis Services 2005 cube.</p>\n\n<p>The Deliveries information consists of the following tables:</p>\n\n<p><strong>FactDeliveres</strong></p>\n\n<ul>\n<li>BranchKey</li>\n<li>DeliveryDateKey</li>\n<li>ProductKey</li>\n<li>InvoiceNumber (DD: degenerate dimension)</li>\n<li>Quantity</li>\n<li>UnitCosT</li>\n<li>Linecost</li>\n</ul>\n\n<p><strong>Note:</strong> </p>\n\n<ul>\n<li>The granularity of FactDeliveres is each line on the invoice</li>\n<li>The Product dimension include supplier information</li>\n</ul>\n\n<p><strong>And the problem:</strong> there is no primary key for the fact table. The primary key should be something that uniquely identifies each delivery plus the ProductKey. But I have no way to uniquely identify a delivery.</p>\n\n<p>In the source OLTP database there is a DeliveryID that is unique for every delivery, but that is an internal ID that meaningless to users. The InvoiceNumber is the suppliers' invoices number -- this is typed in manually and so we get duplicates.</p>\n\n<p>In the cube, I created a dimension based only on the InvoiceNumber field in FactDeliveres. That does mean that when you group by InvoiceNumber, you might get 2 deliveries combined only because they (mistakenly) have the same InvoiceNumber.</p>\n\n<p>I feel that I need to include the DeliveryID (to be called DeliveryKey), but I'm not sure how. </p>\n\n<p><strong>So, do I:</strong> </p>\n\n<ol>\n<li>Use that as the underlying key for the InvoiceNumber dimension?</li>\n<li>Create a DimDelivery that grows every time there is a new delivery? That could mean that some attributes come out of FactDeliveries and go into DimDelivery, like DeliveryDate,Supplier, InvoiceNumber.</li>\n</ol>\n\n<p>After all that, I could just ask you: how do I create a Deliveries cube when I have the following information in my source database</p>\n\n<p><strong>DeliveryHeaders</strong></p>\n\n<ul>\n<li>DeliveryID (PK)</li>\n<li>DeliveryDate</li>\n<li>SupplierID (FK)</li>\n<li>InvoiceNumber (typed in manually)</li>\n</ul>\n\n<p><strong>DeliveryDetails</strong></p>\n\n<ul>\n<li>DeliveryID (PK)</li>\n<li>ProductID (PK)</li>\n<li>Quantity</li>\n<li>UnitCosT</li>\n</ul>\n"},{"tags":["olap","mdx"],"answer_count":1,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":1023,"score":0,"question_id":120616,"title":"How to display the total of a level as the value of its last child in MDX","body":"<p>I have an MDX query which lists a measure for all 'Week' and 'Day' levels in the OLAP database. For example</p>\n\n<pre><code>SELECT \n{\n    HIERARCHIZE( {[Business Time].[Week].members, [Business Time].[Date].members} )\n} \nON ROWS,\n{\n    [Measures].[Quantity]\n} \nON COLUMNS \nFROM [Sales]\n</code></pre>\n\n<p>Where the measure is displayed for a Week though, instead of showing the total of all the Day values, I would like to show the value for the last day within the week. For example</p>\n\n<p><strong>Week 1: 12<br /></strong>\n15 Sept: 10<br />\n16 Sept: 20<br />\n17 Sept: 12<br />\n18 Sept: 15<br />\n19 Sept: 8<br />\n20 Sept: 9<br />\n21 Sept: 12<br />\n<strong>Week 2: 15<br /></strong>\n22 Sept: 12<br />\n23 Sept: 15<br /></p>\n\n<p>How can I achieve this within the MDX?</p>\n"},{"tags":["sql-server","olap"],"answer_count":2,"favorite_count":1,"up_vote_count":0,"down_vote_count":0,"view_count":818,"score":0,"question_id":30374,"title":"What is a good source for learning OLAP","body":"<p>Are there any excellent sources (book, podcast, tribal folklore, etc) fo rgetting a grasp on using OLAP for data analysis in SQL Server (or just in generic terms that can be applied to SQL Server)?</p>\n"},{"tags":["sql-server","report","olap"],"answer_count":2,"favorite_count":0,"up_vote_count":0,"down_vote_count":0,"view_count":251,"score":0,"question_id":28360,"title":"Moving SQL based reports to Data cubes","body":"<p>I am about to migrate a bunch of seriously over-complex Reports (MS SQL report server over some horrible stored procedures) to something more BI based.  I was wondering if anybody had any pointers, gotchas, or general advice on the best way to do this.  Thanks.</p>\n"}]}
